{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeYrP4n7vd0_"
      },
      "source": [
        "# PyTorch Tensor Introduction: Building Blocks of Deep Learning\n",
        "\n",
        "Welcome to the comprehensive introduction to **PyTorch tensors** - the fundamental data structure that powers all computations in PyTorch. This tutorial provides a deep dive into tensor creation, manipulation, and operations, specifically designed for learners transitioning from TensorFlow to PyTorch.\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this tutorial, you will master:\n",
        "1. **Creating Tensors**: Various factory methods and initialization techniques\n",
        "2. **Tensor Operations**: Arithmetic, broadcasting, and in-place operations\n",
        "3. **Tensor Shapes**: Manipulating dimensions with unsqueeze, squeeze, and reshape\n",
        "4. **GPU Acceleration**: Moving tensors to different devices for hardware acceleration\n",
        "5. **NumPy Bridge**: Seamless interoperability between PyTorch and NumPy\n",
        "\n",
        "## Key Differences: TensorFlow vs PyTorch Tensors\n",
        "| Aspect | TensorFlow | PyTorch |\n",
        "|--------|------------|---------|\n",
        "| **Creation** | `tf.constant([1, 2, 3])` | `torch.tensor([1, 2, 3])` |\n",
        "| **Empty Tensors** | `tf.Variable(tf.zeros([2, 3]))` | `torch.empty(2, 3)` |\n",
        "| **Random** | `tf.random.normal([2, 3])` | `torch.randn(2, 3)` |\n",
        "| **Device** | Automatic distribution | Explicit `.to(device)` |\n",
        "| **NumPy** | `.numpy()` method | Direct `.numpy()` sharing memory |\n",
        "| **Execution** | Graph/Eager modes | Always eager (dynamic) |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M2hZ5levd1A"
      },
      "source": [
        "## 1. Environment Setup and Runtime Detection\n",
        "\n",
        "Following PyTorch best practices for cross-platform compatibility and device management:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vn4QTlnkvd1A",
        "outputId": "de12f94c-ec03-458b-bb5d-5ab0efb1aa4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment detected:\n",
            "  - Local: False\n",
            "  - Google Colab: True\n",
            "  - Kaggle: False\n",
            "\n",
            "Setting up Google Colab environment...\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "\n",
            "Verifying required packages...\n",
            "‚úì torch 2.8.0+cu126\n",
            "‚úì torchvision 0.23.0+cu126\n",
            "‚úì numpy 2.0.2\n",
            "‚úì matplotlib 3.10.0\n"
          ]
        }
      ],
      "source": [
        "# Environment Detection and Setup\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Detect the runtime environment\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
        "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
        "\n",
        "print(f\"Environment detected:\")\n",
        "print(f\"  - Local: {IS_LOCAL}\")\n",
        "print(f\"  - Google Colab: {IS_COLAB}\")\n",
        "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
        "\n",
        "# Platform-specific system setup\n",
        "if IS_COLAB:\n",
        "    print(\"\\nSetting up Google Colab environment...\")\n",
        "    !apt update -qq\n",
        "    !apt install -y -qq software-properties-common\n",
        "elif IS_KAGGLE:\n",
        "    print(\"\\nSetting up Kaggle environment...\")\n",
        "    # Kaggle usually has most packages pre-installed\n",
        "else:\n",
        "    print(\"\\nSetting up local environment...\")\n",
        "\n",
        "# Install required packages for this notebook\n",
        "required_packages = [\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"numpy\",\n",
        "    \"matplotlib\"\n",
        "]\n",
        "\n",
        "print(\"\\nVerifying required packages...\")\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        if package == \"torch\":\n",
        "            import torch\n",
        "            print(f\"‚úì {package} {torch.__version__}\")\n",
        "        elif package == \"torchvision\":\n",
        "            import torchvision\n",
        "            print(f\"‚úì {package} {torchvision.__version__}\")\n",
        "        elif package == \"numpy\":\n",
        "            import numpy as np\n",
        "            print(f\"‚úì {package} {np.__version__}\")\n",
        "        elif package == \"matplotlib\":\n",
        "            import matplotlib\n",
        "            print(f\"‚úì {package} {matplotlib.__version__}\")\n",
        "    except ImportError:\n",
        "        print(f\"‚ùå {package} not found\")\n",
        "        if IS_COLAB or IS_KAGGLE:\n",
        "            !pip install -q {package}\n",
        "        else:\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package],\n",
        "                          capture_output=True)\n",
        "        print(f\"üì¶ Installed {package}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6n1NflKKvd1B",
        "outputId": "d53d4718-f313-4223-d3f6-ec0cd4fbe2a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíª Using CPU (no GPU acceleration detected)\n",
            "   Processor: x86_64\n",
            "   PyTorch Threads: 1\n",
            "   System: Linux 6.1.123+\n",
            "\n",
            "‚úÖ PyTorch 2.8.0+cu126 ready!\n",
            "üì± Device selected: cpu\n",
            "üìä Device info: CPU (No GPU acceleration available)\n"
          ]
        }
      ],
      "source": [
        "# Import essential libraries and setup device detection\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import platform\n",
        "\n",
        "def detect_device():\n",
        "    \"\"\"\n",
        "    Detect the best available PyTorch device with comprehensive hardware support.\n",
        "\n",
        "    Priority order:\n",
        "    1. CUDA (NVIDIA GPUs) - Best performance for deep learning\n",
        "    2. MPS (Apple Silicon) - Optimized for M1/M2/M3 Macs\n",
        "    3. CPU (Universal) - Always available fallback\n",
        "\n",
        "    Returns:\n",
        "        torch.device: The optimal device for PyTorch operations\n",
        "        str: Human-readable device description for logging\n",
        "    \"\"\"\n",
        "    # Check for CUDA (NVIDIA GPU)\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        device_info = f\"CUDA GPU: {gpu_name}\"\n",
        "\n",
        "        cuda_version = torch.version.cuda\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "\n",
        "        print(f\"üöÄ Using CUDA acceleration\")\n",
        "        print(f\"   GPU: {gpu_name}\")\n",
        "        print(f\"   CUDA Version: {cuda_version}\")\n",
        "        print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "        return device, device_info\n",
        "\n",
        "    # Check for MPS (Apple Silicon)\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        device_info = \"Apple Silicon MPS\"\n",
        "\n",
        "        system_info = platform.uname()\n",
        "\n",
        "        print(f\"üçé Using Apple Silicon MPS acceleration\")\n",
        "        print(f\"   System: {system_info.system} {system_info.release}\")\n",
        "        print(f\"   Machine: {system_info.machine}\")\n",
        "\n",
        "        return device, device_info\n",
        "\n",
        "    # Fallback to CPU\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        device_info = \"CPU (No GPU acceleration available)\"\n",
        "\n",
        "        cpu_count = torch.get_num_threads()\n",
        "        system_info = platform.uname()\n",
        "\n",
        "        print(f\"üíª Using CPU (no GPU acceleration detected)\")\n",
        "        print(f\"   Processor: {system_info.processor}\")\n",
        "        print(f\"   PyTorch Threads: {cpu_count}\")\n",
        "        print(f\"   System: {system_info.system} {system_info.release}\")\n",
        "\n",
        "        return device, device_info\n",
        "\n",
        "# Detect and set up device\n",
        "device, device_info = detect_device()\n",
        "\n",
        "print(f\"\\n‚úÖ PyTorch {torch.__version__} ready!\")\n",
        "print(f\"üì± Device selected: {device}\")\n",
        "print(f\"üìä Device info: {device_info}\")\n",
        "\n",
        "# Set global device for the notebook\n",
        "DEVICE = device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3mBEUuJvd1B"
      },
      "source": [
        "## 2. Creating Tensors: Factory Methods and Initialization\n",
        "\n",
        "PyTorch provides various methods to create tensors. Let's explore the fundamental tensor creation techniques using Australian tourism data examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YgiM20AUvd1B",
        "outputId": "d860bf9d-1833-43cc-e040-ee0531579af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ 1. Basic Tensor Creation with torch.empty()\n",
            "\n",
            "Empty tensor (3x4):\n",
            "tensor([[1.6326e-38, 0.0000e+00, 5.7231e-18, 4.3093e-41],\n",
            "        [5.7232e-18, 4.3093e-41, 8.9248e-15, 4.3094e-41],\n",
            "        [1.6329e-38, 0.0000e+00, 1.3593e-43, 0.0000e+00]])\n",
            "Shape: torch.Size([3, 4])\n",
            "Data type: torch.float32\n",
            "Device: cpu\n",
            "\n",
            "‚ö†Ô∏è  Note: torch.empty() values are uninitialized!\n",
            "   TensorFlow equivalent: tf.Variable(tf.zeros([3, 4])) or tf.empty([3, 4])\n",
            "   Use torch.empty() when you'll immediately fill the tensor with data\n",
            "\n",
            "üìä TensorFlow vs PyTorch Empty Tensors:\n",
            "   TensorFlow: tf.Variable(tf.zeros([3, 4])) # Usually initialize with zeros\n",
            "   PyTorch:    torch.empty(3, 4)           # Faster, but uninitialized\n"
          ]
        }
      ],
      "source": [
        "# 1. Basic tensor creation with torch.empty()\n",
        "print(\"üì¶ 1. Basic Tensor Creation with torch.empty()\\n\")\n",
        "\n",
        "# torch.empty() allocates memory without initializing values\n",
        "# Values will be whatever was in memory at the time\n",
        "empty_tensor = torch.empty(3, 4)\n",
        "print(f\"Empty tensor (3x4):\\n{empty_tensor}\")\n",
        "print(f\"Shape: {empty_tensor.shape}\")\n",
        "print(f\"Data type: {empty_tensor.dtype}\")\n",
        "print(f\"Device: {empty_tensor.device}\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  Note: torch.empty() values are uninitialized!\")\n",
        "print(\"   TensorFlow equivalent: tf.Variable(tf.zeros([3, 4])) or tf.empty([3, 4])\")\n",
        "print(\"   Use torch.empty() when you'll immediately fill the tensor with data\")\n",
        "\n",
        "# Compare with TensorFlow approach\n",
        "print(\"\\nüìä TensorFlow vs PyTorch Empty Tensors:\")\n",
        "print(\"   TensorFlow: tf.Variable(tf.zeros([3, 4])) # Usually initialize with zeros\")\n",
        "print(\"   PyTorch:    torch.empty(3, 4)           # Faster, but uninitialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ktOwW-HTvd1B",
        "outputId": "63bc175f-126c-4134-dcc1-219d8e2c29b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ 2. Common Factory Methods: Zeros, Ones, and Random\n",
            "\n",
            "Example: Australian state tourism visitor data\n",
            "\n",
            "Visitor data initialized (8 states √ó 4 quarters):\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "Shape: torch.Size([8, 4])\n",
            "\n",
            "Base tourism scores: tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "\n",
            "üé≤ Random Tensor Creation:\n",
            "Weather variations (normal distribution):\n",
            "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345],\n",
            "        [-0.7279, -0.5594, -0.7688,  0.7624,  1.6423, -0.1596],\n",
            "        [ 1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418]])...\n",
            "Shape: torch.Size([8, 12])\n",
            "Mean: 0.0460 (should be ~0)\n",
            "Std: 1.0257 (should be ~1)\n",
            "\n",
            "Tourism ratings (uniform [0,1)):\n",
            "tensor([[0.9578, 0.3313, 0.3227, 0.0162, 0.2137],\n",
            "        [0.6249, 0.4340, 0.1371, 0.5117, 0.1585],\n",
            "        [0.0758, 0.2247, 0.0624, 0.1816, 0.9998],\n",
            "        [0.5944, 0.6541, 0.0337, 0.1716, 0.3336],\n",
            "        [0.5782, 0.0600, 0.2846, 0.2007, 0.5014],\n",
            "        [0.3139, 0.4654, 0.1612, 0.1568, 0.2083],\n",
            "        [0.3289, 0.1054, 0.9192, 0.4008, 0.9302],\n",
            "        [0.6558, 0.0766, 0.8460, 0.3624, 0.3083]])\n",
            "Min: 0.0162, Max: 0.9998\n",
            "\n",
            "üìä TensorFlow vs PyTorch Random Tensors:\n",
            "   TensorFlow: tf.random.normal([8, 12])    PyTorch: torch.randn(8, 12)\n",
            "   TensorFlow: tf.random.uniform([8, 5])    PyTorch: torch.rand(8, 5)\n"
          ]
        }
      ],
      "source": [
        "# 2. Common factory methods for predictable initialization\n",
        "print(\"üéØ 2. Common Factory Methods: Zeros, Ones, and Random\\n\")\n",
        "\n",
        "# Australian tourism data: visitor counts by state (in thousands)\n",
        "print(\"Example: Australian state tourism visitor data\\n\")\n",
        "\n",
        "# Zeros tensor - useful for initialization\n",
        "visitor_data = torch.zeros(8, 4)  # 8 states/territories, 4 quarters\n",
        "print(f\"Visitor data initialized (8 states √ó 4 quarters):\\n{visitor_data}\")\n",
        "print(f\"Shape: {visitor_data.shape}\")\n",
        "\n",
        "# Ones tensor - useful for masks and default weights\n",
        "base_tourism_score = torch.ones(8)  # Base score of 1.0 for each state\n",
        "print(f\"\\nBase tourism scores: {base_tourism_score}\")\n",
        "\n",
        "# Random tensors - crucial for neural network initialization\n",
        "print(\"\\nüé≤ Random Tensor Creation:\")\n",
        "\n",
        "# Set seed for reproducibility in documentation\n",
        "torch.manual_seed(16)\n",
        "\n",
        "# Random numbers from normal distribution (mean=0, std=1)\n",
        "weather_variations = torch.randn(8, 12)  # 8 states, 12 months\n",
        "print(f\"Weather variations (normal distribution):\\n{weather_variations[:3, :6]}...\")  # Show subset\n",
        "print(f\"Shape: {weather_variations.shape}\")\n",
        "print(f\"Mean: {weather_variations.mean():.4f} (should be ~0)\")\n",
        "print(f\"Std: {weather_variations.std():.4f} (should be ~1)\")\n",
        "\n",
        "# Random numbers from uniform distribution [0, 1)\n",
        "tourism_ratings = torch.rand(8, 5)  # 8 states, 5 categories\n",
        "print(f\"\\nTourism ratings (uniform [0,1)):\\n{tourism_ratings}\")\n",
        "print(f\"Min: {tourism_ratings.min():.4f}, Max: {tourism_ratings.max():.4f}\")\n",
        "\n",
        "print(\"\\nüìä TensorFlow vs PyTorch Random Tensors:\")\n",
        "print(\"   TensorFlow: tf.random.normal([8, 12])    PyTorch: torch.randn(8, 12)\")\n",
        "print(\"   TensorFlow: tf.random.uniform([8, 5])    PyTorch: torch.rand(8, 5)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pswP-CNxvd1C"
      },
      "source": [
        "## 3. Tensor Operations: Arithmetic, Broadcasting, and Transformations\n",
        "\n",
        "Explore the rich set of operations available for tensor manipulation, from basic arithmetic to advanced broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2n7dZXzKvd1C",
        "outputId": "65575350-8bac-40c1-c19e-82b611c26ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ûï 1. Arithmetic Operations with Scalars\n",
            "\n",
            "Original hotel prices (AUD): tensor([150., 200., 180., 220., 160.])\n",
            "Cities: ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide']\n",
            "\n",
            "After $20 discount: tensor([130., 180., 160., 200., 140.])\n",
            "With 10% GST: tensor([165., 220., 198., 242., 176.])\n",
            "Weekly rates (√ó7): tensor([1050., 1400., 1260., 1540., 1120.])\n",
            "\n",
            "Log prices: tensor([5.0106, 5.2983, 5.1930, 5.3936, 5.0752])\n",
            "Rounded GST prices: tensor([165., 220., 198., 242., 176.])\n",
            "\n",
            "üìä TensorFlow equivalent operations:\n",
            "   TensorFlow: tf.add(prices, -20)     PyTorch: prices - 20\n",
            "   TensorFlow: tf.multiply(prices, 1.1) PyTorch: prices * 1.1\n",
            "   TensorFlow: tf.math.log(prices)     PyTorch: torch.log(prices)\n"
          ]
        }
      ],
      "source": [
        "# 1. Arithmetic operations with scalars\n",
        "print(\"‚ûï 1. Arithmetic Operations with Scalars\\n\")\n",
        "\n",
        "# Australian hotel prices per night (AUD)\n",
        "hotel_prices = torch.tensor([150.0, 200.0, 180.0, 220.0, 160.0], dtype=torch.float32)\n",
        "cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\"]\n",
        "\n",
        "print(f\"Original hotel prices (AUD): {hotel_prices}\")\n",
        "print(f\"Cities: {cities}\")\n",
        "\n",
        "# Scalar arithmetic - operations apply element-wise\n",
        "gst_rate = 0.1  # 10% GST in Australia\n",
        "discount = 20.0  # $20 discount\n",
        "\n",
        "# Addition and subtraction\n",
        "discounted_prices = hotel_prices - discount\n",
        "print(f\"\\nAfter $20 discount: {discounted_prices}\")\n",
        "\n",
        "# Multiplication and division\n",
        "prices_with_gst = hotel_prices * (1 + gst_rate)\n",
        "print(f\"With 10% GST: {prices_with_gst}\")\n",
        "\n",
        "weekly_prices = hotel_prices * 7\n",
        "print(f\"Weekly rates (√ó7): {weekly_prices}\")\n",
        "\n",
        "# Mathematical functions\n",
        "log_prices = torch.log(hotel_prices)  # Natural logarithm\n",
        "rounded_prices = torch.round(prices_with_gst)\n",
        "\n",
        "print(f\"\\nLog prices: {log_prices}\")\n",
        "print(f\"Rounded GST prices: {rounded_prices}\")\n",
        "\n",
        "print(\"\\nüìä TensorFlow equivalent operations:\")\n",
        "print(\"   TensorFlow: tf.add(prices, -20)     PyTorch: prices - 20\")\n",
        "print(\"   TensorFlow: tf.multiply(prices, 1.1) PyTorch: prices * 1.1\")\n",
        "print(\"   TensorFlow: tf.math.log(prices)     PyTorch: torch.log(prices)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJrGuBYHvd1C"
      },
      "source": [
        "## 4. Tensor Shapes and Dimensions\n",
        "\n",
        "Learn how to manipulate tensor shapes using unsqueeze, squeeze, and reshape operations - essential for deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OjY2fb9kvd1C",
        "outputId": "1eade126-771f-4c6a-e15c-1d7395e64cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Tensor Shape Manipulation: Australian Text Processing\n",
            "\n",
            "Original tokens: tensor([15, 67, 89, 23, 45, 12, 78, 34, 56, 91, 23, 67])\n",
            "Shape: torch.Size([12]) (12 tokens)\n",
            "\n",
            "üìê Reshaping Operations:\n",
            "Reshaped to 3x4:\n",
            "tensor([[15, 67, 89, 23],\n",
            "        [45, 12, 78, 34],\n",
            "        [56, 91, 23, 67]])\n",
            "\n",
            "Reshaped to 2x6:\n",
            "tensor([[15, 67, 89, 23, 45, 12],\n",
            "        [78, 34, 56, 91, 23, 67]])\n",
            "\n",
            "Reshaped to 4x? (auto-calculated):\n",
            "tensor([[15, 67, 89],\n",
            "        [23, 45, 12],\n",
            "        [78, 34, 56],\n",
            "        [91, 23, 67]])\n",
            "Auto shape: torch.Size([4, 3])\n",
            "\n",
            "üìè Adding Dimensions (unsqueeze):\n",
            "With batch dimension: torch.Size([1, 12]) (1 √ó 12)\n",
            "With channel dimension: torch.Size([12, 1]) (12 √ó 1)\n",
            "\n",
            "üóúÔ∏è Removing Dimensions (squeeze):\n",
            "After squeezing batch dim: torch.Size([12])\n",
            "\n",
            "üí° Practical NLP Example: Preparing for Embedding Layer\n",
            "Batch of sentences: torch.Size([3, 6]) (batch_size √ó seq_length)\n",
            "Batch:\n",
            "tensor([[ 15,  67,  89,  23,   0,   0],\n",
            "        [156,  78, 234,  45, 167,  98],\n",
            "        [134,  56,  12,   0,   0,   0]])\n",
            "\n",
            "üìä TensorFlow vs PyTorch Reshaping:\n",
            "   TensorFlow: tf.reshape(x, [3, 4])    PyTorch: x.reshape(3, 4) or x.view(3, 4)\n",
            "   TensorFlow: tf.expand_dims(x, 0)     PyTorch: x.unsqueeze(0)\n",
            "   TensorFlow: tf.squeeze(x, 0)         PyTorch: x.squeeze(0)\n"
          ]
        }
      ],
      "source": [
        "# Tensor shape manipulation\n",
        "print(\"üîÑ Tensor Shape Manipulation: Australian Text Processing\\n\")\n",
        "\n",
        "# Simulate tokenized Australian tourism text\n",
        "# Example: \"Sydney Opera House is beautiful\" ‚Üí token IDs\n",
        "original_tokens = torch.tensor([15, 67, 89, 23, 45, 12, 78, 34, 56, 91, 23, 67])\n",
        "print(f\"Original tokens: {original_tokens}\")\n",
        "print(f\"Shape: {original_tokens.shape} (12 tokens)\")\n",
        "\n",
        "# 1. Reshape to different dimensions\n",
        "print(\"\\nüìê Reshaping Operations:\")\n",
        "\n",
        "# Reshape to 3x4 matrix\n",
        "reshaped_3x4 = original_tokens.reshape(3, 4)\n",
        "print(f\"Reshaped to 3x4:\\n{reshaped_3x4}\")\n",
        "\n",
        "# Reshape to 2x6 matrix\n",
        "reshaped_2x6 = original_tokens.reshape(2, 6)\n",
        "print(f\"\\nReshaped to 2x6:\\n{reshaped_2x6}\")\n",
        "\n",
        "# Use -1 for automatic dimension calculation\n",
        "reshaped_auto = original_tokens.reshape(4, -1)\n",
        "print(f\"\\nReshaped to 4x? (auto-calculated):\\n{reshaped_auto}\")\n",
        "print(f\"Auto shape: {reshaped_auto.shape}\")\n",
        "\n",
        "# 2. Adding dimensions with unsqueeze\n",
        "print(\"\\nüìè Adding Dimensions (unsqueeze):\")\n",
        "\n",
        "# Add batch dimension (common in deep learning)\n",
        "with_batch_dim = original_tokens.unsqueeze(0)\n",
        "print(f\"With batch dimension: {with_batch_dim.shape} (1 √ó 12)\")\n",
        "\n",
        "# Add channel dimension\n",
        "with_channel_dim = original_tokens.unsqueeze(1)\n",
        "print(f\"With channel dimension: {with_channel_dim.shape} (12 √ó 1)\")\n",
        "\n",
        "# 3. Removing dimensions with squeeze\n",
        "print(\"\\nüóúÔ∏è Removing Dimensions (squeeze):\")\n",
        "\n",
        "# Remove the batch dimension\n",
        "squeezed = with_batch_dim.squeeze(0)\n",
        "print(f\"After squeezing batch dim: {squeezed.shape}\")\n",
        "\n",
        "# Practical NLP example: preparing for embedding layer\n",
        "print(\"\\nüí° Practical NLP Example: Preparing for Embedding Layer\")\n",
        "# Simulate batch of sentences with different lengths (padded)\n",
        "batch_sentences = torch.tensor([\n",
        "    [15, 67, 89, 23, 0, 0],    # Sentence 1 (4 real tokens + 2 padding)\n",
        "    [156, 78, 234, 45, 167, 98], # Sentence 2 (6 real tokens)\n",
        "    [134, 56, 12, 0, 0, 0]      # Sentence 3 (3 real tokens + 3 padding)\n",
        "], dtype=torch.long)\n",
        "\n",
        "print(f\"Batch of sentences: {batch_sentences.shape} (batch_size √ó seq_length)\")\n",
        "print(f\"Batch:\\n{batch_sentences}\")\n",
        "\n",
        "print(\"\\nüìä TensorFlow vs PyTorch Reshaping:\")\n",
        "print(\"   TensorFlow: tf.reshape(x, [3, 4])    PyTorch: x.reshape(3, 4) or x.view(3, 4)\")\n",
        "print(\"   TensorFlow: tf.expand_dims(x, 0)     PyTorch: x.unsqueeze(0)\")\n",
        "print(\"   TensorFlow: tf.squeeze(x, 0)         PyTorch: x.squeeze(0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9pYIRGIvd1C"
      },
      "source": [
        "## 5. GPU Acceleration and Device Management\n",
        "\n",
        "Learn how to leverage hardware acceleration by moving tensors between devices (CPU, CUDA, MPS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UryydMgpvd1D"
      },
      "outputs": [],
      "source": [
        "# GPU acceleration and device management\n",
        "print(\"üöÄ GPU Acceleration and Device Management\\n\")\n",
        "\n",
        "# Australian city data for device testing\n",
        "city_data = torch.tensor([5.3, 5.1, 2.6, 2.1, 1.4], dtype=torch.float32)\n",
        "cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\"]\n",
        "\n",
        "print(f\"Original data: {city_data}\")\n",
        "print(f\"Device: {city_data.device}\")\n",
        "print(f\"Data type: {city_data.dtype}\")\n",
        "\n",
        "# Check available devices\n",
        "print(f\"\\nüîç Device Availability:\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if hasattr(torch.backends, 'mps'):\n",
        "    print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
        "else:\n",
        "    print(f\"MPS available: False (not supported in this PyTorch version)\")\n",
        "\n",
        "# Move to different devices\n",
        "print(f\"\\nüì± Moving Tensors Between Devices:\")\n",
        "\n",
        "# Explicit CPU placement\n",
        "cpu_data = city_data.to('cpu')\n",
        "print(f\"CPU data: {cpu_data.device}\")\n",
        "\n",
        "# Try CUDA if available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nüöÄ CUDA GPU available - demonstrating GPU operations:\")\n",
        "    gpu_data = city_data.to('cuda')\n",
        "    print(f\"GPU data device: {gpu_data.device}\")\n",
        "\n",
        "    # Perform computation on GPU\n",
        "    gpu_result = gpu_data * 2 + 1\n",
        "    print(f\"GPU computation result: {gpu_result}\")\n",
        "\n",
        "    # Move back to CPU for display\n",
        "    cpu_result = gpu_result.cpu()\n",
        "    print(f\"Result moved to CPU: {cpu_result}\")\n",
        "\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    print(\"\\nüçé MPS (Apple Silicon) available - demonstrating MPS operations:\")\n",
        "    mps_data = city_data.to('mps')\n",
        "    print(f\"MPS data device: {mps_data.device}\")\n",
        "\n",
        "    # Perform computation on MPS\n",
        "    mps_result = mps_data * 2 + 1\n",
        "    print(f\"MPS computation result: {mps_result}\")\n",
        "\n",
        "    # Move back to CPU for display\n",
        "    cpu_result = mps_result.cpu()\n",
        "    print(f\"Result moved to CPU: {cpu_result}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nüíª No GPU acceleration available - using CPU only\")\n",
        "    print(\"This is normal for most development environments\")\n",
        "\n",
        "# Device-aware tensor creation\n",
        "print(f\"\\nüéØ Device-Aware Tensor Creation:\")\n",
        "device_aware_tensor = torch.randn(3, 4, device=DEVICE)\n",
        "print(f\"Created on {DEVICE}: {device_aware_tensor.device}\")\n",
        "\n",
        "print(\"\\nüí° Best Practices for Device Management:\")\n",
        "print(\"   ‚Ä¢ Always check device availability before using\")\n",
        "print(\"   ‚Ä¢ Move models and data to the same device\")\n",
        "print(\"   ‚Ä¢ Use .to(device) for explicit device placement\")\n",
        "print(\"   ‚Ä¢ Consider memory limitations when using GPU\")\n",
        "\n",
        "print(\"\\nüìä TensorFlow vs PyTorch Device Management:\")\n",
        "print(\"   TensorFlow: with tf.device('/GPU:0'): ...\")\n",
        "print(\"   PyTorch:    tensor.to('cuda')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHjb8SEavd1D"
      },
      "source": [
        "## 6. PyTorch/NumPy Bridge: Seamless Interoperability\n",
        "\n",
        "Discover the powerful integration between PyTorch tensors and NumPy arrays, including memory sharing and conversion methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1B3NfZfYvd1D",
        "outputId": "f06dfe99-989f-4864-fefa-b90b927a0d83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåâ PyTorch/NumPy Bridge: Seamless Interoperability\n",
            "\n",
            "Example: Converting between PyTorch and NumPy for data analysis\n",
            "\n",
            "NumPy array: [8.2 6.7 5.2 2.7 1.8 0.5 0.6 0.4]\n",
            "NumPy dtype: float32\n",
            "NumPy shape: (8,)\n",
            "\n",
            "üì• NumPy ‚Üí PyTorch Conversion:\n",
            "PyTorch tensor: tensor([8.2000, 6.7000, 5.2000, 2.7000, 1.8000, 0.5000, 0.6000, 0.4000])\n",
            "PyTorch dtype: torch.float32\n",
            "PyTorch shape: torch.Size([8])\n",
            "\n",
            "üß† Memory Sharing Check:\n",
            "Shares memory: True\n",
            "Note: from_numpy() creates a tensor that shares memory with the NumPy array\n",
            "\n",
            "Before modification - NumPy[0]: 8.199999809265137, Tensor[0]: 8.199999809265137\n",
            "After modifying NumPy - NumPy[0]: 999.0, Tensor[0]: 999.0\n",
            "\n",
            "üì§ PyTorch ‚Üí NumPy Conversion:\n",
            "Tourism scores (PyTorch): tensor([4.8000, 4.6000, 4.7000, 4.3000, 4.2000, 4.1000, 3.9000, 4.0000])\n",
            "Tourism scores (NumPy): [4.8 4.6 4.7 4.3 4.2 4.1 3.9 4. ]\n",
            "NumPy dtype: float32\n",
            "\n",
            "üîß Device Considerations: CPU vs GPU Tensors\n",
            "CPU tensor: tensor([1., 2., 3., 4.])\n",
            "Device: cpu\n",
            "CPU ‚Üí NumPy: [1. 2. 3. 4.]\n",
            "\n",
            "üíª No GPU/MPS acceleration available - using CPU only\n",
            "\n",
            "‚ö†Ô∏è Important Notes:\n",
            "- NumPy arrays are always on CPU\n",
            "- GPU/MPS tensors must be moved to CPU before .numpy()\n",
            "- from_numpy() always creates CPU tensors\n",
            "- Use .to(device) to move tensors between devices\n",
            "\n",
            "üìä TensorFlow vs PyTorch NumPy Integration:\n",
            "   TensorFlow: tf.convert_to_tensor(numpy_array)\n",
            "   PyTorch:    torch.from_numpy(numpy_array)\n",
            "   TensorFlow: tensor.numpy()\n",
            "   PyTorch:    tensor.numpy()\n"
          ]
        }
      ],
      "source": [
        "# PyTorch/NumPy bridge\n",
        "print(\"üåâ PyTorch/NumPy Bridge: Seamless Interoperability\\n\")\n",
        "\n",
        "# Australian tourism statistics using NumPy arrays\n",
        "print(\"Example: Converting between PyTorch and NumPy for data analysis\\n\")\n",
        "\n",
        "# Start with NumPy array (common in data science)\n",
        "import numpy as np\n",
        "\n",
        "# Australian state populations (millions)\n",
        "state_populations = np.array([8.2, 6.7, 5.2, 2.7, 1.8, 0.5, 0.6, 0.4], dtype=np.float32)\n",
        "states = [\"NSW\", \"VIC\", \"QLD\", \"WA\", \"SA\", \"TAS\", \"ACT\", \"NT\"]\n",
        "\n",
        "print(f\"NumPy array: {state_populations}\")\n",
        "print(f\"NumPy dtype: {state_populations.dtype}\")\n",
        "print(f\"NumPy shape: {state_populations.shape}\")\n",
        "\n",
        "# 1. Convert NumPy to PyTorch with torch.from_numpy()\n",
        "print(\"\\nüì• NumPy ‚Üí PyTorch Conversion:\")\n",
        "\n",
        "pytorch_populations = torch.from_numpy(state_populations)\n",
        "print(f\"PyTorch tensor: {pytorch_populations}\")\n",
        "print(f\"PyTorch dtype: {pytorch_populations.dtype}\")\n",
        "print(f\"PyTorch shape: {pytorch_populations.shape}\")\n",
        "\n",
        "# Check memory sharing\n",
        "print(f\"\\nüß† Memory Sharing Check:\")\n",
        "print(f\"Shares memory: {pytorch_populations.data_ptr() == state_populations.__array_interface__['data'][0]}\")\n",
        "print(\"Note: from_numpy() creates a tensor that shares memory with the NumPy array\")\n",
        "\n",
        "# Demonstrate shared memory\n",
        "original_value = state_populations[0]\n",
        "print(f\"\\nBefore modification - NumPy[0]: {state_populations[0]}, Tensor[0]: {pytorch_populations[0]}\")\n",
        "state_populations[0] = 999  # Modify NumPy array\n",
        "print(f\"After modifying NumPy - NumPy[0]: {state_populations[0]}, Tensor[0]: {pytorch_populations[0]}\")\n",
        "state_populations[0] = original_value  # Restore original value\n",
        "\n",
        "# 2. Convert PyTorch to NumPy with .numpy()\n",
        "print(\"\\nüì§ PyTorch ‚Üí NumPy Conversion:\")\n",
        "\n",
        "# Create PyTorch tensor with tourism data\n",
        "tourism_scores = torch.tensor([4.8, 4.6, 4.7, 4.3, 4.2, 4.1, 3.9, 4.0], dtype=torch.float32)\n",
        "print(f\"Tourism scores (PyTorch): {tourism_scores}\")\n",
        "\n",
        "# Convert to NumPy\n",
        "tourism_numpy = tourism_scores.numpy()\n",
        "print(f\"Tourism scores (NumPy): {tourism_numpy}\")\n",
        "print(f\"NumPy dtype: {tourism_numpy.dtype}\")\n",
        "\n",
        "# 3. Device considerations\n",
        "print(\"\\nüîß Device Considerations: CPU vs GPU Tensors\")\n",
        "\n",
        "# Create tensor on CPU\n",
        "cpu_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0], device='cpu')\n",
        "print(f\"CPU tensor: {cpu_tensor}\")\n",
        "print(f\"Device: {cpu_tensor.device}\")\n",
        "\n",
        "# Convert CPU tensor to NumPy (works directly)\n",
        "cpu_numpy = cpu_tensor.numpy()\n",
        "print(f\"CPU ‚Üí NumPy: {cpu_numpy}\")\n",
        "\n",
        "# Device handling demonstration\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nüöÄ CUDA available - GPU tensor demonstration:\")\n",
        "    gpu_tensor = cpu_tensor.to('cuda')\n",
        "    print(f\"GPU tensor: {gpu_tensor}\")\n",
        "    print(f\"Device: {gpu_tensor.device}\")\n",
        "\n",
        "    # Must move to CPU before converting to NumPy\n",
        "    gpu_to_numpy = gpu_tensor.cpu().numpy()\n",
        "    print(f\"GPU ‚Üí CPU ‚Üí NumPy: {gpu_to_numpy}\")\n",
        "\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    print(\"\\nüçé MPS available - Apple Silicon demonstration:\")\n",
        "    mps_tensor = cpu_tensor.to('mps')\n",
        "    print(f\"MPS tensor: {mps_tensor}\")\n",
        "    print(f\"Device: {mps_tensor.device}\")\n",
        "\n",
        "    # Must move to CPU before converting to NumPy\n",
        "    mps_to_numpy = mps_tensor.cpu().numpy()\n",
        "    print(f\"MPS ‚Üí CPU ‚Üí NumPy: {mps_to_numpy}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nüíª No GPU/MPS acceleration available - using CPU only\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Important Notes:\")\n",
        "print(\"- NumPy arrays are always on CPU\")\n",
        "print(\"- GPU/MPS tensors must be moved to CPU before .numpy()\")\n",
        "print(\"- from_numpy() always creates CPU tensors\")\n",
        "print(\"- Use .to(device) to move tensors between devices\")\n",
        "\n",
        "print(\"\\nüìä TensorFlow vs PyTorch NumPy Integration:\")\n",
        "print(\"   TensorFlow: tf.convert_to_tensor(numpy_array)\")\n",
        "print(\"   PyTorch:    torch.from_numpy(numpy_array)\")\n",
        "print(\"   TensorFlow: tensor.numpy()\")\n",
        "print(\"   PyTorch:    tensor.numpy()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcKGCzXkvd1D"
      },
      "source": [
        "## Summary: PyTorch Tensor Fundamentals\n",
        "\n",
        "Congratulations! You've completed the comprehensive introduction to PyTorch tensors. Let's review what you've learned:\n",
        "\n",
        "### üéØ Key Concepts Mastered\n",
        "\n",
        "1. **Tensor Creation**\n",
        "   - `torch.empty()` for uninitialized tensors\n",
        "   - `torch.zeros()`, `torch.ones()` for initialized tensors\n",
        "   - `torch.randn()`, `torch.rand()` for random tensors\n",
        "   - `torch.manual_seed()` for reproducibility\n",
        "   - \"Like\" methods (`zeros_like()`, `ones_like()`, etc.)\n",
        "   - Creating from Python collections with `torch.tensor()`\n",
        "\n",
        "2. **Tensor Operations**\n",
        "   - Element-wise arithmetic with scalars and tensors\n",
        "   - Broadcasting for operations on different-shaped tensors\n",
        "   - In-place operations with `_` suffix (e.g., `add_()`, `mul_()`)\n",
        "   - Tensor copying with `clone()` and `detach()`\n",
        "\n",
        "3. **Shape Manipulation**\n",
        "   - `reshape()` and `view()` for changing tensor dimensions\n",
        "   - `unsqueeze()` for adding dimensions\n",
        "   - `squeeze()` for removing size-1 dimensions\n",
        "\n",
        "4. **Device Management**\n",
        "   - Device detection (CUDA, MPS, CPU)\n",
        "   - Moving tensors with `.to(device)`\n",
        "   - Device-aware tensor creation\n",
        "\n",
        "5. **NumPy Integration**\n",
        "   - `torch.from_numpy()` for NumPy ‚Üí PyTorch conversion\n",
        "   - `.numpy()` for PyTorch ‚Üí NumPy conversion\n",
        "   - Memory sharing considerations\n",
        "   - Device compatibility with NumPy\n",
        "\n",
        "### üöÄ Next Steps\n",
        "\n",
        "Now that you understand PyTorch tensors, you're ready to:\n",
        "- Build neural networks with `torch.nn`\n",
        "- Implement training loops with automatic differentiation\n",
        "- Work with real datasets using `torch.utils.data`\n",
        "- Explore advanced tensor operations for NLP and computer vision\n",
        "\n",
        "### üìö Additional Resources\n",
        "\n",
        "- [PyTorch Tensor Documentation](https://pytorch.org/docs/stable/tensors.html)\n",
        "- [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
        "- [Australian Tourism Dataset Examples](https://github.com/vuhung16au/pytorch-mastery)\n",
        "\n",
        "### üåü Key Takeaway\n",
        "\n",
        "PyTorch tensors are the foundation of all deep learning operations. Their dynamic nature, device flexibility, and seamless NumPy integration make them powerful tools for research and production. The Australian-themed examples demonstrate how these concepts apply to real-world data processing scenarios.\n",
        "\n",
        "**Happy tensor computing! üéâ**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}