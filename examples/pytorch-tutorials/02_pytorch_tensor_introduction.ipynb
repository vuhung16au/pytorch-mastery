{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor Introduction: Building Blocks of Deep Learning\n",
    "\n",
    "Welcome to the comprehensive introduction to **PyTorch tensors** - the fundamental data structure that powers all computations in PyTorch. This tutorial provides a deep dive into tensor creation, manipulation, and operations, specifically designed for learners transitioning from TensorFlow to PyTorch.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will master:\n",
    "1. **Creating Tensors**: Various factory methods and initialization techniques\n",
    "2. **Tensor Operations**: Arithmetic, broadcasting, and in-place operations\n",
    "3. **Tensor Shapes**: Manipulating dimensions with unsqueeze, squeeze, and reshape\n",
    "4. **GPU Acceleration**: Moving tensors to different devices for hardware acceleration\n",
    "5. **NumPy Bridge**: Seamless interoperability between PyTorch and NumPy\n",
    "\n",
    "## Key Differences: TensorFlow vs PyTorch Tensors\n",
    "| Aspect | TensorFlow | PyTorch |\n",
    "|--------|------------|---------|\n",
    "| **Creation** | `tf.constant([1, 2, 3])` | `torch.tensor([1, 2, 3])` |\n",
    "| **Empty Tensors** | `tf.Variable(tf.zeros([2, 3]))` | `torch.empty(2, 3)` |\n",
    "| **Random** | `tf.random.normal([2, 3])` | `torch.randn(2, 3)` |\n",
    "| **Device** | Automatic distribution | Explicit `.to(device)` |\n",
    "| **NumPy** | `.numpy()` method | Direct `.numpy()` sharing memory |\n",
    "| **Execution** | Graph/Eager modes | Always eager (dynamic) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Runtime Detection\n",
    "\n",
    "Following PyTorch best practices for cross-platform compatibility and device management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    !apt update -qq\n",
    "    !apt install -y -qq software-properties-common\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nSetting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nSetting up local environment...\")\n",
    "\n",
    "# Install required packages for this notebook\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"numpy\",\n",
    "    \"matplotlib\"\n",
    "]\n",
    "\n",
    "print(\"\\nVerifying required packages...\")\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        if package == \"torch\":\n",
    "            import torch\n",
    "            print(f\"\u2713 {package} {torch.__version__}\")\n",
    "        elif package == \"torchvision\":\n",
    "            import torchvision\n",
    "            print(f\"\u2713 {package} {torchvision.__version__}\")\n",
    "        elif package == \"numpy\":\n",
    "            import numpy as np\n",
    "            print(f\"\u2713 {package} {np.__version__}\")\n",
    "        elif package == \"matplotlib\":\n",
    "            import matplotlib\n",
    "            print(f\"\u2713 {package} {matplotlib.__version__}\")\n",
    "    except ImportError:\n",
    "        print(f\"\u274c {package} not found\")\n",
    "        if IS_COLAB or IS_KAGGLE:\n",
    "            !pip install -q {package}\n",
    "        else:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                          capture_output=True)\n",
    "        print(f\"\ud83d\udce6 Installed {package}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries and setup device detection\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "\n",
    "def detect_device():\n",
    "    \"\"\"\n",
    "    Detect the best available PyTorch device with comprehensive hardware support.\n",
    "    \n",
    "    Priority order:\n",
    "    1. CUDA (NVIDIA GPUs) - Best performance for deep learning\n",
    "    2. MPS (Apple Silicon) - Optimized for M1/M2/M3 Macs  \n",
    "    3. CPU (Universal) - Always available fallback\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for PyTorch operations\n",
    "        str: Human-readable device description for logging\n",
    "    \"\"\"\n",
    "    # Check for CUDA (NVIDIA GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        device_info = f\"CUDA GPU: {gpu_name}\"\n",
    "        \n",
    "        cuda_version = torch.version.cuda\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        \n",
    "        print(f\"\ud83d\ude80 Using CUDA acceleration\")\n",
    "        print(f\"   GPU: {gpu_name}\")\n",
    "        print(f\"   CUDA Version: {cuda_version}\")\n",
    "        print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        return device, device_info\n",
    "    \n",
    "    # Check for MPS (Apple Silicon)\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        device_info = \"Apple Silicon MPS\"\n",
    "        \n",
    "        system_info = platform.uname()\n",
    "        \n",
    "        print(f\"\ud83c\udf4e Using Apple Silicon MPS acceleration\")\n",
    "        print(f\"   System: {system_info.system} {system_info.release}\")\n",
    "        print(f\"   Machine: {system_info.machine}\")\n",
    "        \n",
    "        return device, device_info\n",
    "    \n",
    "    # Fallback to CPU\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_info = \"CPU (No GPU acceleration available)\"\n",
    "        \n",
    "        cpu_count = torch.get_num_threads()\n",
    "        system_info = platform.uname()\n",
    "        \n",
    "        print(f\"\ud83d\udcbb Using CPU (no GPU acceleration detected)\")\n",
    "        print(f\"   Processor: {system_info.processor}\")\n",
    "        print(f\"   PyTorch Threads: {cpu_count}\")\n",
    "        print(f\"   System: {system_info.system} {system_info.release}\")\n",
    "        \n",
    "        return device, device_info\n",
    "\n",
    "# Detect and set up device\n",
    "device, device_info = detect_device()\n",
    "\n",
    "print(f\"\\n\u2705 PyTorch {torch.__version__} ready!\")\n",
    "print(f\"\ud83d\udcf1 Device selected: {device}\")\n",
    "print(f\"\ud83d\udcca Device info: {device_info}\")\n",
    "\n",
    "# Set global device for the notebook\n",
    "DEVICE = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Tensors: Factory Methods and Initialization\n",
    "\n",
    "PyTorch provides various methods to create tensors. Let's explore the fundamental tensor creation techniques using Australian tourism data examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic tensor creation with torch.empty()\n",
    "print(\"\ud83d\udce6 1. Basic Tensor Creation with torch.empty()\\n\")\n",
    "\n",
    "# torch.empty() allocates memory without initializing values\n",
    "# Values will be whatever was in memory at the time\n",
    "empty_tensor = torch.empty(3, 4)\n",
    "print(f\"Empty tensor (3x4):\\n{empty_tensor}\")\n",
    "print(f\"Shape: {empty_tensor.shape}\")\n",
    "print(f\"Data type: {empty_tensor.dtype}\")\n",
    "print(f\"Device: {empty_tensor.device}\")\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f  Note: torch.empty() values are uninitialized!\")\n",
    "print(\"   TensorFlow equivalent: tf.Variable(tf.zeros([3, 4])) or tf.empty([3, 4])\")\n",
    "print(\"   Use torch.empty() when you'll immediately fill the tensor with data\")\n",
    "\n",
    "# Compare with TensorFlow approach\n",
    "print(\"\\n\ud83d\udcca TensorFlow vs PyTorch Empty Tensors:\")\n",
    "print(\"   TensorFlow: tf.Variable(tf.zeros([3, 4])) # Usually initialize with zeros\")\n",
    "print(\"   PyTorch:    torch.empty(3, 4)           # Faster, but uninitialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Common factory methods for predictable initialization\n",
    "print(\"\ud83c\udfaf 2. Common Factory Methods: Zeros, Ones, and Random\\n\")\n",
    "\n",
    "# Australian tourism data: visitor counts by state (in thousands)\n",
    "print(\"Example: Australian state tourism visitor data\\n\")\n",
    "\n",
    "# Zeros tensor - useful for initialization\n",
    "visitor_data = torch.zeros(8, 4)  # 8 states/territories, 4 quarters\n",
    "print(f\"Visitor data initialized (8 states \u00d7 4 quarters):\\n{visitor_data}\")\n",
    "print(f\"Shape: {visitor_data.shape}\")\n",
    "\n",
    "# Ones tensor - useful for masks and default weights\n",
    "base_tourism_score = torch.ones(8)  # Base score of 1.0 for each state\n",
    "print(f\"\\nBase tourism scores: {base_tourism_score}\")\n",
    "\n",
    "# Random tensors - crucial for neural network initialization\n",
    "print(\"\\n\ud83c\udfb2 Random Tensor Creation:\")\n",
    "\n",
    "# Set seed for reproducibility in documentation\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Random numbers from normal distribution (mean=0, std=1)\n",
    "weather_variations = torch.randn(8, 12)  # 8 states, 12 months\n",
    "print(f\"Weather variations (normal distribution):\\n{weather_variations[:3, :6]}...\")  # Show subset\n",
    "print(f\"Shape: {weather_variations.shape}\")\n",
    "print(f\"Mean: {weather_variations.mean():.4f} (should be ~0)\")\n",
    "print(f\"Std: {weather_variations.std():.4f} (should be ~1)\")\n",
    "\n",
    "# Random numbers from uniform distribution [0, 1)\n",
    "tourism_ratings = torch.rand(8, 5)  # 8 states, 5 categories\n",
    "print(f\"\\nTourism ratings (uniform [0,1)):\\n{tourism_ratings}\")\n",
    "print(f\"Min: {tourism_ratings.min():.4f}, Max: {tourism_ratings.max():.4f}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca TensorFlow vs PyTorch Random Tensors:\")\n",
    "print(\"   TensorFlow: tf.random.normal([8, 12])    PyTorch: torch.randn(8, 12)\")\n",
    "print(\"   TensorFlow: tf.random.uniform([8, 5])    PyTorch: torch.rand(8, 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tensor Operations: Arithmetic, Broadcasting, and Transformations\n",
    "\n",
    "Explore the rich set of operations available for tensor manipulation, from basic arithmetic to advanced broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Arithmetic operations with scalars\n",
    "print(\"\u2795 1. Arithmetic Operations with Scalars\\n\")\n",
    "\n",
    "# Australian hotel prices per night (AUD)\n",
    "hotel_prices = torch.tensor([150.0, 200.0, 180.0, 220.0, 160.0], dtype=torch.float32)\n",
    "cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\"]\n",
    "\n",
    "print(f\"Original hotel prices (AUD): {hotel_prices}\")\n",
    "print(f\"Cities: {cities}\")\n",
    "\n",
    "# Scalar arithmetic - operations apply element-wise\n",
    "gst_rate = 0.1  # 10% GST in Australia\n",
    "discount = 20.0  # $20 discount\n",
    "\n",
    "# Addition and subtraction\n",
    "discounted_prices = hotel_prices - discount\n",
    "print(f\"\\nAfter $20 discount: {discounted_prices}\")\n",
    "\n",
    "# Multiplication and division\n",
    "prices_with_gst = hotel_prices * (1 + gst_rate)\n",
    "print(f\"With 10% GST: {prices_with_gst}\")\n",
    "\n",
    "weekly_prices = hotel_prices * 7\n",
    "print(f\"Weekly rates (\u00d77): {weekly_prices}\")\n",
    "\n",
    "# Mathematical functions\n",
    "log_prices = torch.log(hotel_prices)  # Natural logarithm\n",
    "rounded_prices = torch.round(prices_with_gst)\n",
    "\n",
    "print(f\"\\nLog prices: {log_prices}\")\n",
    "print(f\"Rounded GST prices: {rounded_prices}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca TensorFlow equivalent operations:\")\n",
    "print(\"   TensorFlow: tf.add(prices, -20)     PyTorch: prices - 20\")\n",
    "print(\"   TensorFlow: tf.multiply(prices, 1.1) PyTorch: prices * 1.1\")\n",
    "print(\"   TensorFlow: tf.math.log(prices)     PyTorch: torch.log(prices)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tensor Shapes and Dimensions\n",
    "\n",
    "Learn how to manipulate tensor shapes using unsqueeze, squeeze, and reshape operations - essential for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor shape manipulation\n",
    "print(\"\ud83d\udd04 Tensor Shape Manipulation: Australian Text Processing\\n\")\n",
    "\n",
    "# Simulate tokenized Australian tourism text\n",
    "# Example: \"Sydney Opera House is beautiful\" \u2192 token IDs\n",
    "original_tokens = torch.tensor([15, 67, 89, 23, 45, 12, 78, 34, 56, 91, 23, 67])\n",
    "print(f\"Original tokens: {original_tokens}\")\n",
    "print(f\"Shape: {original_tokens.shape} (12 tokens)\")\n",
    "\n",
    "# 1. Reshape to different dimensions\n",
    "print(\"\\n\ud83d\udcd0 Reshaping Operations:\")\n",
    "\n",
    "# Reshape to 3x4 matrix\n",
    "reshaped_3x4 = original_tokens.reshape(3, 4)\n",
    "print(f\"Reshaped to 3x4:\\n{reshaped_3x4}\")\n",
    "\n",
    "# Reshape to 2x6 matrix\n",
    "reshaped_2x6 = original_tokens.reshape(2, 6)\n",
    "print(f\"\\nReshaped to 2x6:\\n{reshaped_2x6}\")\n",
    "\n",
    "# Use -1 for automatic dimension calculation\n",
    "reshaped_auto = original_tokens.reshape(4, -1)\n",
    "print(f\"\\nReshaped to 4x? (auto-calculated):\\n{reshaped_auto}\")\n",
    "print(f\"Auto shape: {reshaped_auto.shape}\")\n",
    "\n",
    "# 2. Adding dimensions with unsqueeze\n",
    "print(\"\\n\ud83d\udccf Adding Dimensions (unsqueeze):\")\n",
    "\n",
    "# Add batch dimension (common in deep learning)\n",
    "with_batch_dim = original_tokens.unsqueeze(0)\n",
    "print(f\"With batch dimension: {with_batch_dim.shape} (1 \u00d7 12)\")\n",
    "\n",
    "# Add channel dimension\n",
    "with_channel_dim = original_tokens.unsqueeze(1)\n",
    "print(f\"With channel dimension: {with_channel_dim.shape} (12 \u00d7 1)\")\n",
    "\n",
    "# 3. Removing dimensions with squeeze\n",
    "print(\"\\n\ud83d\udddc\ufe0f Removing Dimensions (squeeze):\")\n",
    "\n",
    "# Remove the batch dimension\n",
    "squeezed = with_batch_dim.squeeze(0)\n",
    "print(f\"After squeezing batch dim: {squeezed.shape}\")\n",
    "\n",
    "# Practical NLP example: preparing for embedding layer\n",
    "print(\"\\n\ud83d\udca1 Practical NLP Example: Preparing for Embedding Layer\")\n",
    "# Simulate batch of sentences with different lengths (padded)\n",
    "batch_sentences = torch.tensor([\n",
    "    [15, 67, 89, 23, 0, 0],    # Sentence 1 (4 real tokens + 2 padding)\n",
    "    [156, 78, 234, 45, 167, 98], # Sentence 2 (6 real tokens)\n",
    "    [134, 56, 12, 0, 0, 0]      # Sentence 3 (3 real tokens + 3 padding)\n",
    "], dtype=torch.long)\n",
    "\n",
    "print(f\"Batch of sentences: {batch_sentences.shape} (batch_size \u00d7 seq_length)\")\n",
    "print(f\"Batch:\\n{batch_sentences}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca TensorFlow vs PyTorch Reshaping:\")\n",
    "print(\"   TensorFlow: tf.reshape(x, [3, 4])    PyTorch: x.reshape(3, 4) or x.view(3, 4)\")\n",
    "print(\"   TensorFlow: tf.expand_dims(x, 0)     PyTorch: x.unsqueeze(0)\")\n",
    "print(\"   TensorFlow: tf.squeeze(x, 0)         PyTorch: x.squeeze(0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GPU Acceleration and Device Management\n",
    "\n",
    "Learn how to leverage hardware acceleration by moving tensors between devices (CPU, CUDA, MPS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU acceleration and device management\n",
    "print(\"\ud83d\ude80 GPU Acceleration and Device Management\\n\")\n",
    "\n",
    "# Australian city data for device testing\n",
    "city_data = torch.tensor([5.3, 5.1, 2.6, 2.1, 1.4], dtype=torch.float32)\n",
    "cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\"]\n",
    "\n",
    "print(f\"Original data: {city_data}\")\n",
    "print(f\"Device: {city_data.device}\")\n",
    "print(f\"Data type: {city_data.dtype}\")\n",
    "\n",
    "# Check available devices\n",
    "print(f\"\\n\ud83d\udd0d Device Availability:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if hasattr(torch.backends, 'mps'):\n",
    "    print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "else:\n",
    "    print(f\"MPS available: False (not supported in this PyTorch version)\")\n",
    "\n",
    "# Move to different devices\n",
    "print(f\"\\n\ud83d\udcf1 Moving Tensors Between Devices:\")\n",
    "\n",
    "# Explicit CPU placement\n",
    "cpu_data = city_data.to('cpu')\n",
    "print(f\"CPU data: {cpu_data.device}\")\n",
    "\n",
    "# Try CUDA if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\ud83d\ude80 CUDA GPU available - demonstrating GPU operations:\")\n",
    "    gpu_data = city_data.to('cuda')\n",
    "    print(f\"GPU data device: {gpu_data.device}\")\n",
    "    \n",
    "    # Perform computation on GPU\n",
    "    gpu_result = gpu_data * 2 + 1\n",
    "    print(f\"GPU computation result: {gpu_result}\")\n",
    "    \n",
    "    # Move back to CPU for display\n",
    "    cpu_result = gpu_result.cpu()\n",
    "    print(f\"Result moved to CPU: {cpu_result}\")\n",
    "    \n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"\\n\ud83c\udf4e MPS (Apple Silicon) available - demonstrating MPS operations:\")\n",
    "    mps_data = city_data.to('mps')\n",
    "    print(f\"MPS data device: {mps_data.device}\")\n",
    "    \n",
    "    # Perform computation on MPS\n",
    "    mps_result = mps_data * 2 + 1\n",
    "    print(f\"MPS computation result: {mps_result}\")\n",
    "    \n",
    "    # Move back to CPU for display\n",
    "    cpu_result = mps_result.cpu()\n",
    "    print(f\"Result moved to CPU: {cpu_result}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n\ud83d\udcbb No GPU acceleration available - using CPU only\")\n",
    "    print(\"This is normal for most development environments\")\n",
    "    \n",
    "# Device-aware tensor creation\n",
    "print(f\"\\n\ud83c\udfaf Device-Aware Tensor Creation:\")\n",
    "device_aware_tensor = torch.randn(3, 4, device=DEVICE)\n",
    "print(f\"Created on {DEVICE}: {device_aware_tensor.device}\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Best Practices for Device Management:\")\n",
    "print(\"   \u2022 Always check device availability before using\")\n",
    "print(\"   \u2022 Move models and data to the same device\")\n",
    "print(\"   \u2022 Use .to(device) for explicit device placement\")\n",
    "print(\"   \u2022 Consider memory limitations when using GPU\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca TensorFlow vs PyTorch Device Management:\")\n",
    "print(\"   TensorFlow: with tf.device('/GPU:0'): ...\")\n",
    "print(\"   PyTorch:    tensor.to('cuda')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PyTorch/NumPy Bridge: Seamless Interoperability\n",
    "\n",
    "Discover the powerful integration between PyTorch tensors and NumPy arrays, including memory sharing and conversion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch/NumPy bridge\n",
    "print(\"\ud83c\udf09 PyTorch/NumPy Bridge: Seamless Interoperability\\n\")\n",
    "\n",
    "# Australian tourism statistics using NumPy arrays\n",
    "print(\"Example: Converting between PyTorch and NumPy for data analysis\\n\")\n",
    "\n",
    "# Start with NumPy array (common in data science)\n",
    "import numpy as np\n",
    "\n",
    "# Australian state populations (millions)\n",
    "state_populations = np.array([8.2, 6.7, 5.2, 2.7, 1.8, 0.5, 0.6, 0.4], dtype=np.float32)\n",
    "states = [\"NSW\", \"VIC\", \"QLD\", \"WA\", \"SA\", \"TAS\", \"ACT\", \"NT\"]\n",
    "\n",
    "print(f\"NumPy array: {state_populations}\")\n",
    "print(f\"NumPy dtype: {state_populations.dtype}\")\n",
    "print(f\"NumPy shape: {state_populations.shape}\")\n",
    "\n",
    "# 1. Convert NumPy to PyTorch with torch.from_numpy()\n",
    "print(\"\\n\ud83d\udce5 NumPy \u2192 PyTorch Conversion:\")\n",
    "\n",
    "pytorch_populations = torch.from_numpy(state_populations)\n",
    "print(f\"PyTorch tensor: {pytorch_populations}\")\n",
    "print(f\"PyTorch dtype: {pytorch_populations.dtype}\")\n",
    "print(f\"PyTorch shape: {pytorch_populations.shape}\")\n",
    "\n",
    "# Check memory sharing\n",
    "print(f\"\\n\ud83e\udde0 Memory Sharing Check:\")\n",
    "print(f\"Shares memory: {pytorch_populations.data_ptr() == state_populations.__array_interface__['data'][0]}\")\n",
    "print(\"Note: from_numpy() creates a tensor that shares memory with the NumPy array\")\n",
    "\n",
    "# Demonstrate shared memory\n",
    "original_value = state_populations[0]\n",
    "print(f\"\\nBefore modification - NumPy[0]: {state_populations[0]}, Tensor[0]: {pytorch_populations[0]}\")\n",
    "state_populations[0] = 999  # Modify NumPy array\n",
    "print(f\"After modifying NumPy - NumPy[0]: {state_populations[0]}, Tensor[0]: {pytorch_populations[0]}\")\n",
    "state_populations[0] = original_value  # Restore original value\n",
    "\n",
    "# 2. Convert PyTorch to NumPy with .numpy()\n",
    "print(\"\\n\ud83d\udce4 PyTorch \u2192 NumPy Conversion:\")\n",
    "\n",
    "# Create PyTorch tensor with tourism data\n",
    "tourism_scores = torch.tensor([4.8, 4.6, 4.7, 4.3, 4.2, 4.1, 3.9, 4.0], dtype=torch.float32)\n",
    "print(f\"Tourism scores (PyTorch): {tourism_scores}\")\n",
    "\n",
    "# Convert to NumPy\n",
    "tourism_numpy = tourism_scores.numpy()\n",
    "print(f\"Tourism scores (NumPy): {tourism_numpy}\")\n",
    "print(f\"NumPy dtype: {tourism_numpy.dtype}\")\n",
    "\n",
    "# 3. Device considerations\n",
    "print(\"\\n\ud83d\udd27 Device Considerations: CPU vs GPU Tensors\")\n",
    "\n",
    "# Create tensor on CPU\n",
    "cpu_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0], device='cpu')\n",
    "print(f\"CPU tensor: {cpu_tensor}\")\n",
    "print(f\"Device: {cpu_tensor.device}\")\n",
    "\n",
    "# Convert CPU tensor to NumPy (works directly)\n",
    "cpu_numpy = cpu_tensor.numpy()\n",
    "print(f\"CPU \u2192 NumPy: {cpu_numpy}\")\n",
    "\n",
    "# Device handling demonstration\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\ud83d\ude80 CUDA available - GPU tensor demonstration:\")\n",
    "    gpu_tensor = cpu_tensor.to('cuda')\n",
    "    print(f\"GPU tensor: {gpu_tensor}\")\n",
    "    print(f\"Device: {gpu_tensor.device}\")\n",
    "    \n",
    "    # Must move to CPU before converting to NumPy\n",
    "    gpu_to_numpy = gpu_tensor.cpu().numpy()\n",
    "    print(f\"GPU \u2192 CPU \u2192 NumPy: {gpu_to_numpy}\")\n",
    "    \n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"\\n\ud83c\udf4e MPS available - Apple Silicon demonstration:\")\n",
    "    mps_tensor = cpu_tensor.to('mps')\n",
    "    print(f\"MPS tensor: {mps_tensor}\")\n",
    "    print(f\"Device: {mps_tensor.device}\")\n",
    "    \n",
    "    # Must move to CPU before converting to NumPy\n",
    "    mps_to_numpy = mps_tensor.cpu().numpy()\n",
    "    print(f\"MPS \u2192 CPU \u2192 NumPy: {mps_to_numpy}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n\ud83d\udcbb No GPU/MPS acceleration available - using CPU only\")\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f Important Notes:\")\n",
    "print(\"- NumPy arrays are always on CPU\")\n",
    "print(\"- GPU/MPS tensors must be moved to CPU before .numpy()\")\n",
    "print(\"- from_numpy() always creates CPU tensors\")\n",
    "print(\"- Use .to(device) to move tensors between devices\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca TensorFlow vs PyTorch NumPy Integration:\")\n",
    "print(\"   TensorFlow: tf.convert_to_tensor(numpy_array)\")\n",
    "print(\"   PyTorch:    torch.from_numpy(numpy_array)\")\n",
    "print(\"   TensorFlow: tensor.numpy()\")\n",
    "print(\"   PyTorch:    tensor.numpy()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: PyTorch Tensor Fundamentals\n",
    "\n",
    "Congratulations! You've completed the comprehensive introduction to PyTorch tensors. Let's review what you've learned:\n",
    "\n",
    "### \ud83c\udfaf Key Concepts Mastered\n",
    "\n",
    "1. **Tensor Creation**\n",
    "   - `torch.empty()` for uninitialized tensors\n",
    "   - `torch.zeros()`, `torch.ones()` for initialized tensors\n",
    "   - `torch.randn()`, `torch.rand()` for random tensors\n",
    "   - `torch.manual_seed()` for reproducibility\n",
    "   - \"Like\" methods (`zeros_like()`, `ones_like()`, etc.)\n",
    "   - Creating from Python collections with `torch.tensor()`\n",
    "\n",
    "2. **Tensor Operations**\n",
    "   - Element-wise arithmetic with scalars and tensors\n",
    "   - Broadcasting for operations on different-shaped tensors\n",
    "   - In-place operations with `_` suffix (e.g., `add_()`, `mul_()`)\n",
    "   - Tensor copying with `clone()` and `detach()`\n",
    "\n",
    "3. **Shape Manipulation**\n",
    "   - `reshape()` and `view()` for changing tensor dimensions\n",
    "   - `unsqueeze()` for adding dimensions\n",
    "   - `squeeze()` for removing size-1 dimensions\n",
    "\n",
    "4. **Device Management**\n",
    "   - Device detection (CUDA, MPS, CPU)\n",
    "   - Moving tensors with `.to(device)`\n",
    "   - Device-aware tensor creation\n",
    "\n",
    "5. **NumPy Integration**\n",
    "   - `torch.from_numpy()` for NumPy \u2192 PyTorch conversion\n",
    "   - `.numpy()` for PyTorch \u2192 NumPy conversion\n",
    "   - Memory sharing considerations\n",
    "   - Device compatibility with NumPy\n",
    "\n",
    "### \ud83d\ude80 Next Steps\n",
    "\n",
    "Now that you understand PyTorch tensors, you're ready to:\n",
    "- Build neural networks with `torch.nn`\n",
    "- Implement training loops with automatic differentiation\n",
    "- Work with real datasets using `torch.utils.data`\n",
    "- Explore advanced tensor operations for NLP and computer vision\n",
    "\n",
    "### \ud83d\udcda Additional Resources\n",
    "\n",
    "- [PyTorch Tensor Documentation](https://pytorch.org/docs/stable/tensors.html)\n",
    "- [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
    "- [Australian Tourism Dataset Examples](https://github.com/vuhung16au/pytorch-mastery)\n",
    "\n",
    "### \ud83c\udf1f Key Takeaway\n",
    "\n",
    "PyTorch tensors are the foundation of all deep learning operations. Their dynamic nature, device flexibility, and seamless NumPy integration make them powerful tools for research and production. The Australian-themed examples demonstrate how these concepts apply to real-world data processing scenarios.\n",
    "\n",
    "**Happy tensor computing! \ud83c\udf89**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}