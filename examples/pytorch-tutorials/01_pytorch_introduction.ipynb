{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch: From Research to Production\n",
    "\n",
    "This comprehensive notebook introduces PyTorch fundamentals, covering everything from basic tensors to production deployment. Based on the PyTorch Introduction video by Brad Heinz, this tutorial is designed for learners transitioning from TensorFlow to PyTorch, with a focus on NLP applications and Australian-themed examples.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "- **PyTorch Overview**: Key features, ecosystem, and advantages\n",
    "- **Tensors**: Core data abstraction and operations (300+ mathematical operations)\n",
    "- **Autograd**: Automatic differentiation engine for gradient computation\n",
    "- **Neural Networks**: Building models with `nn.Module` (LeNet-5 example)\n",
    "- **Data Loading**: Efficient data processing with Dataset and DataLoader\n",
    "- **Training Loops**: Manual training vs TensorFlow's `model.fit()`\n",
    "- **TorchScript**: Model deployment and production optimization\n",
    "\n",
    "## Key Differences from TensorFlow\n",
    "| Aspect | TensorFlow | PyTorch |\n",
    "|--------|------------|---------|\n",
    "| **Execution** | Graph-based (TF 1.x) or Eager (TF 2.x) | Always eager (dynamic graphs) |\n",
    "| **Model Definition** | `tf.keras.Sequential` or Functional API | `nn.Module` subclass |\n",
    "| **Training** | `model.fit()` | Manual training loops |\n",
    "| **Autograd** | `tf.GradientTape` | Automatic with `.backward()` |\n",
    "| **Device Management** | Automatic with strategies | Explicit `.to(device)` |\n",
    "\n",
    "## Australian Context Examples\n",
    "Throughout this notebook, we'll use Australian tourism, city data, and English-Vietnamese language pairs to demonstrate PyTorch concepts in practical, relatable contexts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Runtime Detection\n",
    "\n",
    "Following PyTorch best practices for cross-platform compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"üåê Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nüîß Setting up Google Colab environment...\")\n",
    "    # Colab usually has PyTorch pre-installed\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nüîß Setting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nüîß Setting up local environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages based on platform\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"matplotlib\",\n",
    "    \"tensorboard\"\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        # Use IPython magic commands for notebook environments\n",
    "        try:\n",
    "            exec(f\"!pip install -q {package}\")\n",
    "            print(f\"‚úÖ {package}\")\n",
    "        except:\n",
    "            print(f\"‚ö†Ô∏è {package} (may already be installed)\")\n",
    "    else:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                          capture_output=True, check=True)\n",
    "            print(f\"‚úÖ {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"‚ö†Ô∏è {package} (may already be installed)\")\n",
    "\n",
    "print(\"\\nüéâ Package installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify PyTorch installation and import core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "\n",
    "print(f\"üî• PyTorch {torch.__version__} ready!\")\n",
    "print(f\"üñ•Ô∏è CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"üéØ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Set device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nüíæ Using device: {device}\")\n",
    "\n",
    "# Store device info for later use\n",
    "DEVICE = device\n",
    "DEVICE_INFO = f\"{'CUDA GPU' if torch.cuda.is_available() else 'CPU'}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch Overview and Key Features\n",
    "\n",
    "PyTorch is an open-source machine learning framework that accelerates the path from research prototyping to production deployment. Let's explore its key features and ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî• PyTorch: Open-source ML Framework\\n\")\n",
    "\n",
    "print(\"üõ†Ô∏è Key Features:\")\n",
    "features = [\n",
    "    \"Comprehensive toolkit for ML applications\",\n",
    "    \"Deep learning primitives (layers, activations, optimizers)\", \n",
    "    \"Hardware acceleration (CUDA GPUs, Apple Silicon MPS)\",\n",
    "    \"Rich ecosystem: torchvision, torchtext, torchaudio\",\n",
    "    \"Fast iteration with 'Define-by-Run' paradigm\",\n",
    "    \"Automatic differentiation (autograd) engine\",\n",
    "    \"Enterprise tools: TorchScript, TorchServe, quantization\",\n",
    "    \"Open source with large community\"\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "\n",
    "print(\"\\nüåü Why PyTorch for NLP and Australian Applications:\")\n",
    "print(\"  ‚Ä¢ Hugging Face ecosystem: State-of-the-art NLP models\")\n",
    "print(\"  ‚Ä¢ Research-friendly: Most academic papers use PyTorch\") \n",
    "print(\"  ‚Ä¢ Dynamic graphs: Perfect for variable-length text\")\n",
    "print(\"  ‚Ä¢ Memory sharing with NumPy: Efficient data processing\")\n",
    "print(\"  ‚Ä¢ Community projects: AllenNLP, ClassyVision, Captum\")\n",
    "\n",
    "print(\"\\nüöÄ Used by top companies: Facebook, Tesla, OpenAI, Netflix\")\n",
    "\n",
    "print(\"\\nüìä Ecosystem Overview:\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  Available on device: {DEVICE}\")\n",
    "print(f\"  Device info: {DEVICE_INFO}\")\n",
    "print(f\"  TorchVision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tensors: The Core Data Abstraction\n",
    "\n",
    "Tensors are central to everything in PyTorch. They are multi-dimensional arrays with extra capabilities, supporting over 300 mathematical and logical operations. Although accessed through Python, computations are performed in optimized C++ code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßÆ PyTorch Tensors: Multi-dimensional Arrays with Superpowers\\n\")\n",
    "\n",
    "# Create tensors with Australian tourism data\n",
    "print(\"üèñÔ∏è Creating Tensors: Australian Tourism Data\\n\")\n",
    "\n",
    "# Tourist visitor numbers (millions) for major Australian cities\n",
    "# Cities: Sydney, Melbourne, Brisbane, Perth, Adelaide\n",
    "tourist_visitors = torch.tensor([4.6, 3.2, 2.8, 1.4, 1.1], dtype=torch.float32)\n",
    "print(f\"Tourist visitors (millions): {tourist_visitors}\")\n",
    "print(f\"Tensor shape: {tourist_visitors.shape}\")\n",
    "print(f\"Data type: {tourist_visitors.dtype}\")\n",
    "print(f\"Device: {tourist_visitors.device}\")\n",
    "\n",
    "# 2D tensor: Tourism spending by category and city\n",
    "# Rows: Cities (Sydney, Melbourne, Brisbane)\n",
    "# Columns: Categories (Accommodation, Food, Transport, Activities)\n",
    "tourism_spending = torch.tensor([\n",
    "    [180.5, 85.2, 45.7, 120.0],  # Sydney\n",
    "    [165.0, 95.5, 38.2, 110.5],  # Melbourne  \n",
    "    [145.8, 75.3, 42.1, 95.0]    # Brisbane\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(f\"\\nTourism spending matrix: {tourism_spending.shape}\")\n",
    "print(tourism_spending)\n",
    "\n",
    "# Tensor operations with Australian weather data\n",
    "cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\"]\n",
    "summer_temps = torch.tensor([26.5, 25.5, 28.0, 30.5, 28.5], dtype=torch.float32)\n",
    "winter_temps = torch.tensor([17.0, 14.0, 21.0, 18.5, 15.5], dtype=torch.float32)\n",
    "\n",
    "print(f\"\\nüå§Ô∏è Tensor Operations: Australian Weather Analysis\")\n",
    "print(f\"Summer temperatures: {summer_temps}\")\n",
    "print(f\"Winter temperatures: {winter_temps}\")\n",
    "\n",
    "# Arithmetic operations (over 300 available!)\n",
    "temp_difference = summer_temps - winter_temps\n",
    "avg_temp = (summer_temps + winter_temps) / 2\n",
    "temp_range = torch.abs(temp_difference)\n",
    "\n",
    "print(f\"\\nTemperature differences: {temp_difference}\")\n",
    "print(f\"Average temperatures: {avg_temp}\")\n",
    "print(f\"Temperature ranges: {temp_range}\")\n",
    "\n",
    "# Statistical operations  \n",
    "print(f\"\\nüìà Statistical Analysis (PyTorch's 300+ operations):\")\n",
    "print(f\"Hottest summer city: {cities[torch.argmax(summer_temps)]} ({torch.max(summer_temps):.1f}¬∞C)\")\n",
    "print(f\"Coldest winter city: {cities[torch.argmin(winter_temps)]} ({torch.min(winter_temps):.1f}¬∞C)\")\n",
    "print(f\"Mean summer temp: {torch.mean(summer_temps):.1f}¬∞C\")\n",
    "print(f\"Std dev: {torch.std(summer_temps):.1f}¬∞C\")\n",
    "\n",
    "# TensorFlow comparison\n",
    "print(\"\\nüìä TensorFlow vs PyTorch Tensor Creation:\")\n",
    "print(\"   TensorFlow: tf.constant([1, 2, 3], dtype=tf.float32)\")\n",
    "print(\"   PyTorch:    torch.tensor([1, 2, 3], dtype=torch.float32)\")\n",
    "print(\"   TensorFlow: tf.zeros([2, 3])\")\n",
    "print(\"   PyTorch:    torch.zeros(2, 3)\")\n",
    "print(\"   TensorFlow: tf.random.normal([2, 3])\")\n",
    "print(\"   PyTorch:    torch.randn(2, 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Autograd: Automatic Differentiation Engine\n",
    "\n",
    "The autograd engine drives eager mode computation and enables rapid model iteration. It automatically computes gradients using the chain rule by tracking tensor operations in a Directed Acyclic Graph (DAG). This is what makes the `.backward()` call so powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° Autograd: Automatic Differentiation in Action\\n\")\n",
    "\n",
    "# Simple RNN example (as described in the video)\n",
    "print(\"üß† Simple RNN Forward Pass + Autograd (from the video)\\n\")\n",
    "\n",
    "torch.manual_seed(42)  # Reproducibility\n",
    "\n",
    "# RNN parameters (requires_grad=True for gradient computation)\n",
    "input_size = 5  # Australian city features\n",
    "hidden_size = 8\n",
    "output_size = 3  # Sydney, Melbourne, Brisbane\n",
    "\n",
    "# Learnable weights (like the RNN example from the video)\n",
    "W_input = torch.randn(hidden_size, input_size, requires_grad=True)\n",
    "W_hidden = torch.randn(hidden_size, hidden_size, requires_grad=True)\n",
    "W_output = torch.randn(output_size, hidden_size, requires_grad=True)\n",
    "b_hidden = torch.randn(hidden_size, requires_grad=True)\n",
    "b_output = torch.randn(output_size, requires_grad=True)\n",
    "\n",
    "# Sample input: [population_mil, avg_temp, tourism_mil, coastal, wine_region]\n",
    "# Sydney example\n",
    "x = torch.tensor([5.3, 21.8, 4.6, 1.0, 0.0])  # Sydney features\n",
    "h_prev = torch.zeros(hidden_size)  # Initial hidden state\n",
    "\n",
    "print(f\"Input features (Sydney): {x}\")\n",
    "print(f\"Feature meanings: [population_mil, avg_temp, tourism_mil, coastal, wine_region]\")\n",
    "\n",
    "# Forward pass (exactly like the RNN example in the video)\n",
    "h_input = torch.matmul(W_input, x)  # Input transformation\n",
    "h_hidden = torch.matmul(W_hidden, h_prev)  # Hidden state transformation\n",
    "h_combined = h_input + h_hidden + b_hidden  # Combine\n",
    "h_new = torch.tanh(h_combined)  # Activation (hyperbolic tangent)\n",
    "\n",
    "# Output layer\n",
    "output = torch.matmul(W_output, h_new) + b_output\n",
    "probabilities = torch.softmax(output, dim=0)\n",
    "\n",
    "# Target (correct city: Sydney = index 0)\n",
    "target = torch.tensor([1.0, 0.0, 0.0])  # One-hot encoding for Sydney\n",
    "loss = torch.nn.functional.cross_entropy(output.unsqueeze(0), torch.tensor([0]))\n",
    "\n",
    "print(f\"\\nPredicted probabilities: {probabilities}\")\n",
    "print(f\"City predictions: Sydney={probabilities[0]:.3f}, Melbourne={probabilities[1]:.3f}, Brisbane={probabilities[2]:.3f}\")\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# The magic: compute all gradients with one line (as shown in the video)\n",
    "print(f\"\\n‚ö° Computing gradients with ONE line: loss.backward()\")\n",
    "loss.backward()\n",
    "\n",
    "print(f\"\\nüìà Autograd computed gradients for ALL parameters automatically!\")\n",
    "print(f\"W_input gradient norm: {W_input.grad.norm().item():.4f}\")\n",
    "print(f\"W_hidden gradient norm: {W_hidden.grad.norm().item():.4f}\")\n",
    "print(f\"W_output gradient norm: {W_output.grad.norm().item():.4f}\")\n",
    "\n",
    "print(f\"\\nüîß This enables training: adjust weights opposite to gradients\")\n",
    "print(f\"üéØ Key insight: PyTorch tracks every operation to build computation graph\")\n",
    "print(f\"üìä DAG (Directed Acyclic Graph) enables flexible model architectures\")\n",
    "\n",
    "print(f\"\\nüîç TensorFlow vs PyTorch Gradients:\")\n",
    "print(f\"   TensorFlow: with tf.GradientTape() as tape: ...\")\n",
    "print(f\"   PyTorch:    loss.backward()  # Automatic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TensorBoard Setup for Training Monitoring\n",
    "\n",
    "PyTorch requires explicit TensorBoard setup (unlike TensorFlow's integrated callbacks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform-specific TensorBoard log directory setup\n",
    "def get_run_logdir(name=\"cifar10_training\"):\n",
    "    \"\"\"Create unique log directory for this training run.\"\"\"\n",
    "    if IS_COLAB:\n",
    "        root_logdir = \"/content/tensorboard_logs\"\n",
    "    elif IS_KAGGLE:\n",
    "        root_logdir = \"./tensorboard_logs\"\n",
    "    else:\n",
    "        root_logdir = \"./tensorboard_logs\"\n",
    "    \n",
    "    # Create root directory if it doesn't exist\n",
    "    os.makedirs(root_logdir, exist_ok=True)\n",
    "    \n",
    "    # Generate unique run directory\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    run_logdir = os.path.join(root_logdir, f\"{name}_{timestamp}\")\n",
    "    return run_logdir\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "log_dir = get_run_logdir(\"hello_pytorch_cifar\")\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"üìä TensorBoard logs will be saved to: {log_dir}\")\n",
    "print(f\"üí° To view logs, run: tensorboard --logdir={log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing\n",
    "\n",
    "**Key Difference from TensorFlow**: PyTorch uses explicit transforms and DataLoader objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations for training and testing\n",
    "# TensorFlow equivalent: tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Data augmentation\n",
    "    transforms.ToTensor(),                   # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # CIFAR-10 statistics\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-10 dataset\n",
    "print(\"üì• Loading CIFAR-10 dataset...\")\n",
    "\n",
    "try:\n",
    "    # Try to download CIFAR-10 dataset (requires internet)\n",
    "    print(\"üåê Attempting to download CIFAR-10 dataset...\")\n",
    "    \n",
    "    # Training dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=True, \n",
    "        download=True, \n",
    "        transform=transform_train\n",
    "    )\n",
    "    \n",
    "    # Test dataset\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=False, \n",
    "        download=True, \n",
    "        transform=transform_test\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ CIFAR-10 dataset downloaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Cannot download CIFAR-10 dataset: {type(e).__name__}\")\n",
    "    print(\"üîÑ Creating synthetic dataset for demonstration purposes...\")\n",
    "    \n",
    "    # Create synthetic CIFAR-10-like dataset for demo when offline\n",
    "    from torch.utils.data import TensorDataset\n",
    "    \n",
    "    # Generate synthetic data: 32x32 RGB images\n",
    "    synthetic_train_images = torch.randn(1000, 3, 32, 32)  # 1000 training samples\n",
    "    synthetic_train_labels = torch.randint(0, 10, (1000,))  # Random labels 0-9\n",
    "    \n",
    "    synthetic_test_images = torch.randn(200, 3, 32, 32)   # 200 test samples  \n",
    "    synthetic_test_labels = torch.randint(0, 10, (200,))   # Random labels 0-9\n",
    "    \n",
    "    # Apply transformations manually to synthetic data\n",
    "    # Normalize using CIFAR-10 statistics\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "    \n",
    "    synthetic_train_images = (synthetic_train_images - mean) / std\n",
    "    synthetic_test_images = (synthetic_test_images - mean) / std\n",
    "    \n",
    "    # Create tensor datasets\n",
    "    trainset = TensorDataset(synthetic_train_images, synthetic_train_labels)\n",
    "    testset = TensorDataset(synthetic_test_images, synthetic_test_labels)\n",
    "    \n",
    "    print(\"‚úÖ Synthetic dataset created for demonstration!\")\n",
    "    print(\"üìù Note: This is random data, not real CIFAR-10 images\")\n",
    "\n",
    "# Data loaders (equivalent to TensorFlow's tf.data.Dataset)\n",
    "batch_size = 32  # Small batch size for educational purposes\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,      # Shuffle training data\n",
    "    num_workers=0      # Use 0 for synthetic data to avoid pickling issues\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,     # Don't shuffle test data\n",
    "    num_workers=0      # Use 0 for synthetic data to avoid pickling issues\n",
    ")\n",
    "\n",
    "# CIFAR-10 class names\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"üìä Training samples: {len(trainset)}\")\n",
    "print(f\"üìä Test samples: {len(testset)}\")\n",
    "print(f\"üè∑Ô∏è Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization\n",
    "\n",
    "Let's visualize some sample images from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def imshow(img, title=None):\n",
    "    \"\"\"Display a tensor image.\"\"\"\n",
    "    # Handle both normalized and unnormalized images\n",
    "    if img.min() < 0:  # If normalized, unnormalize\n",
    "        img = img / 2 + 0.5\n",
    "    \n",
    "    # Clamp values to [0, 1] range\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get a batch of training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid of sample images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(8):  # Show first 8 images\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    imshow(images[i], title=f'{classes[labels[i]]}')\n",
    "\n",
    "plt.suptitle('üñºÔ∏è Sample Images from Training Set (CIFAR-10 or Synthetic)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üéØ Batch shape: {images.shape} (batch_size, channels, height, width)\")\n",
    "print(f\"üè∑Ô∏è Labels shape: {labels.shape}\")\n",
    "print(f\"üìã Sample labels: {[classes[label] for label in labels[:8]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building a Model with PyTorch Modules: LeNet-5\n",
    "\n",
    "PyTorch models inherit from `torch.nn.Module`. We'll implement LeNet-5, the early CNN designed for handwritten digit recognition, adapted for Australian landmark classification. This follows the exact architecture described in the video:\n",
    "\n",
    "- **C1**: Convolutional layer (6 feature maps, 5x5 kernel) - scans input for learned features\n",
    "- **S2**: Subsampling layer (2x2 max pooling) - downsamples activation map\n",
    "- **C3**: Convolutional layer (16 feature maps, 5x5 kernel) - scans for feature combinations  \n",
    "- **S4**: Subsampling layer (2x2 max pooling) - downsamples again\n",
    "- **F5**: Fully connected layer (120 units) - classification layer\n",
    "- **F6**: Fully connected layer (84 units) - classification layer\n",
    "- **Output**: Fully connected layer (8 Australian cities)\n",
    "\n",
    "**PyTorch vs TensorFlow Model Definition**:\n",
    "- **PyTorch**: Explicit `nn.Module` subclass with `__init__` and `forward` methods\n",
    "- **TensorFlow**: `tf.keras.Sequential` or Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCIFAR10CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN for CIFAR-10 classification - Hello World PyTorch model.\n",
    "    \n",
    "    Architecture:\n",
    "    - 2 Convolutional blocks (Conv2d + ReLU + MaxPool)\n",
    "    - 2 Fully connected layers with dropout\n",
    "    - Output: 10 classes (CIFAR-10)\n",
    "    \n",
    "    TensorFlow equivalent:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCIFAR10CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)   # 3 input channels (RGB)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32 -> 64 channels\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduce spatial dimensions by half\n",
    "        \n",
    "        # Calculate size after convolutions: 32x32 -> 16x16 -> 8x8\n",
    "        # Final feature map: 64 channels * 8 * 8 = 4096\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(64, num_classes)  # Output layer\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input batch of images [batch_size, 3, 32, 32]\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Class logits [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Convolutional block 1: Conv -> ReLU -> Pool\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 16, 16]\n",
    "        \n",
    "        # Convolutional block 2: Conv -> ReLU -> Pool  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 8, 8]\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(-1, 64 * 8 * 8)            # [batch, 4096]\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        x = F.relu(self.fc1(x))               # [batch, 64]\n",
    "        x = self.dropout(x)                   # Apply dropout during training\n",
    "        x = self.fc2(x)                       # [batch, 10] - final logits\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Return model architecture information.\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        \n",
    "        return {\n",
    "            'model_name': 'SimpleCIFAR10CNN',\n",
    "            'total_parameters': total_params,\n",
    "            'trainable_parameters': trainable_params,\n",
    "            'architecture': 'Conv2d(32) -> Conv2d(64) -> FC(64) -> FC(10)'\n",
    "        }\n",
    "\n",
    "# Create model instance and move to device\n",
    "model = SimpleCIFAR10CNN(num_classes=10).to(device)\n",
    "\n",
    "# Display model information\n",
    "model_info = model.get_model_info()\n",
    "print(f\"üß† Model: {model_info['model_name']}\")\n",
    "print(f\"üî¢ Total parameters: {model_info['total_parameters']:,}\")\n",
    "print(f\"üéØ Trainable parameters: {model_info['trainable_parameters']:,}\")\n",
    "print(f\"üèóÔ∏è Architecture: {model_info['architecture']}\")\n",
    "print(f\"\\nüìã Model summary:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss Function and Optimizer Setup\n",
    "\n",
    "**Key PyTorch Pattern**: Explicit loss and optimizer definition (vs TensorFlow's `model.compile()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer setup\n",
    "# TensorFlow equivalent: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "# Optional: Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print(f\"üéØ Loss function: {criterion}\")\n",
    "print(f\"üîß Optimizer: {optimizer}\")\n",
    "print(f\"üìâ Learning rate scheduler: Step LR (decay by 0.5 every 5 epochs)\")\n",
    "print(f\"üìä Initial learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop Implementation\n",
    "\n",
    "**Major Difference from TensorFlow**: PyTorch requires manual training loops instead of `model.fit()`.\n",
    "\n",
    "This gives more control but requires more code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, criterion, optimizer, scheduler, \n",
    "                num_epochs=5, device=device):\n",
    "    \"\"\"\n",
    "    Training function with TensorBoard logging.\n",
    "    \n",
    "    TensorFlow equivalent:\n",
    "    model.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test))\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        trainloader: Training data loader\n",
    "        testloader: Test data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        num_epochs: Number of training epochs\n",
    "        device: Device to train on (CPU/GPU)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üöÄ Starting training for {num_epochs} epochs...\")\n",
    "    print(f\"üíæ Device: {device}\")\n",
    "    print(f\"üî¢ Batch size: {batch_size}\")\n",
    "    print(f\"üìä Training batches per epoch: {len(trainloader)}\")\n",
    "    print(f\"üìä Test batches: {len(testloader)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()  # Set model to training mode (enables dropout, batch norm)\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            # Move data to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients (PyTorch accumulates gradients by default)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()    # Compute gradients\n",
    "            optimizer.step()   # Update weights\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Log batch-level metrics to TensorBoard\n",
    "            if batch_idx % 200 == 0:  # Log every 200 batches\n",
    "                writer.add_scalar('Loss/Train_Batch', loss.item(), \n",
    "                                epoch * len(trainloader) + batch_idx)\n",
    "        \n",
    "        # Calculate epoch training metrics\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        epoch_acc = 100 * correct_train / total_train\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode (disables dropout)\n",
    "        test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate test metrics\n",
    "        test_loss = test_loss / len(testloader)\n",
    "        test_acc = 100 * correct_test / total_test\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Log epoch-level metrics to TensorBoard\n",
    "        writer.add_scalar('Loss/Train_Epoch', epoch_loss, epoch)\n",
    "        writer.add_scalar('Loss/Test', test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', epoch_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/Test', test_acc, epoch)\n",
    "        writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "        \n",
    "        # Log model parameters histogram\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f'Parameters/{name}', param, epoch)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
    "        print(f'  Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%')\n",
    "        print(f'  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "        print(f'  Learning Rate: {current_lr:.6f}')\n",
    "        \n",
    "        # Early stopping for demo (if we reach good accuracy)\n",
    "        if test_acc > 65.0:  # CIFAR-10 is challenging, 65% is decent for a simple model\n",
    "            print(f\"\\nüéâ Early stopping! Achieved {test_acc:.2f}% test accuracy.\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed!\")\n",
    "    return model\n",
    "\n",
    "# Train the model (using small number of epochs for demo)\n",
    "num_epochs = 8  # Small number for educational purposes\n",
    "trained_model = train_model(\n",
    "    model, trainloader, testloader, criterion, optimizer, scheduler, \n",
    "    num_epochs=num_epochs, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Testing\n",
    "\n",
    "Let's evaluate our trained model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "def evaluate_model(model, testloader, classes, device=device):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model and show per-class accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(len(classes)))\n",
    "    class_total = list(0. for i in range(len(classes)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # Overall accuracy\n",
    "    overall_accuracy = 100 * correct / total\n",
    "    print(f\"üéØ Overall Test Accuracy: {overall_accuracy:.2f}%\")\n",
    "    print(\"\\nüìä Per-class accuracy:\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    for i in range(len(classes)):\n",
    "        if class_total[i] > 0:\n",
    "            accuracy = 100 * class_correct[i] / class_total[i]\n",
    "            print(f\"  {classes[i]:>12}: {accuracy:.1f}%\")\n",
    "    \n",
    "    return overall_accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"üîç Evaluating trained model...\")\n",
    "final_accuracy = evaluate_model(trained_model, testloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Predictions on Sample Images\n",
    "\n",
    "Let's see how our model performs on some test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on sample test images\n",
    "def predict_samples(model, testloader, classes, num_samples=8, device=device):\n",
    "    \"\"\"\n",
    "    Show predictions on sample test images.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of test images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        \n",
    "        # Move image back to CPU for plotting\n",
    "        img = images[i].cpu()\n",
    "        imshow(img)\n",
    "        \n",
    "        # Get prediction info\n",
    "        true_label = classes[labels[i]]\n",
    "        pred_label = classes[predicted[i]]\n",
    "        confidence = probabilities[i][predicted[i]].item() * 100\n",
    "        \n",
    "        # Color: green if correct, red if wrong\n",
    "        color = 'green' if predicted[i] == labels[i] else 'red'\n",
    "        \n",
    "        plt.title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                 color=color, fontsize=10)\n",
    "    \n",
    "    plt.suptitle('üîÆ Model Predictions on Test Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate accuracy for this batch\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    batch_accuracy = 100 * correct / len(labels)\n",
    "    print(f\"üìä Batch accuracy: {batch_accuracy:.1f}% ({correct}/{len(labels)} correct)\")\n",
    "\n",
    "# Show sample predictions\n",
    "predict_samples(trained_model, testloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. TensorBoard Visualization Instructions\n",
    "\n",
    "View your training progress with TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# Display TensorBoard viewing instructions\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä TENSORBOARD VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Log directory: {log_dir}\")\n",
    "print(\"\\nüöÄ To view TensorBoard:\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"   In Google Colab:\")\n",
    "    print(\"   1. Run: %load_ext tensorboard\")\n",
    "    print(f\"   2. Run: %tensorboard --logdir {log_dir}\")\n",
    "    print(\"   3. TensorBoard will appear inline in the notebook\")\n",
    "elif IS_KAGGLE:\n",
    "    print(\"   In Kaggle:\")\n",
    "    print(f\"   1. Download logs from: {log_dir}\")\n",
    "    print(\"   2. Run locally: tensorboard --logdir ./tensorboard_logs\")\n",
    "    print(\"   3. Open http://localhost:6006 in browser\")\n",
    "else:\n",
    "    print(\"   Locally:\")\n",
    "    print(f\"   1. Run: tensorboard --logdir {log_dir}\")\n",
    "    print(\"   2. Open http://localhost:6006 in browser\")\n",
    "\n",
    "print(\"\\nüìà Available visualizations:\")\n",
    "print(\"   ‚Ä¢ Scalars: Loss, accuracy, learning rate over time\")\n",
    "print(\"   ‚Ä¢ Histograms: Model parameter distributions\")\n",
    "print(\"   ‚Ä¢ Graphs: Model architecture visualization\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Learning Points: TensorFlow vs PyTorch\n",
    "\n",
    "Summary of key differences encountered in this \"Hello World\" example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "üéì KEY LEARNING POINTS: TensorFlow ‚Üí PyTorch Transition\n",
    "\n",
    "1. üèóÔ∏è MODEL DEFINITION:\n",
    "   TensorFlow: tf.keras.Sequential() or Functional API\n",
    "   PyTorch:    nn.Module subclass with __init__ and forward methods\n",
    "\n",
    "2. üîÑ TRAINING LOOPS:\n",
    "   TensorFlow: model.fit() handles everything automatically\n",
    "   PyTorch:    Manual loops with optimizer.zero_grad(), loss.backward(), optimizer.step()\n",
    "\n",
    "3. üìä DATA LOADING:\n",
    "   TensorFlow: tf.data.Dataset with built-in batching\n",
    "   PyTorch:    DataLoader with explicit dataset and transforms\n",
    "\n",
    "4. üéØ LOSS & OPTIMIZATION:\n",
    "   TensorFlow: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "   PyTorch:    Explicit criterion = nn.CrossEntropyLoss() and optimizer = optim.Adam()\n",
    "\n",
    "5. üíæ DEVICE MANAGEMENT:\n",
    "   TensorFlow: Mostly automatic with tf.distribute.Strategy\n",
    "   PyTorch:    Explicit .to(device) calls for model and data\n",
    "\n",
    "6. üé≠ TRAINING/INFERENCE MODES:\n",
    "   TensorFlow: Implicit (training=True/False parameter)\n",
    "   PyTorch:    Explicit model.train() and model.eval() calls\n",
    "\n",
    "7. üìà MONITORING:\n",
    "   TensorFlow: Built-in callbacks and metrics\n",
    "   PyTorch:    Manual TensorBoard logging with SummaryWriter\n",
    "\n",
    "üöÄ ADVANTAGES OF PYTORCH:\n",
    "   ‚úÖ More explicit control over training process\n",
    "   ‚úÖ Dynamic computation graphs (easier debugging)\n",
    "   ‚úÖ Pythonic and intuitive API\n",
    "   ‚úÖ Better integration with Hugging Face transformers\n",
    "   ‚úÖ Immediate execution (no session.run())\n",
    "\n",
    "üéØ NEXT STEPS:\n",
    "   1. Practice with more complex architectures\n",
    "   2. Explore Hugging Face transformers\n",
    "   3. Learn custom dataset creation\n",
    "   4. Study advanced PyTorch features (autograd, hooks, etc.)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Saving (Optional)\n",
    "\n",
    "Save your trained model for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = './hello_pytorch_cifar10_model.pth'\n",
    "\n",
    "# PyTorch way: Save state dictionary\n",
    "torch.save(trained_model.state_dict(), model_save_path)\n",
    "print(f\"üíæ Model saved to: {model_save_path}\")\n",
    "\n",
    "# To load the model later:\n",
    "# model = SimpleCIFAR10CNN()\n",
    "# model.load_state_dict(torch.load(model_save_path))\n",
    "# model.eval()\n",
    "\n",
    "print(f\"\\nüéâ Hello PyTorch CIFAR-10 tutorial completed!\")\n",
    "print(f\"üìä Final test accuracy: {final_accuracy:.2f}%\")\n",
    "print(f\"üß† Model parameters: {model.get_model_info()['total_parameters']:,}\")\n",
    "print(f\"‚è±Ô∏è Training epochs: {num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Congratulations!\n",
    "\n",
    "You've successfully completed your first PyTorch \"Hello World\" with CIFAR-10! You've learned:\n",
    "\n",
    "‚úÖ **PyTorch Fundamentals**: Tensors, autograd, and nn.Module  \n",
    "‚úÖ **Model Definition**: Creating CNN architectures with PyTorch  \n",
    "‚úÖ **Data Handling**: DataLoaders and transforms  \n",
    "‚úÖ **Training Loops**: Manual training vs TensorFlow's model.fit()  \n",
    "‚úÖ **Monitoring**: TensorBoard integration for PyTorch  \n",
    "‚úÖ **Model Evaluation**: Testing and visualization  \n",
    "\n",
    "### üöÄ Next Steps in Your PyTorch Journey:\n",
    "\n",
    "1. **Advanced CNN Architectures**: ResNet, VGG, EfficientNet\n",
    "2. **Transfer Learning**: Using pre-trained models\n",
    "3. **Hugging Face Integration**: Modern NLP with transformers\n",
    "4. **Custom Datasets**: Working with your own data\n",
    "5. **Advanced Training**: Mixed precision, distributed training\n",
    "\n",
    "**Happy learning with PyTorch!** üî•\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook demonstrates fundamental PyTorch concepts through a practical CIFAR-10 classification example. For more advanced tutorials and examples, explore the other notebooks in this repository.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}