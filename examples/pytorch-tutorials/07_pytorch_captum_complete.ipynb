{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model Understanding with Captum: Australian Tourism Image Analysis\n",
    "\n",
    "This notebook demonstrates **Captum**, PyTorch's open-source library for model interpretability, using Australian tourism imagery and multilingual examples. Learn how to understand and explain your PyTorch models' behavior through various attribution techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand core Captum concepts: Feature, Layer, and Neuron Attribution\n",
    "- Implement **Integrated Gradients** for identifying important input features\n",
    "- Use **Occlusion** analysis for perturbation-based explanations\n",
    "- Apply **Grad-CAM** for layer-level interpretability\n",
    "- Create interactive visualizations with **Captum Insights**\n",
    "- Analyze Australian tourism images and multilingual content\n",
    "\n",
    "## Australian Context Examples\n",
    "We'll analyze images and content related to:\n",
    "- üèõÔ∏è Sydney Opera House and Harbour Bridge\n",
    "- üèñÔ∏è Gold Coast beaches and tourism\n",
    "- üê® Australian wildlife (cats, native animals)\n",
    "- üó£Ô∏è English-Vietnamese tourism descriptions\n",
    "\n",
    "**Captum Documentation**: https://captum.ai\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Runtime Detection\n",
    "\n",
    "Following PyTorch best practices for cross-platform compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"üåê Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nüîß Setting up Google Colab environment...\")\n",
    "    # Colab usually has PyTorch pre-installed\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nüîß Setting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nüîß Setting up local environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages based on platform\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"captum\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"tensorboard\",\n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        # Use IPython magic commands for notebook environments\n",
    "        try:\n",
    "            exec(f\"!pip install -q {package}\")\n",
    "            print(f\"‚úÖ {package}\")\n",
    "        except:\n",
    "            print(f\"‚ö†Ô∏è {package} (may already be installed)\")\n",
    "    else:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                          capture_output=True, check=True)\n",
    "            print(f\"‚úÖ {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"‚ö†Ô∏è {package} (may already be installed)\")\n",
    "\n",
    "print(\"\\nüéâ Package installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify PyTorch and Captum installation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Captum imports\n",
    "import captum\n",
    "from captum.attr import (\n",
    "    IntegratedGradients,\n",
    "    Occlusion,\n",
    "    LayerGradCam,\n",
    "    LayerAttribution\n",
    ")\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "# Additional libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import json\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"üî• PyTorch {torch.__version__} ready!\")\n",
    "print(f\"üéØ Captum {captum.__version__} ready!\")\n",
    "print(f\"üñ•Ô∏è CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"üéØ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
