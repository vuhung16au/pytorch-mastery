{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch TensorBoard Support: Comprehensive Visualization Guide\n",
    "\n",
    "This notebook demonstrates how to integrate and effectively use **TensorBoard** with PyTorch for visualizing model training, understanding model architecture, and exploring datasets. Perfect for learners transitioning from TensorFlow to PyTorch!\n",
    "\n",
    "## Learning Objectives\n",
    "- **Set up TensorBoard** with PyTorch using `SummaryWriter`\n",
    "- **Visualize data elements** - especially useful for computer vision tasks\n",
    "- **Monitor training progress** with scalar metrics (loss, accuracy)\n",
    "- **Understand model architecture** through computational graphs\n",
    "- **Explore high-dimensional data** using embedding projections\n",
    "- **Australian context examples** with English-Vietnamese multilingual support\n",
    "\n",
    "## Dataset: FashionMNIST with Australian Fashion Context\n",
    "We'll use **FashionMNIST** dataset (28x28 grayscale images of clothing items) and adapt it with Australian fashion context:\n",
    "- \ud83d\udc55 T-shirt/top \u2192 Australian surf wear\n",
    "- \ud83d\udc56 Trouser \u2192 Boardshorts for Sydney beaches\n",
    "- \ud83d\udc5a Pullover \u2192 Melbourne winter jumper\n",
    "- \ud83d\udc57 Dress \u2192 Perth summer dress\n",
    "- \ud83e\udde5 Coat \u2192 Hobart winter coat\n",
    "- \ud83d\udc61 Sandal \u2192 Flip-flops (thongs) for Brisbane\n",
    "- \ud83d\udc55 Shirt \u2192 Work shirt for Adelaide\n",
    "- \ud83d\udc5f Sneaker \u2192 Running shoes for Darwin\n",
    "- \ud83d\udc5c Bag \u2192 Beach bag for Gold Coast\n",
    "- \ud83d\udc62 Ankle boot \u2192 Bush boots for outback\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Runtime Detection\n",
    "\n",
    "Following PyTorch best practices for cross-platform compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    !apt update -qq\n",
    "    !apt install -y -qq software-properties-common\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nSetting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nSetting up local environment...\")\n",
    "\n",
    "# Install required packages for this notebook\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"matplotlib\",\n",
    "    \"tensorboard\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "print(\"\\nInstalling required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        !pip install -q {package}\n",
    "    else:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                      capture_output=True)\n",
    "    print(f\"\u2713 {package}\")\n",
    "\n",
    "print(\"\\n\ud83c\udf89 Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Imports and Device Detection\n",
    "\n",
    "**PyTorch vs TensorFlow Import Patterns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter  # Key for TensorBoard integration\n",
    "\n",
    "# Vision and data handling\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# Visualization and utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA  # For embedding visualization\n",
    "\n",
    "# Device detection with comprehensive hardware support\n",
    "def detect_device():\n",
    "    \"\"\"\n",
    "    Detect the best available PyTorch device.\n",
    "    \n",
    "    Priority order:\n",
    "    1. CUDA (NVIDIA GPUs) - Best performance for deep learning\n",
    "    2. MPS (Apple Silicon) - Optimized for M1/M2/M3 Macs  \n",
    "    3. CPU (Universal) - Always available fallback\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for PyTorch operations\n",
    "        str: Human-readable device description\n",
    "    \"\"\"\n",
    "    # Check for CUDA (NVIDIA GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        device_info = f\"CUDA GPU: {gpu_name}\"\n",
    "        \n",
    "        print(f\"\ud83d\ude80 Using CUDA acceleration\")\n",
    "        print(f\"   GPU: {gpu_name}\")\n",
    "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "        \n",
    "        return device, device_info\n",
    "    \n",
    "    # Check for MPS (Apple Silicon)\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        device_info = \"Apple Silicon MPS\"\n",
    "        \n",
    "        print(f\"\ud83c\udf4e Using Apple Silicon MPS acceleration\")\n",
    "        \n",
    "        return device, device_info\n",
    "    \n",
    "    # Fallback to CPU\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_info = \"CPU (No GPU acceleration available)\"\n",
    "        \n",
    "        print(f\"\ud83d\udcbb Using CPU (no GPU acceleration detected)\")\n",
    "        print(f\"   PyTorch Threads: {torch.get_num_threads()}\")\n",
    "        \n",
    "        return device, device_info\n",
    "\n",
    "# Usage in this notebook\n",
    "device, device_info = detect_device()\n",
    "print(f\"\\n\u2705 PyTorch device selected: {device}\")\n",
    "print(f\"\ud83d\udcca Device info: {device_info}\")\n",
    "\n",
    "# Set global device for the notebook\n",
    "DEVICE = device\n",
    "\n",
    "# Verify PyTorch installation\n",
    "print(f\"\\n\ud83d\udd25 PyTorch {torch.__version__} ready!\")\n",
    "print(f\"\ud83d\udd25 TorchVision {torchvision.__version__} ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorBoard Setup - Platform-Specific Configuration\n",
    "\n",
    "**Key difference from TensorFlow**: PyTorch requires explicit TensorBoard setup via `SummaryWriter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform-specific TensorBoard log directory setup\n",
    "def get_run_logdir(name=\"australian_fashion_mnist\"):\n",
    "    \"\"\"Create unique log directory for this training run.\"\"\"\n",
    "    if IS_COLAB:\n",
    "        root_logdir = \"/content/tensorboard_logs\"\n",
    "    elif IS_KAGGLE:\n",
    "        root_logdir = \"./tensorboard_logs\"\n",
    "    else:\n",
    "        root_logdir = \"./tensorboard_logs\"\n",
    "    \n",
    "    # Create root directory if it doesn't exist\n",
    "    os.makedirs(root_logdir, exist_ok=True)\n",
    "    \n",
    "    # Generate unique run directory\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    run_logdir = os.path.join(root_logdir, f\"{name}_{timestamp}\")\n",
    "    return run_logdir\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "log_dir = get_run_logdir(\"pytorch_tensorboard_tutorial\")\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"\ud83d\udcca TensorBoard logs will be saved to: {log_dir}\")\n",
    "print(f\"\ud83d\udca1 To view TensorBoard after running this notebook:\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"   In Google Colab:\")\n",
    "    print(\"   1. Run: %load_ext tensorboard\")\n",
    "    print(f\"   2. Run: %tensorboard --logdir {log_dir}\")\n",
    "elif IS_KAGGLE:\n",
    "    print(\"   In Kaggle:\")\n",
    "    print(f\"   1. Download logs from: {log_dir}\")\n",
    "    print(\"   2. Run locally: tensorboard --logdir ./tensorboard_logs\")\n",
    "else:\n",
    "    print(\"   Locally:\")\n",
    "    print(f\"   1. Run: tensorboard --logdir {log_dir}\")\n",
    "    print(\"   2. Open http://localhost:6006 in browser\")\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 This notebook will demonstrate:\")\n",
    "print(\"   \u2022 Images: Fashion item visualizations\")\n",
    "print(\"   \u2022 Scalars: Loss and accuracy over time\")\n",
    "print(\"   \u2022 Graphs: Model architecture visualization\")\n",
    "print(\"   \u2022 Embeddings: High-dimensional data projection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the 4 key TensorBoard features with PyTorch:\n",
    "\n",
    "1. **Image Visualization** - Log fashion samples to TensorBoard\n",
    "2. **Scalar Monitoring** - Track training/validation metrics\n",
    "3. **Graph Visualization** - Understand model architecture  \n",
    "4. **Embeddings** - Explore high-dimensional data clusters\n",
    "\n",
    "All examples use Australian fashion context with English-Vietnamese translations.\n",
    "\n",
    "**TensorFlow vs PyTorch Key Differences:**\n",
    "- PyTorch: Manual `SummaryWriter` setup and explicit logging calls\n",
    "- TensorFlow: Built-in callbacks and automatic metric logging\n",
    "- PyTorch: More granular control over what and when to log\n",
    "- Both: Use same TensorBoard UI for visualization\n",
    "\n",
    "**Next Steps:**\n",
    "- Run the complete notebook with real FashionMNIST data\n",
    "- Explore TensorBoard's interactive features\n",
    "- Apply to your own PyTorch projects\n",
    "- Integrate with Hugging Face transformers for NLP tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}