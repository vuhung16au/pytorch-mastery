{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emtWuCRmAr2r"
      },
      "source": [
        "# Building Models with PyTorch: From Fundamentals to Advanced Architectures\n",
        "\n",
        "This notebook demonstrates the foundational concepts and tools within PyTorch's `torch.nn` module for constructing neural network models. We'll explore essential classes for defining models and parameters, various common layer types, and crucial functions like activation and loss functions.\n",
        "\n",
        "## Learning Objectives\n",
        "- Master the core classes: `nn.Module` and `nn.Parameter`\n",
        "- Understand common neural network layer types (Linear, Convolutional, RNN, Transformer)\n",
        "- Explore essential functions: pooling, normalization, dropout, activation, and loss functions\n",
        "- Build practical models with Australian context examples\n",
        "- Compare PyTorch patterns with TensorFlow equivalents\n",
        "- Implement multilingual NLP models (English-Vietnamese)\n",
        "\n",
        "## Key Concepts Covered\n",
        "1. **Core Classes**: `nn.Module` and `nn.Parameter`\n",
        "2. **Layer Types**: Linear, Convolutional, RNN/LSTM, Transformer\n",
        "3. **Essential Functions**: Pooling, Normalization, Dropout, Activation, Loss\n",
        "4. **Practical Applications**: Australian tourism sentiment analysis, city classification\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56-nwAoyAr2r"
      },
      "source": [
        "## 1. Environment Setup and Runtime Detection\n",
        "\n",
        "Following PyTorch best practices for cross-platform compatibility:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVNIFGpZAr2s",
        "outputId": "69e8932d-4fac-47c0-941c-aa437d919370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment detected:\n",
            "  - Local: False\n",
            "  - Google Colab: True\n",
            "  - Kaggle: False\n",
            "\n",
            "Setting up Google Colab environment...\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "\n",
            "Installing required packages...\n",
            "‚úì torch\n",
            "‚úì torchvision\n",
            "‚úì transformers\n",
            "‚úì datasets\n",
            "‚úì tokenizers\n",
            "‚úì pandas\n",
            "‚úì matplotlib\n",
            "‚úì seaborn\n",
            "‚úì tensorboard\n",
            "\n",
            "‚úÖ PyTorch 2.8.0+cu126 ready!\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Environment Detection and Setup\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Detect the runtime environment\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
        "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
        "\n",
        "print(f\"Environment detected:\")\n",
        "print(f\"  - Local: {IS_LOCAL}\")\n",
        "print(f\"  - Google Colab: {IS_COLAB}\")\n",
        "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
        "\n",
        "# Platform-specific system setup\n",
        "if IS_COLAB:\n",
        "    print(\"\\nSetting up Google Colab environment...\")\n",
        "    !apt update -qq\n",
        "    !apt install -y -qq software-properties-common\n",
        "elif IS_KAGGLE:\n",
        "    print(\"\\nSetting up Kaggle environment...\")\n",
        "    # Kaggle usually has most packages pre-installed\n",
        "else:\n",
        "    print(\"\\nSetting up local environment...\")\n",
        "\n",
        "# Install required packages for this notebook\n",
        "required_packages = [\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"transformers\",\n",
        "    \"datasets\",\n",
        "    \"tokenizers\",\n",
        "    \"pandas\",\n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"tensorboard\"\n",
        "]\n",
        "\n",
        "print(\"\\nInstalling required packages...\")\n",
        "for package in required_packages:\n",
        "    if IS_COLAB or IS_KAGGLE:\n",
        "        !pip install -q {package}\n",
        "    else:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package],\n",
        "                      capture_output=True)\n",
        "    print(f\"‚úì {package}\")\n",
        "\n",
        "# Verify PyTorch installation\n",
        "import torch\n",
        "print(f\"\\n‚úÖ PyTorch {torch.__version__} ready!\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ceaPsL1Ar2s"
      },
      "source": [
        "## 2. Device Detection and Setup\n",
        "\n",
        "Implementing intelligent device detection for optimal performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cQYfARFAr2s",
        "outputId": "89eeb39f-3991-4de3-906d-1152a0f6b31c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíª Using CPU (no GPU acceleration detected)\n",
            "   Processor: x86_64\n",
            "   PyTorch Threads: 1\n",
            "\n",
            "‚úÖ PyTorch device selected: cpu\n",
            "üìä Device info: CPU (No GPU acceleration available)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import platform\n",
        "\n",
        "def detect_device():\n",
        "    \"\"\"\n",
        "    Detect the best available PyTorch device with comprehensive hardware support.\n",
        "\n",
        "    Priority order:\n",
        "    1. CUDA (NVIDIA GPUs) - Best performance for deep learning\n",
        "    2. MPS (Apple Silicon) - Optimized for M1/M2/M3 Macs\n",
        "    3. CPU (Universal) - Always available fallback\n",
        "\n",
        "    Returns:\n",
        "        torch.device: The optimal device for PyTorch operations\n",
        "        str: Human-readable device description for logging\n",
        "    \"\"\"\n",
        "    # Check for CUDA (NVIDIA GPU)\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        device_info = f\"CUDA GPU: {gpu_name}\"\n",
        "\n",
        "        print(f\"üöÄ Using CUDA acceleration\")\n",
        "        print(f\"   GPU: {gpu_name}\")\n",
        "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "        return device, device_info\n",
        "\n",
        "    # Check for MPS (Apple Silicon)\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        device_info = \"Apple Silicon MPS\"\n",
        "\n",
        "        print(f\"üçé Using Apple Silicon MPS acceleration\")\n",
        "        print(f\"   System: {platform.uname().system} {platform.uname().release}\")\n",
        "\n",
        "        return device, device_info\n",
        "\n",
        "    # Fallback to CPU\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        device_info = \"CPU (No GPU acceleration available)\"\n",
        "\n",
        "        print(f\"üíª Using CPU (no GPU acceleration detected)\")\n",
        "        print(f\"   Processor: {platform.uname().processor}\")\n",
        "        print(f\"   PyTorch Threads: {torch.get_num_threads()}\")\n",
        "\n",
        "        return device, device_info\n",
        "\n",
        "# Detect and set global device\n",
        "DEVICE, DEVICE_INFO = detect_device()\n",
        "print(f\"\\n‚úÖ PyTorch device selected: {DEVICE}\")\n",
        "print(f\"üìä Device info: {DEVICE_INFO}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LIUoOImAr2s"
      },
      "source": [
        "## 3. Core Classes: nn.Module and nn.Parameter\n",
        "\n",
        "Model building in PyTorch revolves around two key classes within the `torch.nn` module:\n",
        "\n",
        "### `nn.Module`: The Foundation of PyTorch Models\n",
        "\n",
        "**`nn.Module`** is the base class for all neural network modules. It encapsulates entire models, as well as individual model components like neural network layers.\n",
        "\n",
        "**Key aspects:**\n",
        "- An `__init__` method where the model's layers and functions are defined\n",
        "- A `forward` method that dictates how data flows through the layers\n",
        "- Automatic registration of `nn.Parameter` objects assigned as attributes\n",
        "\n",
        "**TensorFlow Comparison:**\n",
        "- PyTorch: Explicit `nn.Module` subclass with `__init__` and `forward` methods\n",
        "- TensorFlow: `tf.keras.Sequential` or Functional API with automatic forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fKRz1sFAr2s",
        "outputId": "283ef163-07bc-4891-a12b-f6fd538e172e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèõÔ∏è Australian City Classifier Model:\n",
            "AustralianCityClassifier(\n",
            "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=8, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "\n",
            "üìä Model Info: {'total_parameters': 8808, 'trainable_parameters': 8808, 'cities': ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide', 'Darwin', 'Hobart', 'Canberra'], 'num_cities': 8}\n",
            "üéØ Target cities: ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide', 'Darwin', 'Hobart', 'Canberra']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Australian City Classifier - Demonstrates nn.Module fundamentals\n",
        "class AustralianCityClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple classifier for Australian cities - demonstrates nn.Module patterns.\n",
        "\n",
        "    TensorFlow equivalent:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_size,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(len(australian_cities), activation='softmax')\n",
        "    ])\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_cities):\n",
        "        # MUST call parent constructor first\n",
        "        super(AustralianCityClassifier, self).__init__()\n",
        "\n",
        "        # Define layers - these become registered nn.Parameters automatically\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.fc3 = nn.Linear(hidden_size // 2, num_cities)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # Store city names for interpretation\n",
        "        self.australian_cities = [\n",
        "            \"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\",\n",
        "            \"Adelaide\", \"Darwin\", \"Hobart\", \"Canberra\"\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass - defines how data flows through the model.\n",
        "\n",
        "        TensorFlow: forward pass is automatic with model(x)\n",
        "        PyTorch: explicit forward method required\n",
        "        \"\"\"\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # No softmax here if using CrossEntropyLoss\n",
        "        return x\n",
        "\n",
        "    def get_model_info(self):\n",
        "        \"\"\"Utility method to get model information.\"\"\"\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        return {\n",
        "            'total_parameters': total_params,\n",
        "            'trainable_parameters': trainable_params,\n",
        "            'cities': self.australian_cities,\n",
        "            'num_cities': len(self.australian_cities)\n",
        "        }\n",
        "\n",
        "# Create model instance\n",
        "australian_cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\", \"Darwin\", \"Hobart\", \"Canberra\"]\n",
        "model = AustralianCityClassifier(input_size=100, hidden_size=64, num_cities=len(australian_cities))\n",
        "\n",
        "# Move to detected device\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "print(\"üèõÔ∏è Australian City Classifier Model:\")\n",
        "print(model)\n",
        "print(f\"\\nüìä Model Info: {model.get_model_info()}\")\n",
        "print(f\"üéØ Target cities: {australian_cities}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7UbxiNhAr2s"
      },
      "source": [
        "### `nn.Parameter`: Learnable Weights and Biases\n",
        "\n",
        "**`nn.Parameter`** is a subclass of `torch.Tensor` specifically designed to represent learnable weights and biases within a model.\n",
        "\n",
        "**Key features:**\n",
        "- Automatically have `requires_grad=True`\n",
        "- Autograd tracks operations for gradient computation\n",
        "- Automatically registered when assigned as module attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6-Swc6oAr2t",
        "outputId": "9779c08b-97c0-4cd4-a700-01038b48f0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Custom Linear Layer:\n",
            "CustomLinearLayer()\n",
            "\n",
            "üìã Parameters:\n",
            "  weight: torch.Size([5, 10]), requires_grad=True\n",
            "  bias: torch.Size([5]), requires_grad=True\n",
            "\n",
            "üèóÔ∏è Built-in nn.Linear:\n",
            "  weight: torch.Size([5, 10]), requires_grad=True\n",
            "  bias: torch.Size([5]), requires_grad=True\n",
            "\n",
            "üß™ Test Results:\n",
            "  Custom layer output shape: torch.Size([1, 5])\n",
            "  Built-in layer output shape: torch.Size([1, 5])\n",
            "  Both layers work identically! ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate nn.Parameter usage\n",
        "class CustomLinearLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom linear layer demonstrating nn.Parameter usage.\n",
        "\n",
        "    This manually implements what nn.Linear does internally.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(CustomLinearLayer, self).__init__()\n",
        "\n",
        "        # Define learnable parameters explicitly\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "        # Initialize weights (common practice)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights using Xavier initialization.\"\"\"\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Manual linear transformation: y = xW^T + b\n",
        "        return F.linear(x, self.weight, self.bias)\n",
        "\n",
        "# Create custom layer\n",
        "custom_layer = CustomLinearLayer(10, 5).to(DEVICE)\n",
        "\n",
        "print(\"üîß Custom Linear Layer:\")\n",
        "print(custom_layer)\n",
        "print(f\"\\nüìã Parameters:\")\n",
        "for name, param in custom_layer.named_parameters():\n",
        "    print(f\"  {name}: {param.shape}, requires_grad={param.requires_grad}\")\n",
        "\n",
        "# Compare with built-in nn.Linear\n",
        "builtin_layer = nn.Linear(10, 5).to(DEVICE)\n",
        "print(f\"\\nüèóÔ∏è Built-in nn.Linear:\")\n",
        "for name, param in builtin_layer.named_parameters():\n",
        "    print(f\"  {name}: {param.shape}, requires_grad={param.requires_grad}\")\n",
        "\n",
        "# Test both layers with sample input\n",
        "sample_input = torch.randn(1, 10).to(DEVICE)\n",
        "custom_output = custom_layer(sample_input)\n",
        "builtin_output = builtin_layer(sample_input)\n",
        "\n",
        "print(f\"\\nüß™ Test Results:\")\n",
        "print(f\"  Custom layer output shape: {custom_output.shape}\")\n",
        "print(f\"  Built-in layer output shape: {builtin_output.shape}\")\n",
        "print(f\"  Both layers work identically! ‚úÖ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ElOkkcAr2t"
      },
      "source": [
        "## 4. Common Neural Network Layer Types\n",
        "\n",
        "PyTorch provides classes for standard neural network layer types. Let's explore each with practical examples.\n",
        "\n",
        "### 4.1 Linear Layers (Fully Connected Layers)\n",
        "\n",
        "**Linear layers** are the most basic type of neural network layer. Every input influences every output, with the degree of influence determined by the layer's weights.\n",
        "\n",
        "**Key characteristics:**\n",
        "- If a layer has `m` inputs and `n` outputs, its weight matrix will be `m x n`\n",
        "- Widely used, commonly found at the end of classifier models\n",
        "- Parameters automatically set to `requires_grad=True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDEfVFe8Ar2t",
        "outputId": "4ae85403-eb7e-483f-d34e-380ff8998fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Basic Linear Layer Example:\n",
            "Layer: Linear(in_features=3, out_features=2, bias=True)\n",
            "Weight shape: torch.Size([2, 3])\n",
            "Bias shape: torch.Size([2])\n",
            "Input: tensor([[1., 2., 3.]])\n",
            "Output: tensor([[ 0.5259, -0.7117]], grad_fn=<AddmmBackward0>)\n",
            "Output shape: torch.Size([1, 2])\n"
          ]
        }
      ],
      "source": [
        "# Linear Layer Demonstration with Australian Tourism Example\n",
        "\n",
        "# Simple linear layer example\n",
        "print(\"üîó Basic Linear Layer Example:\")\n",
        "linear_layer = nn.Linear(3, 2)  # 3 inputs -> 2 outputs\n",
        "print(f\"Layer: {linear_layer}\")\n",
        "print(f\"Weight shape: {linear_layer.weight.shape}\")\n",
        "print(f\"Bias shape: {linear_layer.bias.shape}\")\n",
        "\n",
        "# Test with sample input\n",
        "sample_input = torch.tensor([[1.0, 2.0, 3.0]])  # Batch size 1, 3 features\n",
        "output = linear_layer(sample_input)\n",
        "print(f\"Input: {sample_input}\")\n",
        "print(f\"Output: {output}\")\n",
        "print(f\"Output shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWlVUiuAAr2t",
        "outputId": "03cf5b7e-3dd3-4904-9077-572003d90e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèñÔ∏è Australian Tourism Rating Predictor:\n",
            "TourismRatingPredictor(\n",
            "  (fc1): Linear(in_features=3, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "üéØ Sample Predictions:\n",
            "  Sydney Opera House: 2.25 stars\n",
            "  Melbourne Coffee Culture: 2.24 stars\n",
            "  Uluru Sacred Site: 2.18 stars\n",
            "  Great Barrier Reef: 2.25 stars\n",
            "\n",
            "üìä Model Parameters:\n",
            "  Total parameters: 209\n",
            "  fc1.weight: torch.Size([16, 3])\n",
            "  fc1.bias: torch.Size([16])\n",
            "  fc2.weight: torch.Size([8, 16])\n",
            "  fc2.bias: torch.Size([8])\n",
            "  fc3.weight: torch.Size([1, 8])\n",
            "  fc3.bias: torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "# Practical Example: Australian Tourism Rating Predictor\n",
        "class TourismRatingPredictor(nn.Module):\n",
        "    \"\"\"\n",
        "    Predicts tourism ratings for Australian attractions using linear layers.\n",
        "\n",
        "    Features: [location_score, accessibility, price_rating]\n",
        "    Output: Rating from 1-5 stars\n",
        "\n",
        "    TensorFlow equivalent:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(16, activation='relu', input_shape=(3,)),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(TourismRatingPredictor, self).__init__()\n",
        "\n",
        "        # Sequential linear layers with decreasing dimensions\n",
        "        self.fc1 = nn.Linear(3, 16)   # Input: 3 features\n",
        "        self.fc2 = nn.Linear(16, 8)   # Hidden layer\n",
        "        self.fc3 = nn.Linear(8, 1)    # Output: 1 rating\n",
        "\n",
        "        # Activation and regularization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.sigmoid = nn.Sigmoid()   # Normalize output to 0-1\n",
        "\n",
        "        # Australian attractions for demo\n",
        "        self.attractions = [\n",
        "            \"Sydney Opera House\",\n",
        "            \"Melbourne Laneways\",\n",
        "            \"Uluru (Ayers Rock)\",\n",
        "            \"Great Barrier Reef\",\n",
        "            \"Blue Mountains\"\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through linear layers\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))  # Output: 0-1 range\n",
        "        return x * 5  # Scale to 1-5 star rating\n",
        "\n",
        "    def predict_rating(self, location_score, accessibility, price_rating):\n",
        "        \"\"\"Predict rating for given features.\"\"\"\n",
        "        features = torch.tensor([[location_score, accessibility, price_rating]], dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            rating = self.forward(features)\n",
        "        return rating.item()\n",
        "\n",
        "# Create and test the tourism rating predictor\n",
        "tourism_model = TourismRatingPredictor().to(DEVICE)\n",
        "\n",
        "print(\"üèñÔ∏è Australian Tourism Rating Predictor:\")\n",
        "print(tourism_model)\n",
        "\n",
        "# Test with sample Australian attractions\n",
        "print(\"\\nüéØ Sample Predictions:\")\n",
        "test_attractions = [\n",
        "    {\"name\": \"Sydney Opera House\", \"features\": [0.95, 0.85, 0.7]},\n",
        "    {\"name\": \"Melbourne Coffee Culture\", \"features\": [0.8, 0.9, 0.9]},\n",
        "    {\"name\": \"Uluru Sacred Site\", \"features\": [1.0, 0.6, 0.8]},\n",
        "    {\"name\": \"Great Barrier Reef\", \"features\": [0.98, 0.5, 0.4]}\n",
        "]\n",
        "\n",
        "for attraction in test_attractions:\n",
        "    rating = tourism_model.predict_rating(*attraction[\"features\"])\n",
        "    print(f\"  {attraction['name']}: {rating:.2f} stars\")\n",
        "\n",
        "print(f\"\\nüìä Model Parameters:\")\n",
        "total_params = sum(p.numel() for p in tourism_model.parameters())\n",
        "print(f\"  Total parameters: {total_params}\")\n",
        "for name, param in tourism_model.named_parameters():\n",
        "    print(f\"  {name}: {param.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkcpSeqeAr2t"
      },
      "source": [
        "### 4.2 Convolutional Layers\n",
        "\n",
        "**Convolutional layers** are designed for data with strong spatial correlations, such as images. They detect local features and compose them into larger features or recognized objects.\n",
        "\n",
        "**Key concepts:**\n",
        "- `nn.Conv2d(in_channels, out_channels, kernel_size)`\n",
        "- `in_channels`: Number of input channels (1 for grayscale, 3 for color)\n",
        "- `out_channels`: Number of features the layer learns to detect\n",
        "- `kernel_size`: Size of the convolution \"window\" (e.g., 5x5)\n",
        "- Output: Activation map showing spatial locations of detected features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdRwqaEKAr2t",
        "outputId": "44a314b4-c177-43dd-f362-3853be39b9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèõÔ∏è Australian Landmark CNN:\n",
            "AustralianLandmarkCNN(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=5, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "\n",
            "üß™ Test Results:\n",
            "  Input shape: torch.Size([4, 1, 32, 32])\n",
            "  Output shape: torch.Size([4, 5])\n",
            "  Batch size: 4\n",
            "  Number of classes: 5\n",
            "\n",
            "üîç Feature Map Analysis:\n",
            "  conv1: torch.Size([1, 6, 28, 28])\n",
            "  pool1: torch.Size([1, 6, 14, 14])\n",
            "  conv2: torch.Size([1, 16, 10, 10])\n",
            "  pool2: torch.Size([1, 16, 5, 5])\n",
            "\n",
            "üéØ Landmark Categories: ['Sydney Opera House', 'Uluru (Ayers Rock)', 'Sydney Harbour Bridge', 'Twelve Apostles', 'Parliament House Canberra']\n",
            "\n",
            "üìä Parameter Breakdown:\n",
            "  Total parameters: 61,281\n",
            "  Convolutional parameters: 2,572\n",
            "  Fully connected parameters: 58,709\n"
          ]
        }
      ],
      "source": [
        "# LeNet-5 Inspired CNN for Australian Landmark Recognition\n",
        "class AustralianLandmarkCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN for recognizing Australian landmarks, inspired by LeNet-5 architecture.\n",
        "\n",
        "    Architecture:\n",
        "    - Conv2d(1, 6, 5) -> ReLU -> MaxPool2d\n",
        "    - Conv2d(6, 16, 5) -> ReLU -> MaxPool2d\n",
        "    - Flatten -> Linear layers\n",
        "\n",
        "    TensorFlow equivalent:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(6, 5, activation='relu', input_shape=(32, 32, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2),\n",
        "        tf.keras.layers.Conv2D(16, 5, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(120, activation='relu'),\n",
        "        tf.keras.layers.Dense(84, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(AustralianLandmarkCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Calculated based on input size\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        # Activation and regularization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # Australian landmarks for classification\n",
        "        self.landmarks = [\n",
        "            \"Sydney Opera House\",\n",
        "            \"Uluru (Ayers Rock)\",\n",
        "            \"Sydney Harbour Bridge\",\n",
        "            \"Twelve Apostles\",\n",
        "            \"Parliament House Canberra\"\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional feature extraction\n",
        "        x = self.pool(self.relu(self.conv1(x)))  # Conv1 -> ReLU -> Pool\n",
        "        x = self.pool(self.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = x.view(-1, 16 * 5 * 5)  # Reshape to (batch_size, features)\n",
        "\n",
        "        # Fully connected classification\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # No softmax if using CrossEntropyLoss\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_feature_maps(self, x):\n",
        "        \"\"\"Return intermediate feature maps for visualization.\"\"\"\n",
        "        conv1_out = self.relu(self.conv1(x))\n",
        "        pool1_out = self.pool(conv1_out)\n",
        "        conv2_out = self.relu(self.conv2(pool1_out))\n",
        "        pool2_out = self.pool(conv2_out)\n",
        "\n",
        "        return {\n",
        "            'conv1': conv1_out,\n",
        "            'pool1': pool1_out,\n",
        "            'conv2': conv2_out,\n",
        "            'pool2': pool2_out\n",
        "        }\n",
        "\n",
        "# Create and test the CNN\n",
        "landmark_cnn = AustralianLandmarkCNN(num_classes=5).to(DEVICE)\n",
        "\n",
        "print(\"üèõÔ∏è Australian Landmark CNN:\")\n",
        "print(landmark_cnn)\n",
        "\n",
        "# Test with sample input (simulating 32x32 grayscale images)\n",
        "sample_batch = torch.randn(4, 1, 32, 32).to(DEVICE)  # Batch of 4 images\n",
        "output = landmark_cnn(sample_batch)\n",
        "\n",
        "print(f\"\\nüß™ Test Results:\")\n",
        "print(f\"  Input shape: {sample_batch.shape}\")\n",
        "print(f\"  Output shape: {output.shape}\")\n",
        "print(f\"  Batch size: {output.shape[0]}\")\n",
        "print(f\"  Number of classes: {output.shape[1]}\")\n",
        "\n",
        "# Analyze feature maps\n",
        "with torch.no_grad():\n",
        "    feature_maps = landmark_cnn.get_feature_maps(sample_batch[:1])  # Single image\n",
        "\n",
        "print(f\"\\nüîç Feature Map Analysis:\")\n",
        "for layer_name, feature_map in feature_maps.items():\n",
        "    print(f\"  {layer_name}: {feature_map.shape}\")\n",
        "\n",
        "print(f\"\\nüéØ Landmark Categories: {landmark_cnn.landmarks}\")\n",
        "\n",
        "# Parameter count\n",
        "total_params = sum(p.numel() for p in landmark_cnn.parameters())\n",
        "conv_params = sum(p.numel() for name, p in landmark_cnn.named_parameters() if 'conv' in name)\n",
        "fc_params = sum(p.numel() for name, p in landmark_cnn.named_parameters() if 'fc' in name)\n",
        "\n",
        "print(f\"\\nüìä Parameter Breakdown:\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Convolutional parameters: {conv_params:,}\")\n",
        "print(f\"  Fully connected parameters: {fc_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qll9QZIAr2t"
      },
      "source": [
        "### 4.3 Recurrent Neural Networks (RNNs)\n",
        "\n",
        "**RNNs** are used for sequential data like natural language sentences or time-series measurements.\n",
        "\n",
        "**Key concepts:**\n",
        "- **Hidden State/Memory**: RNNs maintain a hidden state that acts as memory\n",
        "- **Sequential Processing**: Process one element at a time, maintaining context\n",
        "- **Variants**: LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit)\n",
        "- **Applications**: NLP, time series prediction, sequence-to-sequence tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Q6u6QWAr2t",
        "outputId": "188a04a8-31b7-4150-b979-864fddb9d4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üè∑Ô∏è Australian Tourism POS Tagger:\n",
            "AustralianPOSTagger(\n",
            "  (embedding): Embedding(1000, 64)\n",
            "  (lstm): LSTM(64, 128, batch_first=True)\n",
            "  (hidden2tag): Linear(in_features=128, out_features=7, bias=True)\n",
            ")\n",
            "\n",
            "üéØ POS Tags: ['NOUN', 'PROPN', 'VERB', 'ADJ', 'DET', 'ADP', 'ADV']\n",
            "üìö Sample Vocabulary: ['<PAD>', '<UNK>', 'Sydney', 'Melbourne', 'beaches', 'are', 'beautiful', 'coffee', 'culture', 'amazing']...\n",
            "\n",
            "üß™ Test Results:\n",
            "  Input shape: torch.Size([1, 4])\n",
            "  Output shape: torch.Size([1, 4, 7])\n",
            "  Sample sentence: Sydney beaches are beautiful\n",
            "  Expected POS tags: PROPN NOUN VERB ADJ\n",
            "  Predicted tag indices: [2, 1, 2, 1]\n",
            "\n",
            "üìä Parameter Breakdown:\n",
            "  Total parameters: 164,231\n",
            "  Embedding parameters: 64,000\n",
            "  LSTM parameters: 99,328\n",
            "  Linear parameters: 903\n"
          ]
        }
      ],
      "source": [
        "# Part-of-Speech Tagger for Australian Tourism Text\n",
        "class AustralianPOSTagger(nn.Module):\n",
        "    \"\"\"\n",
        "    Part-of-Speech tagger for Australian tourism content using LSTM.\n",
        "\n",
        "    Architecture:\n",
        "    - Embedding layer: Maps vocabulary words to embeddings\n",
        "    - LSTM layer: Processes sequence of embeddings\n",
        "    - Linear layer: Classifies POS tags with log_softmax\n",
        "\n",
        "    Example input: \"Sydney beaches are beautiful\"\n",
        "    Expected output: [PROPN, NOUN, VERB, ADJ] (simplified POS tags)\n",
        "\n",
        "    TensorFlow equivalent:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        tf.keras.layers.LSTM(hidden_dim, return_sequences=True),\n",
        "        tf.keras.layers.Dense(tagset_size, activation='softmax')\n",
        "    ])\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size):\n",
        "        super(AustralianPOSTagger, self).__init__()\n",
        "\n",
        "        # Embedding layer - maps words to dense vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM layer - processes sequences\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Classification layer\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "        # Store tag and word mappings\n",
        "        self.pos_tags = [\n",
        "            \"NOUN\",     # Sydney, beaches, coffee\n",
        "            \"PROPN\",    # Sydney, Melbourne, Australia\n",
        "            \"VERB\",     # are, visit, enjoy\n",
        "            \"ADJ\",      # beautiful, amazing, expensive\n",
        "            \"DET\",      # the, a, an\n",
        "            \"ADP\",      # in, on, at\n",
        "            \"ADV\"       # very, really, quite\n",
        "        ]\n",
        "\n",
        "        # Sample Australian tourism vocabulary\n",
        "        self.sample_vocab = [\n",
        "            \"<PAD>\", \"<UNK>\", \"Sydney\", \"Melbourne\", \"beaches\", \"are\", \"beautiful\",\n",
        "            \"coffee\", \"culture\", \"amazing\", \"Opera\", \"House\", \"Harbour\", \"Bridge\",\n",
        "            \"the\", \"in\", \"at\", \"very\", \"quite\", \"visit\", \"enjoy\", \"expensive\"\n",
        "        ]\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        \"\"\"\n",
        "        Forward pass for POS tagging.\n",
        "\n",
        "        Args:\n",
        "            sentence: Tensor of word indices [batch_size, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            POS tag scores for each word [batch_size, seq_len, tagset_size]\n",
        "        \"\"\"\n",
        "        # Get word embeddings\n",
        "        embeds = self.embedding(sentence)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Process through LSTM\n",
        "        lstm_out, _ = self.lstm(embeds)    # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # Classify each position\n",
        "        tag_space = self.hidden2tag(lstm_out)  # [batch_size, seq_len, tagset_size]\n",
        "\n",
        "        # Apply log_softmax for NLL loss\n",
        "        tag_scores = F.log_softmax(tag_space, dim=2)\n",
        "\n",
        "        return tag_scores\n",
        "\n",
        "    def predict_pos(self, sentence_indices):\n",
        "        \"\"\"Predict POS tags for a sentence.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            scores = self.forward(sentence_indices)\n",
        "            predicted_tags = torch.argmax(scores, dim=2)\n",
        "        return predicted_tags\n",
        "\n",
        "# Create POS tagger\n",
        "vocab_size = 1000\n",
        "embedding_dim = 64\n",
        "hidden_dim = 128\n",
        "tagset_size = 7  # Number of POS tags\n",
        "\n",
        "pos_tagger = AustralianPOSTagger(vocab_size, embedding_dim, hidden_dim, tagset_size).to(DEVICE)\n",
        "\n",
        "print(\"üè∑Ô∏è Australian Tourism POS Tagger:\")\n",
        "print(pos_tagger)\n",
        "\n",
        "# Test with sample sentences\n",
        "print(f\"\\nüéØ POS Tags: {pos_tagger.pos_tags}\")\n",
        "print(f\"üìö Sample Vocabulary: {pos_tagger.sample_vocab[:10]}...\")\n",
        "\n",
        "# Create sample input (word indices)\n",
        "# Simulating \"Sydney beaches are beautiful\"\n",
        "sample_sentence = torch.tensor([[2, 4, 5, 6]], dtype=torch.long).to(DEVICE)  # [batch_size=1, seq_len=4]\n",
        "sample_words = [\"Sydney\", \"beaches\", \"are\", \"beautiful\"]\n",
        "expected_pos = [\"PROPN\", \"NOUN\", \"VERB\", \"ADJ\"]\n",
        "\n",
        "# Forward pass\n",
        "tag_scores = pos_tagger(sample_sentence)\n",
        "predicted_tags = pos_tagger.predict_pos(sample_sentence)\n",
        "\n",
        "print(f\"\\nüß™ Test Results:\")\n",
        "print(f\"  Input shape: {sample_sentence.shape}\")\n",
        "print(f\"  Output shape: {tag_scores.shape}\")\n",
        "print(f\"  Sample sentence: {' '.join(sample_words)}\")\n",
        "print(f\"  Expected POS tags: {' '.join(expected_pos)}\")\n",
        "print(f\"  Predicted tag indices: {predicted_tags.squeeze().tolist()}\")\n",
        "\n",
        "# Show parameter breakdown\n",
        "total_params = sum(p.numel() for p in pos_tagger.parameters())\n",
        "embed_params = pos_tagger.embedding.weight.numel()\n",
        "lstm_params = sum(p.numel() for name, p in pos_tagger.named_parameters() if 'lstm' in name)\n",
        "linear_params = pos_tagger.hidden2tag.weight.numel() + pos_tagger.hidden2tag.bias.numel()\n",
        "\n",
        "print(f\"\\nüìä Parameter Breakdown:\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Embedding parameters: {embed_params:,}\")\n",
        "print(f\"  LSTM parameters: {lstm_params:,}\")\n",
        "print(f\"  Linear parameters: {linear_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CD0UhEJAr2t"
      },
      "source": [
        "### Multilingual LSTM Example: English-Vietnamese Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VszPXfjOAr2u",
        "outputId": "0481a93f-d2a7-482d-ae65-9d9892657bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåè Multilingual Sentiment LSTM:\n",
            "MultilingualSentimentLSTM(\n",
            "  (embedding): Embedding(5000, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (classifier): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n",
            "\n",
            "üß™ Test Results:\n",
            "  Input shape: torch.Size([2, 10])\n",
            "  Output shape: torch.Size([2, 3])\n",
            "  Sentiment classes: ['negative', 'neutral', 'positive']\n",
            "\n",
            "üó£Ô∏è Sample Tourism Phrases:\n",
            "  EN: Sydney beaches are amazing\n",
            "  VI: B√£i bi·ªÉn Sydney tuy·ªát v·ªùi\n",
            "\n",
            "üìä Multilingual LSTM Parameters: 839,043\n"
          ]
        }
      ],
      "source": [
        "# Multilingual Sentiment Analyzer for Australian Tourism\n",
        "class MultilingualSentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM-based sentiment analyzer supporting English and Vietnamese.\n",
        "\n",
        "    Designed for Australian tourism reviews in both languages.\n",
        "    Example texts:\n",
        "    - English: \"Sydney Opera House is absolutely stunning!\"\n",
        "    - Vietnamese: \"Nh√† h√°t Opera Sydney th·∫≠t tuy·ªát v·ªùi!\"\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2):\n",
        "        super(MultilingualSentimentLSTM, self).__init__()\n",
        "\n",
        "        # Shared embedding for both languages\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Bidirectional LSTM for better context understanding\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, num_layers,\n",
        "            batch_first=True, bidirectional=True, dropout=0.3\n",
        "        )\n",
        "\n",
        "        # Classification layers\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.classifier = nn.Linear(hidden_dim * 2, 3)  # 3 sentiment classes\n",
        "\n",
        "        # Sentiment labels\n",
        "        self.sentiments = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "        # Sample multilingual tourism vocabulary\n",
        "        self.sample_phrases = {\n",
        "            'en': [\n",
        "                \"Sydney beaches are amazing\",\n",
        "                \"Melbourne coffee is expensive\",\n",
        "                \"Great Barrier Reef is beautiful\",\n",
        "                \"Tourist traps are disappointing\"\n",
        "            ],\n",
        "            'vi': [\n",
        "                \"B√£i bi·ªÉn Sydney tuy·ªát v·ªùi\",\n",
        "                \"C√† ph√™ Melbourne ƒë·∫Øt ti·ªÅn\",\n",
        "                \"R·∫°n san h√¥ Great Barrier Reef ƒë·∫πp\",\n",
        "                \"B·∫´y du l·ªãch th·∫≠t th·∫•t v·ªçng\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def forward(self, x, lengths=None):\n",
        "        \"\"\"\n",
        "        Forward pass for sentiment classification.\n",
        "\n",
        "        Args:\n",
        "            x: Input token indices [batch_size, seq_len]\n",
        "            lengths: Actual sequence lengths for packing (optional)\n",
        "        \"\"\"\n",
        "        # Embedding lookup\n",
        "        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # LSTM processing\n",
        "        if lengths is not None:\n",
        "            # Pack sequences for variable length inputs\n",
        "            packed = nn.utils.rnn.pack_padded_sequence(\n",
        "                embedded, lengths, batch_first=True, enforce_sorted=False\n",
        "            )\n",
        "            lstm_out, (hidden, _) = self.lstm(packed)\n",
        "            lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "        else:\n",
        "            lstm_out, (hidden, _) = self.lstm(embedded)\n",
        "\n",
        "        # Use last hidden state from both directions\n",
        "        # hidden: [num_layers * num_directions, batch_size, hidden_dim]\n",
        "        forward_hidden = hidden[-2, :, :]   # Last layer, forward direction\n",
        "        backward_hidden = hidden[-1, :, :]  # Last layer, backward direction\n",
        "\n",
        "        # Concatenate bidirectional hidden states\n",
        "        final_hidden = torch.cat([forward_hidden, backward_hidden], dim=1)\n",
        "\n",
        "        # Classification\n",
        "        output = self.dropout(final_hidden)\n",
        "        sentiment_scores = self.classifier(output)\n",
        "\n",
        "        return sentiment_scores\n",
        "\n",
        "# Create multilingual sentiment analyzer\n",
        "multilingual_lstm = MultilingualSentimentLSTM(\n",
        "    vocab_size=5000, embedding_dim=128, hidden_dim=64, num_layers=2\n",
        ").to(DEVICE)\n",
        "\n",
        "print(\"üåè Multilingual Sentiment LSTM:\")\n",
        "print(multilingual_lstm)\n",
        "\n",
        "# Test with sample multilingual input\n",
        "sample_batch = torch.randint(1, 100, (2, 10)).to(DEVICE)  # 2 sentences, max 10 tokens\n",
        "sentiment_scores = multilingual_lstm(sample_batch)\n",
        "\n",
        "print(f\"\\nüß™ Test Results:\")\n",
        "print(f\"  Input shape: {sample_batch.shape}\")\n",
        "print(f\"  Output shape: {sentiment_scores.shape}\")\n",
        "print(f\"  Sentiment classes: {multilingual_lstm.sentiments}\")\n",
        "\n",
        "# Show sample phrases\n",
        "print(f\"\\nüó£Ô∏è Sample Tourism Phrases:\")\n",
        "for lang, phrases in multilingual_lstm.sample_phrases.items():\n",
        "    print(f\"  {lang.upper()}: {phrases[0]}\")\n",
        "\n",
        "# Parameter analysis\n",
        "total_params = sum(p.numel() for p in multilingual_lstm.parameters())\n",
        "print(f\"\\nüìä Multilingual LSTM Parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN4LDOGJAr2u"
      },
      "source": [
        "### 4.4 Transformers\n",
        "\n",
        "**Transformers** are multi-purpose neural networks, prominently used in modern NLP applications. They've revolutionized NLP with models like BERT, GPT, and T5.\n",
        "\n",
        "**Key aspects:**\n",
        "- **Self-attention mechanism**: Allows model to focus on relevant parts of input\n",
        "- **Parallel processing**: Unlike RNNs, can process all positions simultaneously\n",
        "- **Encoder-decoder architecture**: Flexible for various NLP tasks\n",
        "- **PyTorch components**: `nn.Transformer`, `nn.TransformerEncoder`, `nn.TransformerDecoder`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYJyyIyaAr2u",
        "outputId": "cb2096c8-b2db-49ec-8547-9da1565b6521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Australian Tourism Transformer:\n",
            "Model parameters: 5,763,845\n",
            "Categories: ['Attractions', 'Restaurants', 'Activities', 'Accommodation', 'Transportation']\n",
            "\n",
            "üß™ Transformer Test:\n",
            "  Input shape: torch.Size([2, 20])\n",
            "  Output shape: torch.Size([2, 5])\n",
            "  Output categories: 5\n",
            "\n",
            "üèóÔ∏è Transformer Architecture:\n",
            "  Model dimension: 256\n",
            "  Attention heads: 8\n",
            "  Encoder layers: 6\n",
            "  Vocabulary size: 3,000\n",
            "\n",
            "üí° Note: Models like BERT can be built using similar transformer components\n",
            "   with proper parameters, pre-training, and fine-tuning strategies.\n"
          ]
        }
      ],
      "source": [
        "# Simple Transformer for Australian Tourism Text Classification\n",
        "class AustralianTourismTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer-based classifier for Australian tourism content.\n",
        "\n",
        "    Uses PyTorch's built-in transformer components for text classification.\n",
        "    Suitable for tasks like:\n",
        "    - Categorizing tourism content (attractions, restaurants, activities)\n",
        "    - Multilingual tourism review analysis\n",
        "    - Australian destination recommendation\n",
        "\n",
        "    Note: This is a simplified example. Production models like BERT\n",
        "    can be built using similar transformer components with proper parameters.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_layers, num_classes):\n",
        "        super(AustralianTourismTransformer, self).__init__()\n",
        "\n",
        "        # Embedding and positional encoding\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1000, d_model))  # Max sequence length\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # Australian tourism categories\n",
        "        self.categories = [\n",
        "            \"Attractions\",     # Opera House, Uluru, etc.\n",
        "            \"Restaurants\",     # Dining experiences\n",
        "            \"Activities\",      # Surfing, hiking, etc.\n",
        "            \"Accommodation\",   # Hotels, hostels, etc.\n",
        "            \"Transportation\"   # Flights, trains, etc.\n",
        "        ]\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass through transformer.\n",
        "\n",
        "        Args:\n",
        "            x: Input token indices [batch_size, seq_len]\n",
        "            mask: Attention mask for padding (optional)\n",
        "        \"\"\"\n",
        "        seq_len = x.size(1)\n",
        "\n",
        "        # Embedding with positional encoding\n",
        "        x = self.embedding(x) * (self.d_model ** 0.5)  # Scale embeddings\n",
        "        x = x + self.pos_encoding[:seq_len, :].unsqueeze(0)  # Add positional encoding\n",
        "\n",
        "        # Transform through encoder\n",
        "        x = self.transformer(x, src_key_padding_mask=mask)\n",
        "\n",
        "        # Global average pooling for classification\n",
        "        if mask is not None:\n",
        "            # Mask out padding tokens for averaging\n",
        "            x = x.masked_fill(mask.unsqueeze(-1), 0)\n",
        "            x = x.sum(dim=1) / (~mask).sum(dim=1, keepdim=True).float()\n",
        "        else:\n",
        "            x = x.mean(dim=1)  # Simple average pooling\n",
        "\n",
        "        # Classification\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Create transformer model\n",
        "tourism_transformer = AustralianTourismTransformer(\n",
        "    vocab_size=3000,\n",
        "    d_model=256,\n",
        "    nhead=8,\n",
        "    num_layers=6,\n",
        "    num_classes=5\n",
        ").to(DEVICE)\n",
        "\n",
        "print(\"ü§ñ Australian Tourism Transformer:\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in tourism_transformer.parameters()):,}\")\n",
        "print(f\"Categories: {tourism_transformer.categories}\")\n",
        "\n",
        "# Test transformer\n",
        "sample_input = torch.randint(1, 1000, (2, 20)).to(DEVICE)  # 2 samples, 20 tokens max\n",
        "output = tourism_transformer(sample_input)\n",
        "\n",
        "print(f\"\\nüß™ Transformer Test:\")\n",
        "print(f\"  Input shape: {sample_input.shape}\")\n",
        "print(f\"  Output shape: {output.shape}\")\n",
        "print(f\"  Output categories: {len(tourism_transformer.categories)}\")\n",
        "\n",
        "# Show transformer architecture components\n",
        "print(f\"\\nüèóÔ∏è Transformer Architecture:\")\n",
        "print(f\"  Model dimension: {tourism_transformer.d_model}\")\n",
        "print(f\"  Attention heads: 8\")\n",
        "print(f\"  Encoder layers: 6\")\n",
        "print(f\"  Vocabulary size: 3,000\")\n",
        "\n",
        "# Note about building BERT-like models\n",
        "print(f\"\\nüí° Note: Models like BERT can be built using similar transformer components\")\n",
        "print(f\"   with proper parameters, pre-training, and fine-tuning strategies.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KOde24ZAr2u"
      },
      "source": [
        "## 5. Other Essential Layers and Functions\n",
        "\n",
        "Beyond the main layer types, PyTorch offers crucial non-learning layers and functions that are essential for building effective neural networks.\n",
        "\n",
        "### 5.1 Pooling Layers\n",
        "\n",
        "**Pooling layers** reduce the dimensionality of tensors (downsampling) by combining cells and taking the maximum or average value within a defined window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxilT_TPAr2u",
        "outputId": "8d4cd46f-8dec-4960-d008-104c1af40e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèä Pooling Layers Demonstration:\n",
            "Original feature map shape: torch.Size([1, 3, 8, 8])\n",
            "After MaxPool2d(2x2): torch.Size([1, 3, 4, 4])\n",
            "After AvgPool2d(2x2): torch.Size([1, 3, 4, 4])\n",
            "After AdaptiveAvgPool2d(4x4): torch.Size([1, 3, 4, 4])\n",
            "After Global Average Pooling: torch.Size([1, 3, 1, 1])\n",
            "\n",
            "üí° Pooling Benefits:\n",
            "  ‚Ä¢ Reduces computation and memory requirements\n",
            "  ‚Ä¢ Makes feature detection more robust to small shifts\n",
            "  ‚Ä¢ Provides translation invariance\n",
            "  ‚Ä¢ Helps prevent overfitting\n"
          ]
        }
      ],
      "source": [
        "# Pooling Layers Demonstration\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"üèä Pooling Layers Demonstration:\")\n",
        "\n",
        "# Create sample feature map (simulating conv layer output)\n",
        "# Shape: [batch_size, channels, height, width]\n",
        "sample_feature_map = torch.randn(1, 3, 8, 8).to(DEVICE)\n",
        "print(f\"Original feature map shape: {sample_feature_map.shape}\")\n",
        "\n",
        "# MaxPool2d - takes maximum value in each window\n",
        "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "max_pooled = max_pool(sample_feature_map)\n",
        "print(f\"After MaxPool2d(2x2): {max_pooled.shape}\")\n",
        "\n",
        "# AvgPool2d - takes average value in each window\n",
        "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "avg_pooled = avg_pool(sample_feature_map)\n",
        "print(f\"After AvgPool2d(2x2): {avg_pooled.shape}\")\n",
        "\n",
        "# Adaptive pooling - output size is fixed regardless of input size\n",
        "adaptive_avg_pool = nn.AdaptiveAvgPool2d((4, 4))  # Always outputs 4x4\n",
        "adaptive_pooled = adaptive_avg_pool(sample_feature_map)\n",
        "print(f\"After AdaptiveAvgPool2d(4x4): {adaptive_pooled.shape}\")\n",
        "\n",
        "# Global Average Pooling (common in modern architectures)\n",
        "global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "global_pooled = global_avg_pool(sample_feature_map)\n",
        "print(f\"After Global Average Pooling: {global_pooled.shape}\")\n",
        "\n",
        "print(f\"\\nüí° Pooling Benefits:\")\n",
        "print(f\"  ‚Ä¢ Reduces computation and memory requirements\")\n",
        "print(f\"  ‚Ä¢ Makes feature detection more robust to small shifts\")\n",
        "print(f\"  ‚Ä¢ Provides translation invariance\")\n",
        "print(f\"  ‚Ä¢ Helps prevent overfitting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5pNDesxAr2u"
      },
      "source": [
        "### 5.2 Normalization Layers\n",
        "\n",
        "**Normalization layers** like `nn.BatchNorm1d` re-center and normalize the output of one layer before feeding it to the next, leading to faster and more stable training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBgXneImAr2u",
        "outputId": "986be7af-a89c-4cd1-d237-19fdbee0bfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Normalization Layers:\n",
            "BatchNorm1d: torch.Size([32, 128]) -> torch.Size([32, 128])\n",
            "  Mean before: -0.0054, Std before: 0.9875\n",
            "  Mean after: 0.0000, Std after: 1.0001\n",
            "\n",
            "BatchNorm2d: torch.Size([32, 64, 32, 32]) -> torch.Size([32, 64, 32, 32])\n",
            "\n",
            "LayerNorm: torch.Size([32, 128]) -> torch.Size([32, 128])\n",
            "\n",
            "üèõÔ∏è Normalized Australian Classifier:\n",
            "  Parameters: 9,000\n",
            "\n",
            "‚úÖ Normalization Benefits:\n",
            "  ‚Ä¢ Prevents vanishing/exploding gradients\n",
            "  ‚Ä¢ Allows higher learning rates\n",
            "  ‚Ä¢ Faster and more stable convergence\n",
            "  ‚Ä¢ Reduces internal covariate shift\n"
          ]
        }
      ],
      "source": [
        "# Normalization Layers Demonstration\n",
        "print(\"üìä Normalization Layers:\")\n",
        "\n",
        "# BatchNorm for different input types\n",
        "batch_size, features, seq_len = 32, 128, 50\n",
        "\n",
        "# 1D BatchNorm (for fully connected layers)\n",
        "bn1d = nn.BatchNorm1d(features)\n",
        "fc_input = torch.randn(batch_size, features).to(DEVICE)\n",
        "bn1d_output = bn1d(fc_input)\n",
        "print(f\"BatchNorm1d: {fc_input.shape} -> {bn1d_output.shape}\")\n",
        "print(f\"  Mean before: {fc_input.mean():.4f}, Std before: {fc_input.std():.4f}\")\n",
        "print(f\"  Mean after: {bn1d_output.mean():.4f}, Std after: {bn1d_output.std():.4f}\")\n",
        "\n",
        "# 2D BatchNorm (for convolutional layers)\n",
        "bn2d = nn.BatchNorm2d(64)  # 64 channels\n",
        "conv_input = torch.randn(batch_size, 64, 32, 32).to(DEVICE)\n",
        "bn2d_output = bn2d(conv_input)\n",
        "print(f\"\\nBatchNorm2d: {conv_input.shape} -> {bn2d_output.shape}\")\n",
        "\n",
        "# LayerNorm (alternative to BatchNorm, common in transformers)\n",
        "layer_norm = nn.LayerNorm(features)\n",
        "ln_output = layer_norm(fc_input)\n",
        "print(f\"\\nLayerNorm: {fc_input.shape} -> {ln_output.shape}\")\n",
        "\n",
        "# Practical example with Australian city classifier\n",
        "class NormalizedAustralianClassifier(nn.Module):\n",
        "    \"\"\"Australian city classifier with normalization layers.\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_cities):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size)  # Normalize after first layer\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size // 2)  # Normalize after second layer\n",
        "        self.fc3 = nn.Linear(hidden_size // 2, num_cities)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))  # Linear -> BatchNorm -> ReLU\n",
        "        x = F.relu(self.bn2(self.fc2(x)))  # Linear -> BatchNorm -> ReLU\n",
        "        x = self.fc3(x)  # Final layer (no normalization)\n",
        "        return x\n",
        "\n",
        "normalized_model = NormalizedAustralianClassifier(100, 64, 8).to(DEVICE)\n",
        "print(f\"\\nüèõÔ∏è Normalized Australian Classifier:\")\n",
        "print(f\"  Parameters: {sum(p.numel() for p in normalized_model.parameters()):,}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Normalization Benefits:\")\n",
        "print(f\"  ‚Ä¢ Prevents vanishing/exploding gradients\")\n",
        "print(f\"  ‚Ä¢ Allows higher learning rates\")\n",
        "print(f\"  ‚Ä¢ Faster and more stable convergence\")\n",
        "print(f\"  ‚Ä¢ Reduces internal covariate shift\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iCfwyj3Ar2u"
      },
      "source": [
        "### 5.3 Dropout Layers\n",
        "\n",
        "**Dropout** is a regularization technique that helps prevent overfitting by encouraging sparse representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eEiHuubAr2u",
        "outputId": "b4231c0f-2103-4221-c4de-4a8305de9901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé≠ Dropout Layers:\n",
            "Original input:\n",
            "tensor([[-0.2934, -1.2665,  0.6081, -0.2501, -0.3373, -0.7917, -0.4177, -1.2013,\n",
            "         -0.1163,  1.2424],\n",
            "        [-0.9284, -1.5218,  0.0698,  1.4362,  1.1988, -0.2821,  1.9995, -0.0930,\n",
            "         -1.4426, -0.8318],\n",
            "        [-0.3327, -0.1458,  0.0588,  1.1323, -0.6039, -0.9335, -0.8200, -0.5583,\n",
            "         -1.0536, -2.0693],\n",
            "        [ 0.9680, -0.6944, -0.0897, -0.8950,  1.0623,  1.5032, -1.0396, -1.6998,\n",
            "         -1.9106, -1.0283]])\n",
            "\n",
            "During training (dropout active):\n",
            "tensor([[-0.0000, -0.0000,  1.2163, -0.5002, -0.6746, -1.5834, -0.8355, -2.4027,\n",
            "         -0.0000,  0.0000],\n",
            "        [-1.8567, -3.0436,  0.1397,  0.0000,  2.3977, -0.0000,  3.9990, -0.0000,\n",
            "         -0.0000, -1.6637],\n",
            "        [-0.6655, -0.2916,  0.0000,  0.0000, -1.2078, -0.0000, -1.6400, -0.0000,\n",
            "         -2.1071, -0.0000],\n",
            "        [ 1.9360, -0.0000, -0.0000, -0.0000,  0.0000,  3.0064, -2.0791, -3.3995,\n",
            "         -0.0000, -2.0565]])\n",
            "Zeros in output: 18 / 40\n",
            "\n",
            "During evaluation (dropout inactive):\n",
            "tensor([[-0.2934, -1.2665,  0.6081, -0.2501, -0.3373, -0.7917, -0.4177, -1.2013,\n",
            "         -0.1163,  1.2424],\n",
            "        [-0.9284, -1.5218,  0.0698,  1.4362,  1.1988, -0.2821,  1.9995, -0.0930,\n",
            "         -1.4426, -0.8318],\n",
            "        [-0.3327, -0.1458,  0.0588,  1.1323, -0.6039, -0.9335, -0.8200, -0.5583,\n",
            "         -1.0536, -2.0693],\n",
            "        [ 0.9680, -0.6944, -0.0897, -0.8950,  1.0623,  1.5032, -1.0396, -1.6998,\n",
            "         -1.9106, -1.0283]])\n",
            "Zeros in output: 0 / 40\n",
            "\n",
            "üçΩÔ∏è Restaurant Review Classifier:\n",
            "  Embedding dropout: 20%\n",
            "  LSTM dropout: 30%\n",
            "  Classifier dropout: 50%\n",
            "  Restaurant types: ['Asian', 'European', 'Australian', 'Fusion']\n",
            "\n",
            "Training mode output: torch.Size([2, 3])\n",
            "Evaluation mode output: torch.Size([2, 3])\n",
            "\n",
            "üí° Dropout Best Practices:\n",
            "  ‚Ä¢ Always turn off during inference: model.eval()\n",
            "  ‚Ä¢ Use different rates for different layers\n",
            "  ‚Ä¢ Start with 0.2-0.5 and adjust based on overfitting\n",
            "  ‚Ä¢ Higher dropout for layers closer to output\n"
          ]
        }
      ],
      "source": [
        "# Dropout Demonstration\n",
        "print(\"üé≠ Dropout Layers:\")\n",
        "\n",
        "# Create dropout layer\n",
        "dropout = nn.Dropout(p=0.5)  # 50% dropout probability\n",
        "\n",
        "# Sample input\n",
        "sample_input = torch.randn(4, 10).to(DEVICE)\n",
        "print(f\"Original input:\")\n",
        "print(sample_input)\n",
        "\n",
        "# Training mode - dropout is active\n",
        "dropout.train()\n",
        "training_output = dropout(sample_input)\n",
        "print(f\"\\nDuring training (dropout active):\")\n",
        "print(training_output)\n",
        "print(f\"Zeros in output: {(training_output == 0).sum().item()} / {training_output.numel()}\")\n",
        "\n",
        "# Evaluation mode - dropout is inactive\n",
        "dropout.eval()\n",
        "eval_output = dropout(sample_input)\n",
        "print(f\"\\nDuring evaluation (dropout inactive):\")\n",
        "print(eval_output)\n",
        "print(f\"Zeros in output: {(eval_output == 0).sum().item()} / {eval_output.numel()}\")\n",
        "\n",
        "# Practical example: Australian restaurant review classifier with dropout\n",
        "class RestaurantReviewClassifier(nn.Module):\n",
        "    \"\"\"Restaurant review classifier with dropout regularization.\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Multiple dropout layers for different stages\n",
        "        self.embedding_dropout = nn.Dropout(0.2)  # Light dropout for embeddings\n",
        "        self.lstm_dropout = nn.Dropout(0.3)       # Moderate dropout after LSTM\n",
        "        self.classifier_dropout = nn.Dropout(0.5) # Heavy dropout before classifier\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_dim, 3)  # negative, neutral, positive\n",
        "\n",
        "        self.restaurant_types = [\"Asian\", \"European\", \"Australian\", \"Fusion\"]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding with light dropout\n",
        "        embedded = self.embedding(x)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
        "        last_hidden = self.lstm_dropout(hidden[-1])\n",
        "\n",
        "        # Classification with heavy dropout\n",
        "        features = self.classifier_dropout(last_hidden)\n",
        "        sentiment = self.classifier(features)\n",
        "\n",
        "        return sentiment\n",
        "\n",
        "restaurant_classifier = RestaurantReviewClassifier(5000, 128, 64).to(DEVICE)\n",
        "\n",
        "print(f\"\\nüçΩÔ∏è Restaurant Review Classifier:\")\n",
        "print(f\"  Embedding dropout: 20%\")\n",
        "print(f\"  LSTM dropout: 30%\")\n",
        "print(f\"  Classifier dropout: 50%\")\n",
        "print(f\"  Restaurant types: {restaurant_classifier.restaurant_types}\")\n",
        "\n",
        "# Demonstrate training vs evaluation mode\n",
        "sample_reviews = torch.randint(1, 1000, (2, 15)).to(DEVICE)\n",
        "\n",
        "restaurant_classifier.train()\n",
        "train_output = restaurant_classifier(sample_reviews)\n",
        "print(f\"\\nTraining mode output: {train_output.shape}\")\n",
        "\n",
        "restaurant_classifier.eval()\n",
        "eval_output = restaurant_classifier(sample_reviews)\n",
        "print(f\"Evaluation mode output: {eval_output.shape}\")\n",
        "\n",
        "print(f\"\\nüí° Dropout Best Practices:\")\n",
        "print(f\"  ‚Ä¢ Always turn off during inference: model.eval()\")\n",
        "print(f\"  ‚Ä¢ Use different rates for different layers\")\n",
        "print(f\"  ‚Ä¢ Start with 0.2-0.5 and adjust based on overfitting\")\n",
        "print(f\"  ‚Ä¢ Higher dropout for layers closer to output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdK1k1TPAr2u"
      },
      "source": [
        "### 5.4 Activation Functions\n",
        "\n",
        "**Activation functions** introduce non-linearity into the model, enabling neural networks to learn complex, non-linear relationships. Without them, stacking linear layers would just result in another linear transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN2GfS_ZAr2u",
        "outputId": "23e17533-a7cd-4696-b09e-fe416912cbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Activation Functions in PyTorch:\n",
            "\n",
            "üéØ Activation Function Properties:\n",
            "ReLU        : [0.0, 0.0, 0.0, 1.0, 2.0]\n",
            "LeakyReLU   : [-0.20000000298023224, -0.10000000149011612, 0.0, 1.0, 2.0]\n",
            "Tanh        : [-0.9640275835990906, -0.7615941762924194, 0.0, 0.7615941762924194, 0.9640275835990906]\n",
            "Sigmoid     : [0.11920291930437088, 0.2689414322376251, 0.5, 0.7310585975646973, 0.8807970285415649]\n",
            "GELU        : [-0.045500099658966064, -0.1586552858352661, 0.0, 0.8413447141647339, 1.9544999599456787]\n",
            "Swish/SiLU  : [-0.23840583860874176, -0.2689414322376251, 0.0, 0.7310585975646973, 1.7615940570831299]\n",
            "\n",
            "üîß Functional vs Module Forms:\n",
            "Module form (nn.ReLU):     [[0.0, 0.0, 1.0]]\n",
            "Functional form (F.relu):  [[0.0, 0.0, 1.0]]\n",
            "\n",
            "Softmax probabilities: [0.6590011715888977, 0.24243298172950745, 0.09856589138507843]\n",
            "Sum of probabilities: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Activation Functions Comprehensive Demonstration\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"‚ö° Activation Functions in PyTorch:\")\n",
        "\n",
        "# Sample input for demonstration\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "\n",
        "# Common activation functions\n",
        "activations = {\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU(0.1), #\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'GELU': nn.GELU(),  # Popular in transformers\n",
        "    'Swish/SiLU': nn.SiLU(),  # Self-gated activation\n",
        "}\n",
        "\n",
        "print(f\"\\nüéØ Activation Function Properties:\")\n",
        "sample_input = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
        "\n",
        "for name, activation in activations.items():\n",
        "    output = activation(sample_input)\n",
        "    print(f\"{name:12}: {output.tolist()}\")\n",
        "\n",
        "# Functional vs Module forms\n",
        "print(f\"\\nüîß Functional vs Module Forms:\")\n",
        "sample_tensor = torch.tensor([[-1.0, 0.0, 1.0]])\n",
        "\n",
        "# Module form (for use in nn.Sequential or as class attributes)\n",
        "relu_module = nn.ReLU()\n",
        "module_output = relu_module(sample_tensor)\n",
        "print(f\"Module form (nn.ReLU):     {module_output.tolist()}\")\n",
        "\n",
        "# Functional form (for direct application)\n",
        "functional_output = F.relu(sample_tensor)\n",
        "print(f\"Functional form (F.relu):  {functional_output.tolist()}\")\n",
        "\n",
        "# Softmax for classification\n",
        "logits = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "softmax = F.softmax(logits, dim=1)\n",
        "print(f\"\\nSoftmax probabilities: {softmax.tolist()[0]}\")\n",
        "print(f\"Sum of probabilities: {softmax.sum().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt7gdi2sAr2u",
        "outputId": "576e98e9-85d3-4595-d882-ff6dba53a63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üèõÔ∏è Tourism Classifiers with Different Activations:\n",
            "\n",
            "RELU Activation:\n",
            "  Nature: 0.216\n",
            "  Culture: 0.241\n",
            "  Food: 0.265\n",
            "  Adventure: 0.278\n",
            "\n",
            "LEAKY_RELU Activation:\n",
            "  Nature: 0.343\n",
            "  Culture: 0.157\n",
            "  Food: 0.266\n",
            "  Adventure: 0.234\n",
            "\n",
            "GELU Activation:\n",
            "  Nature: 0.273\n",
            "  Culture: 0.236\n",
            "  Food: 0.239\n",
            "  Adventure: 0.252\n",
            "\n",
            "SWISH Activation:\n",
            "  Nature: 0.239\n",
            "  Culture: 0.264\n",
            "  Food: 0.278\n",
            "  Adventure: 0.219\n",
            "\n",
            "üìã Activation Function Guidelines:\n",
            "  ‚Ä¢ ReLU: Most common, simple and effective\n",
            "  ‚Ä¢ LeakyReLU: Solves 'dying ReLU' problem\n",
            "  ‚Ä¢ GELU: Popular in transformers (BERT, GPT)\n",
            "  ‚Ä¢ Swish/SiLU: Self-gated, smooth activation\n",
            "  ‚Ä¢ Tanh: Centered around 0, good for RNNs\n",
            "  ‚Ä¢ Sigmoid: For binary classification output\n"
          ]
        }
      ],
      "source": [
        "# Practical Example: Australian Tourism Content Classifier with Different Activations\n",
        "class TourismClassifierWithActivations(nn.Module):\n",
        "    \"\"\"\n",
        "    Tourism classifier demonstrating different activation functions.\n",
        "\n",
        "    Classifies Australian tourism content into categories:\n",
        "    - Nature (beaches, national parks)\n",
        "    - Culture (museums, galleries)\n",
        "    - Food (restaurants, wineries)\n",
        "    - Adventure (sports, activities)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_classes, activation_type='relu'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n",
        "\n",
        "        # Choose activation function\n",
        "        self.activation_type = activation_type\n",
        "        if activation_type == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation_type == 'leaky_relu':\n",
        "            self.activation = nn.LeakyReLU(0.1)\n",
        "        elif activation_type == 'gelu':\n",
        "            self.activation = nn.GELU()\n",
        "        elif activation_type == 'swish':\n",
        "            self.activation = nn.SiLU()\n",
        "        else:\n",
        "            self.activation = nn.ReLU()  # Default\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.categories = [\"Nature\", \"Culture\", \"Food\", \"Adventure\"]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)  # No activation on final layer for classification\n",
        "        return x\n",
        "\n",
        "    def predict_probabilities(self, x):\n",
        "        \"\"\"Get probability predictions using softmax.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            logits = self.forward(x)\n",
        "            probabilities = F.softmax(logits, dim=1)\n",
        "        return probabilities\n",
        "\n",
        "# Compare different activation functions\n",
        "activation_types = ['relu', 'leaky_relu', 'gelu', 'swish']\n",
        "models = {}\n",
        "\n",
        "print(f\"\\nüèõÔ∏è Tourism Classifiers with Different Activations:\")\n",
        "\n",
        "for activation in activation_types:\n",
        "    model = TourismClassifierWithActivations(50, 32, 4, activation).to(DEVICE)\n",
        "    models[activation] = model\n",
        "\n",
        "    # Test with sample input\n",
        "    sample_input = torch.randn(1, 50).to(DEVICE)\n",
        "    probabilities = model.predict_probabilities(sample_input)\n",
        "\n",
        "    print(f\"\\n{activation.upper()} Activation:\")\n",
        "    for i, (category, prob) in enumerate(zip(model.categories, probabilities[0])):\n",
        "        print(f\"  {category}: {prob.item():.3f}\")\n",
        "\n",
        "print(f\"\\nüìã Activation Function Guidelines:\")\n",
        "print(f\"  ‚Ä¢ ReLU: Most common, simple and effective\")\n",
        "print(f\"  ‚Ä¢ LeakyReLU: Solves 'dying ReLU' problem\")\n",
        "print(f\"  ‚Ä¢ GELU: Popular in transformers (BERT, GPT)\")\n",
        "print(f\"  ‚Ä¢ Swish/SiLU: Self-gated, smooth activation\")\n",
        "print(f\"  ‚Ä¢ Tanh: Centered around 0, good for RNNs\")\n",
        "print(f\"  ‚Ä¢ Sigmoid: For binary classification output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnaxkJcPAr2v"
      },
      "source": [
        "### 5.5 Loss Functions\n",
        "\n",
        "**Loss functions** (also known as criteria) measure the error between a model's prediction and the actual target. Choosing the appropriate loss function is crucial for effective training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uGrvyoTAr2v",
        "outputId": "b4b0395f-0a88-4dcf-f38b-b77d83e6cf71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Loss Functions in PyTorch:\n",
            "\n",
            "üìä Sample Data:\n",
            "  Predictions shape: torch.Size([4, 5])\n",
            "  Class targets: [1, 4, 1, 4]\n",
            "  Regression pred: torch.Size([4, 1])\n",
            "\n",
            "üè∑Ô∏è CrossEntropyLoss: 1.9940\n",
            "   Use case: Multi-class classification (Australian city classification)\n",
            "   Combines LogSoftmax + NLLLoss\n",
            "\n",
            "üìà MSELoss: 0.7074\n",
            "   Use case: Regression (tourism rating prediction)\n",
            "   Formula: (y_pred - y_true)¬≤\n",
            "\n",
            "üî¢ BCELoss: 0.6444\n",
            "   Use case: Binary classification (tourism recommendation: yes/no)\n",
            "\n",
            "üìù NLLLoss: 1.9940\n",
            "   Use case: With log_softmax for classification\n",
            "\n",
            "üõ°Ô∏è HuberLoss: 0.3440\n",
            "   Use case: Robust regression (less sensitive to outliers)\n"
          ]
        }
      ],
      "source": [
        "# Loss Functions Comprehensive Demonstration\n",
        "print(\"üéØ Loss Functions in PyTorch:\")\n",
        "\n",
        "# Sample data for demonstrations\n",
        "batch_size = 4\n",
        "num_classes = 5\n",
        "\n",
        "# Classification data\n",
        "predictions = torch.randn(batch_size, num_classes).to(DEVICE)  # Raw logits\n",
        "class_targets = torch.randint(0, num_classes, (batch_size,)).to(DEVICE)  # Class indices\n",
        "\n",
        "# Regression data\n",
        "regression_pred = torch.randn(batch_size, 1).to(DEVICE)\n",
        "regression_target = torch.randn(batch_size, 1).to(DEVICE)\n",
        "\n",
        "print(f\"\\nüìä Sample Data:\")\n",
        "print(f\"  Predictions shape: {predictions.shape}\")\n",
        "print(f\"  Class targets: {class_targets.tolist()}\")\n",
        "print(f\"  Regression pred: {regression_pred.shape}\")\n",
        "\n",
        "# 1. CrossEntropyLoss - Most common for multi-class classification\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "ce_value = ce_loss(predictions, class_targets)\n",
        "print(f\"\\nüè∑Ô∏è CrossEntropyLoss: {ce_value.item():.4f}\")\n",
        "print(f\"   Use case: Multi-class classification (Australian city classification)\")\n",
        "print(f\"   Combines LogSoftmax + NLLLoss\")\n",
        "\n",
        "# 2. MSELoss - Mean Squared Error for regression\n",
        "mse_loss = nn.MSELoss()\n",
        "mse_value = mse_loss(regression_pred, regression_target)\n",
        "print(f\"\\nüìà MSELoss: {mse_value.item():.4f}\")\n",
        "print(f\"   Use case: Regression (tourism rating prediction)\")\n",
        "print(f\"   Formula: (y_pred - y_true)¬≤\")\n",
        "\n",
        "# 3. BCELoss - Binary Cross Entropy for binary classification\n",
        "binary_pred = torch.sigmoid(torch.randn(batch_size, 1)).to(DEVICE)  # Must be 0-1\n",
        "binary_target = torch.randint(0, 2, (batch_size, 1)).float().to(DEVICE)\n",
        "bce_loss = nn.BCELoss()\n",
        "bce_value = bce_loss(binary_pred, binary_target)\n",
        "print(f\"\\nüî¢ BCELoss: {bce_value.item():.4f}\")\n",
        "print(f\"   Use case: Binary classification (tourism recommendation: yes/no)\")\n",
        "\n",
        "# 4. NLLLoss - Negative Log Likelihood (often used with log_softmax)\n",
        "log_probs = F.log_softmax(predictions, dim=1)\n",
        "nll_loss = nn.NLLLoss()\n",
        "nll_value = nll_loss(log_probs, class_targets)\n",
        "print(f\"\\nüìù NLLLoss: {nll_value.item():.4f}\")\n",
        "print(f\"   Use case: With log_softmax for classification\")\n",
        "\n",
        "# 5. Huber Loss - Robust regression loss\n",
        "huber_loss = nn.HuberLoss(delta=1.0)\n",
        "huber_value = huber_loss(regression_pred, regression_target)\n",
        "print(f\"\\nüõ°Ô∏è HuberLoss: {huber_value.item():.4f}\")\n",
        "print(f\"   Use case: Robust regression (less sensitive to outliers)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5e24DlsAr2v",
        "outputId": "adcea514-d516-4881-88cc-86710955abc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üè¢ Australian Tourism Multi-task Model:\n",
            "  Cities: ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide', 'Darwin', 'Hobart', 'Canberra']\n",
            "  Tasks: City classification, Rating prediction, Recommendation\n",
            "\n",
            "üéØ Loss Functions for Each Task:\n",
            "  City classification: CrossEntropyLoss\n",
            "  Rating prediction: MSELoss\n",
            "  Recommendation: BCELoss\n",
            "\n",
            "üìä Sample Loss Values:\n",
            "  City classification loss: 2.2510\n",
            "  Rating prediction loss: 2.0492\n",
            "  Recommendation loss: 0.6879\n",
            "  Total loss: 4.9880\n",
            "\n",
            "üí° Loss Function Selection Guidelines:\n",
            "  üìã Classification:\n",
            "    ‚Ä¢ CrossEntropyLoss: Multi-class (city, sentiment, category)\n",
            "    ‚Ä¢ BCELoss: Binary (recommend/not, positive/negative)\n",
            "  üìà Regression:\n",
            "    ‚Ä¢ MSELoss: Standard regression (ratings, prices)\n",
            "    ‚Ä¢ HuberLoss: Robust to outliers\n",
            "    ‚Ä¢ MAELoss: Less sensitive to outliers than MSE\n",
            "  üîß Special Cases:\n",
            "    ‚Ä¢ NLLLoss: When using log_softmax manually\n",
            "    ‚Ä¢ Focal Loss: For imbalanced classification (custom)\n",
            "    ‚Ä¢ Triplet Loss: For similarity learning (custom)\n"
          ]
        }
      ],
      "source": [
        "# Practical Example: Australian Tourism Multi-task Model\n",
        "class AustralianTourismMultiTask(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-task model for Australian tourism analysis.\n",
        "\n",
        "    Tasks:\n",
        "    1. City classification (multi-class): Which Australian city?\n",
        "    2. Rating prediction (regression): 1-5 star rating\n",
        "    3. Recommendation (binary): Recommend or not?\n",
        "\n",
        "    Demonstrates different loss functions for different tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared feature extractor\n",
        "        self.shared_layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # Task-specific heads\n",
        "        self.city_classifier = nn.Linear(hidden_size // 2, 8)  # 8 Australian cities\n",
        "        self.rating_predictor = nn.Linear(hidden_size // 2, 1)  # Regression output\n",
        "        self.recommender = nn.Linear(hidden_size // 2, 1)      # Binary classification\n",
        "\n",
        "        # Australian cities\n",
        "        self.cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\",\n",
        "                      \"Adelaide\", \"Darwin\", \"Hobart\", \"Canberra\"]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shared feature extraction\n",
        "        features = self.shared_layers(x)\n",
        "\n",
        "        # Task-specific outputs\n",
        "        city_logits = self.city_classifier(features)\n",
        "        rating = torch.sigmoid(self.rating_predictor(features)) * 5  # Scale to 1-5\n",
        "        recommendation = torch.sigmoid(self.recommender(features))   # 0-1 probability\n",
        "\n",
        "        return city_logits, rating, recommendation\n",
        "\n",
        "# Create multi-task model\n",
        "multitask_model = AustralianTourismMultiTask(100, 64).to(DEVICE)\n",
        "\n",
        "print(f\"\\nüè¢ Australian Tourism Multi-task Model:\")\n",
        "print(f\"  Cities: {multitask_model.cities}\")\n",
        "print(f\"  Tasks: City classification, Rating prediction, Recommendation\")\n",
        "\n",
        "# Define appropriate loss functions for each task\n",
        "city_loss_fn = nn.CrossEntropyLoss()        # Multi-class classification\n",
        "rating_loss_fn = nn.MSELoss()               # Regression\n",
        "recommendation_loss_fn = nn.BCELoss()       # Binary classification\n",
        "\n",
        "print(f\"\\nüéØ Loss Functions for Each Task:\")\n",
        "print(f\"  City classification: CrossEntropyLoss\")\n",
        "print(f\"  Rating prediction: MSELoss\")\n",
        "print(f\"  Recommendation: BCELoss\")\n",
        "\n",
        "# Sample training step\n",
        "sample_input = torch.randn(4, 100).to(DEVICE)\n",
        "sample_city_labels = torch.randint(0, 8, (4,)).to(DEVICE)\n",
        "sample_ratings = torch.rand(4, 1).to(DEVICE) * 5  # 1-5 scale\n",
        "sample_recommendations = torch.randint(0, 2, (4, 1)).float().to(DEVICE)\n",
        "\n",
        "# Forward pass\n",
        "city_pred, rating_pred, rec_pred = multitask_model(sample_input)\n",
        "\n",
        "# Calculate losses\n",
        "city_loss = city_loss_fn(city_pred, sample_city_labels)\n",
        "rating_loss = rating_loss_fn(rating_pred, sample_ratings)\n",
        "rec_loss = recommendation_loss_fn(rec_pred, sample_recommendations)\n",
        "\n",
        "# Combined loss (weighted)\n",
        "total_loss = city_loss + rating_loss + rec_loss\n",
        "\n",
        "print(f\"\\nüìä Sample Loss Values:\")\n",
        "print(f\"  City classification loss: {city_loss.item():.4f}\")\n",
        "print(f\"  Rating prediction loss: {rating_loss.item():.4f}\")\n",
        "print(f\"  Recommendation loss: {rec_loss.item():.4f}\")\n",
        "print(f\"  Total loss: {total_loss.item():.4f}\")\n",
        "\n",
        "print(f\"\\nüí° Loss Function Selection Guidelines:\")\n",
        "print(f\"  üìã Classification:\")\n",
        "print(f\"    ‚Ä¢ CrossEntropyLoss: Multi-class (city, sentiment, category)\")\n",
        "print(f\"    ‚Ä¢ BCELoss: Binary (recommend/not, positive/negative)\")\n",
        "print(f\"  üìà Regression:\")\n",
        "print(f\"    ‚Ä¢ MSELoss: Standard regression (ratings, prices)\")\n",
        "print(f\"    ‚Ä¢ HuberLoss: Robust to outliers\")\n",
        "print(f\"    ‚Ä¢ MAELoss: Less sensitive to outliers than MSE\")\n",
        "print(f\"  üîß Special Cases:\")\n",
        "print(f\"    ‚Ä¢ NLLLoss: When using log_softmax manually\")\n",
        "print(f\"    ‚Ä¢ Focal Loss: For imbalanced classification (custom)\")\n",
        "print(f\"    ‚Ä¢ Triplet Loss: For similarity learning (custom)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWLdTvuyAr2v"
      },
      "source": [
        "## 6. Comprehensive Example: Complete Australian Tourism Analysis Model\n",
        "\n",
        "Let's put everything together in a comprehensive model that demonstrates all the concepts we've learned, with TensorBoard logging and proper device handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g2zTsYtAr2v",
        "outputId": "20cac8a2-db30-4222-c254-793f94e49d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåü Comprehensive Australian Tourism Analysis Model:\n",
            "  Total parameters: 1,100,044\n",
            "  Text processing: 904,192 params\n",
            "  Image processing: 93,696 params\n",
            "  Feature fusion: 99,072 params\n",
            "  Task heads: 3,084 params\n",
            "  Cities: ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide', 'Darwin', 'Hobart', 'Canberra']\n",
            "  Languages: ['en', 'vi']\n"
          ]
        }
      ],
      "source": [
        "# Complete Australian Tourism Analysis System\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class ComprehensiveAustralianTourismModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Comprehensive model combining all PyTorch building blocks:\n",
        "    - Embedding layers for text processing\n",
        "    - Convolutional layers for image features\n",
        "    - LSTM for sequential analysis\n",
        "    - Linear layers for classification\n",
        "    - Proper normalization, dropout, and activations\n",
        "\n",
        "    Multi-modal analysis of Australian tourism content:\n",
        "    - Text: Reviews in English and Vietnamese\n",
        "    - Images: Tourism photos\n",
        "    - Sequential: Time-series visitor data\n",
        "\n",
        "    TensorFlow equivalent would require multiple models or complex subclassing.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size=5000, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "\n",
        "        # Text processing branch (multilingual)\n",
        "        self.text_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.text_lstm = nn.LSTM(embed_dim, hidden_dim//2, batch_first=True, bidirectional=True)\n",
        "        self.text_dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # Image processing branch\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
        "        self.image_dropout = nn.Dropout(0.25)\n",
        "\n",
        "        # Feature fusion\n",
        "        self.fusion_layer = nn.Linear(hidden_dim + 128, 256)\n",
        "        self.fusion_norm = nn.LayerNorm(256)\n",
        "        self.fusion_dropout = nn.Dropout(0.4)\n",
        "\n",
        "        # Multi-task outputs\n",
        "        self.city_classifier = nn.Linear(256, 8)      # Australian cities\n",
        "        self.sentiment_classifier = nn.Linear(256, 3) # Sentiment\n",
        "        self.rating_predictor = nn.Linear(256, 1)     # Rating prediction\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.gelu = nn.GELU()  # For text features\n",
        "\n",
        "        # Model metadata\n",
        "        self.cities = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\",\n",
        "                      \"Adelaide\", \"Darwin\", \"Hobart\", \"Canberra\"]\n",
        "        self.sentiments = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "        # Multilingual support\n",
        "        self.languages = [\"en\", \"vi\"]\n",
        "        self.sample_texts = {\n",
        "            \"en\": [\"Sydney Opera House is stunning\", \"Melbourne coffee is amazing\"],\n",
        "            \"vi\": [\"Nh√† h√°t Opera Sydney tuy·ªát ƒë·∫πp\", \"C√† ph√™ Melbourne tuy·ªát v·ªùi\"]\n",
        "        }\n",
        "\n",
        "    def forward(self, text_input, image_input):\n",
        "        \"\"\"\n",
        "        Multi-modal forward pass.\n",
        "\n",
        "        Args:\n",
        "            text_input: [batch_size, seq_len] - tokenized text\n",
        "            image_input: [batch_size, 3, H, W] - tourism images\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with predictions for all tasks\n",
        "        \"\"\"\n",
        "        batch_size = text_input.size(0)\n",
        "\n",
        "        # Text processing pipeline\n",
        "        text_embedded = self.text_embedding(text_input)\n",
        "        text_lstm_out, (text_hidden, _) = self.text_lstm(text_embedded)\n",
        "        # Concatenate bidirectional hidden states\n",
        "        text_features = torch.cat([text_hidden[-2], text_hidden[-1]], dim=1)\n",
        "        text_features = self.text_dropout(self.gelu(text_features))\n",
        "\n",
        "        # Image processing pipeline\n",
        "        x = self.pool(self.relu(self.batch_norm1(self.conv1(image_input))))\n",
        "        x = self.pool(self.relu(self.batch_norm2(self.conv2(x))))\n",
        "        x = self.pool(self.relu(self.batch_norm3(self.conv3(x))))\n",
        "\n",
        "        # Global average pooling for images\n",
        "        image_features = F.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)\n",
        "        image_features = self.image_dropout(image_features)\n",
        "\n",
        "        # Feature fusion\n",
        "        combined_features = torch.cat([text_features, image_features], dim=1)\n",
        "        fused_features = self.fusion_layer(combined_features)\n",
        "        fused_features = self.fusion_dropout(self.relu(self.fusion_norm(fused_features)))\n",
        "\n",
        "        # Multi-task predictions\n",
        "        city_logits = self.city_classifier(fused_features)\n",
        "        sentiment_logits = self.sentiment_classifier(fused_features)\n",
        "        rating = torch.sigmoid(self.rating_predictor(fused_features)) * 5  # 1-5 scale\n",
        "\n",
        "        # Return as a tuple for tracing compatibility\n",
        "        return city_logits, sentiment_logits, rating, fused_features\n",
        "\n",
        "    def get_model_info(self):\n",
        "        \"\"\"Get comprehensive model information.\"\"\"\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        # Parameter breakdown by component\n",
        "        text_params = sum(p.numel() for name, p in self.named_parameters()\n",
        "                         if any(comp in name for comp in ['text_', 'embedding']))\n",
        "        image_params = sum(p.numel() for name, p in self.named_parameters()\n",
        "                          if any(comp in name for comp in ['conv', 'batch_norm']))\n",
        "        fusion_params = sum(p.numel() for name, p in self.named_parameters()\n",
        "                           if 'fusion' in name)\n",
        "        task_params = sum(p.numel() for name, p in self.named_parameters()\n",
        "                         if any(comp in name for comp in ['classifier', 'predictor']))\n",
        "\n",
        "        return {\n",
        "            'total_parameters': total_params,\n",
        "            'trainable_parameters': trainable_params,\n",
        "            'text_parameters': text_params,\n",
        "            'image_parameters': image_params,\n",
        "            'fusion_parameters': fusion_params,\n",
        "            'task_parameters': task_params,\n",
        "            'cities': self.cities,\n",
        "            'sentiments': self.sentiments,\n",
        "            'supported_languages': self.languages\n",
        "        }\n",
        "\n",
        "# Create comprehensive model\n",
        "comprehensive_model = ComprehensiveAustralianTourismModel().to(DEVICE)\n",
        "\n",
        "print(\"üåü Comprehensive Australian Tourism Analysis Model:\")\n",
        "model_info = comprehensive_model.get_model_info()\n",
        "print(f\"  Total parameters: {model_info['total_parameters']:,}\")\n",
        "print(f\"  Text processing: {model_info['text_parameters']:,} params\")\n",
        "print(f\"  Image processing: {model_info['image_parameters']:,} params\")\n",
        "print(f\"  Feature fusion: {model_info['fusion_parameters']:,} params\")\n",
        "print(f\"  Task heads: {model_info['task_parameters']:,} params\")\n",
        "print(f\"  Cities: {model_info['cities']}\")\n",
        "print(f\"  Languages: {model_info['supported_languages']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6LzEDSRAr2v",
        "outputId": "662a063f-94e3-4e9f-d0e8-c927138f5764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Training Setup Complete:\n",
            "  TensorBoard logs: /content/tensorboard_logs/comprehensive_tourism_model_2025_09_21-12_55_37\n",
            "  Loss functions: ['city_loss', 'sentiment_loss', 'rating_loss']\n",
            "  Optimizer: Adam with component-specific learning rates\n",
            "\n",
            "üß™ Testing Complete Pipeline:\n",
            "  Input shapes:\n",
            "    Text: torch.Size([4, 50])\n",
            "    Images: torch.Size([4, 3, 64, 64])\n",
            "  Output shapes:\n",
            "    City logits: torch.Size([4, 8])\n",
            "    Sentiment logits: torch.Size([4, 3])\n",
            "    Ratings: torch.Size([4, 1])\n",
            "  Loss values:\n",
            "    City: 1.9519\n",
            "    Sentiment: 1.0064\n",
            "    Rating: 3.8730\n",
            "    Total: 4.8948\n",
            "\n",
            "üéØ Sample Predictions:\n",
            "  Predicted city: Canberra\n",
            "  Predicted sentiment: positive\n",
            "  Predicted rating: 3.23 stars\n",
            "\n",
            "üìä TensorBoard Logging Complete!\n",
            "üí° To view logs, run: tensorboard --logdir /content/tensorboard_logs/comprehensive_tourism_model_2025_09_21-12_55_37\n"
          ]
        }
      ],
      "source": [
        "# Training Setup with TensorBoard Logging\n",
        "def setup_pytorch_training():\n",
        "    \"\"\"Setup comprehensive training with TensorBoard logging.\"\"\"\n",
        "\n",
        "    # TensorBoard setup with platform-specific log directory\n",
        "    if IS_COLAB:\n",
        "        root_logdir = \"/content/tensorboard_logs\"\n",
        "    elif IS_KAGGLE:\n",
        "        root_logdir = \"./tensorboard_logs\"\n",
        "    else:\n",
        "        root_logdir = \"./tensorboard_logs\"\n",
        "\n",
        "    # Create timestamped run directory\n",
        "    timestamp = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "    run_logdir = f\"{root_logdir}/comprehensive_tourism_model_{timestamp}\"\n",
        "\n",
        "    # Initialize TensorBoard writer\n",
        "    writer = SummaryWriter(log_dir=run_logdir)\n",
        "\n",
        "    # Define loss functions for multi-task learning\n",
        "    loss_functions = {\n",
        "        'city_loss': nn.CrossEntropyLoss(),\n",
        "        'sentiment_loss': nn.CrossEntropyLoss(),\n",
        "        'rating_loss': nn.MSELoss()\n",
        "    }\n",
        "\n",
        "    # Optimizer with different learning rates for different components\n",
        "    optimizer = torch.optim.Adam([\n",
        "        {'params': comprehensive_model.text_embedding.parameters(), 'lr': 1e-4},\n",
        "        {'params': comprehensive_model.text_lstm.parameters(), 'lr': 1e-4},\n",
        "        {'params': [p for name, p in comprehensive_model.named_parameters()\n",
        "                   if 'conv' in name or 'batch_norm' in name], 'lr': 1e-3},\n",
        "        {'params': [p for name, p in comprehensive_model.named_parameters()\n",
        "                   if 'fusion' in name], 'lr': 1e-3},\n",
        "        {'params': [p for name, p in comprehensive_model.named_parameters()\n",
        "                   if 'classifier' in name or 'predictor' in name], 'lr': 1e-3}\n",
        "    ])\n",
        "\n",
        "    return writer, loss_functions, optimizer, run_logdir\n",
        "\n",
        "# Setup training components\n",
        "writer, loss_functions, optimizer, run_logdir = setup_pytorch_training()\n",
        "\n",
        "print(f\"\\nüìä Training Setup Complete:\")\n",
        "print(f\"  TensorBoard logs: {run_logdir}\")\n",
        "print(f\"  Loss functions: {list(loss_functions.keys())}\")\n",
        "print(f\"  Optimizer: Adam with component-specific learning rates\")\n",
        "\n",
        "# Create sample data for testing\n",
        "def create_sample_data(batch_size=8):\n",
        "    \"\"\"Create sample multi-modal data.\"\"\"\n",
        "    # Sample text data (tokenized)\n",
        "    text_data = torch.randint(1, 1000, (batch_size, 50)).to(DEVICE)\n",
        "\n",
        "    # Sample image data (tourism photos)\n",
        "    image_data = torch.randn(batch_size, 3, 64, 64).to(DEVICE)\n",
        "\n",
        "    # Sample targets\n",
        "    city_targets = torch.randint(0, 8, (batch_size,)).to(DEVICE)\n",
        "    sentiment_targets = torch.randint(0, 3, (batch_size,)).to(DEVICE)\n",
        "    rating_targets = torch.rand(batch_size, 1).to(DEVICE) * 5\n",
        "\n",
        "    return {\n",
        "        'text': text_data,\n",
        "        'images': image_data,\n",
        "        'city_labels': city_targets,\n",
        "        'sentiment_labels': sentiment_targets,\n",
        "        'rating_labels': rating_targets\n",
        "    }\n",
        "\n",
        "# Test the complete pipeline\n",
        "print(f\"\\nüß™ Testing Complete Pipeline:\")\n",
        "sample_data = create_sample_data(4)\n",
        "\n",
        "# Forward pass\n",
        "comprehensive_model.train()\n",
        "city_pred, sentiment_pred, rating_pred, _ = comprehensive_model(sample_data['text'], sample_data['images'])\n",
        "\n",
        "# Calculate losses\n",
        "city_loss = loss_functions['city_loss'](city_pred, sample_data['city_labels'])\n",
        "sentiment_loss = loss_functions['sentiment_loss'](sentiment_pred, sample_data['sentiment_labels'])\n",
        "rating_loss = loss_functions['rating_loss'](rating_pred, sample_data['rating_labels'])\n",
        "\n",
        "# Combined loss with weights\n",
        "total_loss = city_loss + sentiment_loss + 0.5 * rating_loss\n",
        "\n",
        "print(f\"  Input shapes:\")\n",
        "print(f\"    Text: {sample_data['text'].shape}\")\n",
        "print(f\"    Images: {sample_data['images'].shape}\")\n",
        "print(f\"  Output shapes:\")\n",
        "print(f\"    City logits: {city_pred.shape}\")\n",
        "print(f\"    Sentiment logits: {sentiment_pred.shape}\")\n",
        "print(f\"    Ratings: {rating_pred.shape}\")\n",
        "print(f\"  Loss values:\")\n",
        "print(f\"    City: {city_loss.item():.4f}\")\n",
        "print(f\"    Sentiment: {sentiment_loss.item():.4f}\")\n",
        "print(f\"    Rating: {rating_loss.item():.4f}\")\n",
        "print(f\"    Total: {total_loss.item():.4f}\")\n",
        "\n",
        "# Log to TensorBoard\n",
        "writer.add_scalar('Loss/City_Classification', city_loss.item(), 0)\n",
        "writer.add_scalar('Loss/Sentiment_Analysis', sentiment_loss.item(), 0)\n",
        "writer.add_scalar('Loss/Rating_Prediction', rating_loss.item(), 0)\n",
        "writer.add_scalar('Loss/Total', total_loss.item(), 0)\n",
        "\n",
        "# Log model graph\n",
        "writer.add_graph(comprehensive_model, (sample_data['text'][:1], sample_data['images'][:1]))\n",
        "\n",
        "# Log sample predictions\n",
        "with torch.no_grad():\n",
        "    comprehensive_model.eval()\n",
        "    city_eval_pred, sentiment_eval_pred, rating_eval_pred, _ = comprehensive_model(sample_data['text'][:1], sample_data['images'][:1])\n",
        "\n",
        "    city_probs = F.softmax(city_eval_pred, dim=1)\n",
        "    sentiment_probs = F.softmax(sentiment_eval_pred, dim=1)\n",
        "\n",
        "    print(f\"\\nüéØ Sample Predictions:\")\n",
        "    print(f\"  Predicted city: {comprehensive_model.cities[torch.argmax(city_probs).item()]}\")\n",
        "    print(f\"  Predicted sentiment: {comprehensive_model.sentiments[torch.argmax(sentiment_probs).item()]}\")\n",
        "    print(f\"  Predicted rating: {rating_eval_pred.item():.2f} stars\")\n",
        "\n",
        "writer.close()\n",
        "\n",
        "print(f\"\\nüìä TensorBoard Logging Complete!\")\n",
        "print(f\"üí° To view logs, run: tensorboard --logdir {run_logdir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ0wYDJKAr2v"
      },
      "source": [
        "## 7. Summary and Key Takeaways\n",
        "\n",
        "üéâ **Congratulations!** You've mastered the fundamentals of building models with PyTorch!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhdVxah_Ar2v",
        "outputId": "823e8921-08b8-469c-f19f-b09584cca6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéì PyTorch Model Building: Complete Learning Summary\n",
            "============================================================\n",
            "\n",
            "üèóÔ∏è CORE CLASSES:\n",
            "  üì¶ nn.Module: Base class for all models and layers\n",
            "    ‚Ä¢ Must implement __init__ and forward methods\n",
            "    ‚Ä¢ Automatic parameter registration\n",
            "    ‚Ä¢ Built-in training/evaluation modes\n",
            "  ‚öôÔ∏è nn.Parameter: Learnable tensors with requires_grad=True\n",
            "    ‚Ä¢ Automatic gradient tracking\n",
            "    ‚Ä¢ Discoverable by optimizers\n",
            "\n",
            "üß± LAYER TYPES:\n",
            "  üîó Linear Layers (nn.Linear):\n",
            "    ‚Ä¢ Fully connected layers\n",
            "    ‚Ä¢ Every input influences every output\n",
            "    ‚Ä¢ Common in classification heads\n",
            "  üñºÔ∏è Convolutional Layers (nn.Conv2d):\n",
            "    ‚Ä¢ For spatial data (images)\n",
            "    ‚Ä¢ Local feature detection\n",
            "    ‚Ä¢ Translation invariance\n",
            "  üîÑ Recurrent Layers (nn.LSTM, nn.GRU):\n",
            "    ‚Ä¢ For sequential data (text, time series)\n",
            "    ‚Ä¢ Hidden state memory\n",
            "    ‚Ä¢ Handle variable length sequences\n",
            "  ü§ñ Transformers (nn.Transformer):\n",
            "    ‚Ä¢ Self-attention mechanism\n",
            "    ‚Ä¢ Parallel processing\n",
            "    ‚Ä¢ State-of-the-art for NLP\n",
            "\n",
            "üõ†Ô∏è ESSENTIAL FUNCTIONS:\n",
            "  üèä Pooling (nn.MaxPool2d, nn.AvgPool2d):\n",
            "    ‚Ä¢ Dimensionality reduction\n",
            "    ‚Ä¢ Robust feature detection\n",
            "  üìä Normalization (nn.BatchNorm, nn.LayerNorm):\n",
            "    ‚Ä¢ Stable training\n",
            "    ‚Ä¢ Faster convergence\n",
            "  üé≠ Dropout (nn.Dropout):\n",
            "    ‚Ä¢ Regularization\n",
            "    ‚Ä¢ Prevents overfitting\n",
            "  ‚ö° Activations (ReLU, GELU, Sigmoid):\n",
            "    ‚Ä¢ Non-linearity\n",
            "    ‚Ä¢ Enable complex representations\n",
            "  üéØ Loss Functions (CrossEntropy, MSE, BCE):\n",
            "    ‚Ä¢ Task-specific error measurement\n",
            "    ‚Ä¢ Guide training optimization\n",
            "\n",
            "üåè MULTILINGUAL & AUSTRALIAN CONTEXT:\n",
            "  1. Australian city classification (Sydney, Melbourne, etc.)\n",
            "  2. Tourism content analysis and recommendation\n",
            "  3. English-Vietnamese translation for tourism\n",
            "  4. Restaurant review sentiment analysis\n",
            "  5. Multi-modal tourism content processing\n",
            "\n",
            "üîÑ TENSORFLOW VS PYTORCH:\n",
            "  Model Definition:\n",
            "    TensorFlow: tf.keras.Sequential/Functional\n",
            "    PyTorch: nn.Module subclass\n",
            "  Training Loop:\n",
            "    TensorFlow: model.fit() automatic\n",
            "    PyTorch: Manual with optimizer steps\n",
            "  Execution:\n",
            "    TensorFlow: Graph/Eager modes\n",
            "    PyTorch: Always eager (dynamic)\n",
            "  Device Management:\n",
            "    TensorFlow: Automatic strategies\n",
            "    PyTorch: Explicit .to(device)\n",
            "  Parameter Access:\n",
            "    TensorFlow: model.trainable_variables\n",
            "    PyTorch: model.parameters()\n",
            "\n",
            "üöÄ NEXT STEPS IN YOUR PYTORCH JOURNEY:\n",
            "  üîß Advanced Architectures: ResNet, DenseNet, Vision Transformers\n",
            "  üèãÔ∏è Training Strategies: Learning rate scheduling, mixed precision\n",
            "  ü§ó Hugging Face Integration: Pre-trained transformers, fine-tuning\n",
            "  üìä Data Loading: Custom datasets, data augmentation\n",
            "  üéØ Model Optimization: Quantization, pruning, ONNX export\n",
            "  üåê Deployment: TorchServe, mobile deployment\n",
            "\n",
            "üí° KEY BEST PRACTICES:\n",
            "  ‚úÖ Always call super().__init__() in nn.Module subclasses\n",
            "  ‚úÖ Use appropriate loss functions for your task type\n",
            "  ‚úÖ Implement proper device handling for CPU/GPU compatibility\n",
            "  ‚úÖ Add normalization and dropout for stable training\n",
            "  ‚úÖ Use TensorBoard for training visualization\n",
            "  ‚úÖ Follow the train()/eval() mode switching pattern\n",
            "  ‚úÖ Implement proper error handling and data validation\n",
            "\n",
            "üéâ You're now equipped to build sophisticated PyTorch models!\n",
            "Ready to tackle real-world deep learning challenges with confidence.\n",
            "\n",
            "ü§ó Next recommended: Hugging Face transformers for state-of-the-art NLP!\n"
          ]
        }
      ],
      "source": [
        "# Summary of PyTorch Model Building Concepts\n",
        "print(\"üéì PyTorch Model Building: Complete Learning Summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüèóÔ∏è CORE CLASSES:\")\n",
        "print(\"  üì¶ nn.Module: Base class for all models and layers\")\n",
        "print(\"    ‚Ä¢ Must implement __init__ and forward methods\")\n",
        "print(\"    ‚Ä¢ Automatic parameter registration\")\n",
        "print(\"    ‚Ä¢ Built-in training/evaluation modes\")\n",
        "print(\"  ‚öôÔ∏è nn.Parameter: Learnable tensors with requires_grad=True\")\n",
        "print(\"    ‚Ä¢ Automatic gradient tracking\")\n",
        "print(\"    ‚Ä¢ Discoverable by optimizers\")\n",
        "\n",
        "print(\"\\nüß± LAYER TYPES:\")\n",
        "print(\"  üîó Linear Layers (nn.Linear):\")\n",
        "print(\"    ‚Ä¢ Fully connected layers\")\n",
        "print(\"    ‚Ä¢ Every input influences every output\")\n",
        "print(\"    ‚Ä¢ Common in classification heads\")\n",
        "print(\"  üñºÔ∏è Convolutional Layers (nn.Conv2d):\")\n",
        "print(\"    ‚Ä¢ For spatial data (images)\")\n",
        "print(\"    ‚Ä¢ Local feature detection\")\n",
        "print(\"    ‚Ä¢ Translation invariance\")\n",
        "print(\"  üîÑ Recurrent Layers (nn.LSTM, nn.GRU):\")\n",
        "print(\"    ‚Ä¢ For sequential data (text, time series)\")\n",
        "print(\"    ‚Ä¢ Hidden state memory\")\n",
        "print(\"    ‚Ä¢ Handle variable length sequences\")\n",
        "print(\"  ü§ñ Transformers (nn.Transformer):\")\n",
        "print(\"    ‚Ä¢ Self-attention mechanism\")\n",
        "print(\"    ‚Ä¢ Parallel processing\")\n",
        "print(\"    ‚Ä¢ State-of-the-art for NLP\")\n",
        "\n",
        "print(\"\\nüõ†Ô∏è ESSENTIAL FUNCTIONS:\")\n",
        "print(\"  üèä Pooling (nn.MaxPool2d, nn.AvgPool2d):\")\n",
        "print(\"    ‚Ä¢ Dimensionality reduction\")\n",
        "print(\"    ‚Ä¢ Robust feature detection\")\n",
        "print(\"  üìä Normalization (nn.BatchNorm, nn.LayerNorm):\")\n",
        "print(\"    ‚Ä¢ Stable training\")\n",
        "print(\"    ‚Ä¢ Faster convergence\")\n",
        "print(\"  üé≠ Dropout (nn.Dropout):\")\n",
        "print(\"    ‚Ä¢ Regularization\")\n",
        "print(\"    ‚Ä¢ Prevents overfitting\")\n",
        "print(\"  ‚ö° Activations (ReLU, GELU, Sigmoid):\")\n",
        "print(\"    ‚Ä¢ Non-linearity\")\n",
        "print(\"    ‚Ä¢ Enable complex representations\")\n",
        "print(\"  üéØ Loss Functions (CrossEntropy, MSE, BCE):\")\n",
        "print(\"    ‚Ä¢ Task-specific error measurement\")\n",
        "print(\"    ‚Ä¢ Guide training optimization\")\n",
        "\n",
        "print(\"\\nüåè MULTILINGUAL & AUSTRALIAN CONTEXT:\")\n",
        "australian_examples = [\n",
        "    \"Australian city classification (Sydney, Melbourne, etc.)\",\n",
        "    \"Tourism content analysis and recommendation\",\n",
        "    \"English-Vietnamese translation for tourism\",\n",
        "    \"Restaurant review sentiment analysis\",\n",
        "    \"Multi-modal tourism content processing\"\n",
        "]\n",
        "\n",
        "for i, example in enumerate(australian_examples, 1):\n",
        "    print(f\"  {i}. {example}\")\n",
        "\n",
        "print(\"\\nüîÑ TENSORFLOW VS PYTORCH:\")\n",
        "comparisons = [\n",
        "    (\"Model Definition\", \"tf.keras.Sequential/Functional\", \"nn.Module subclass\"),\n",
        "    (\"Training Loop\", \"model.fit() automatic\", \"Manual with optimizer steps\"),\n",
        "    (\"Execution\", \"Graph/Eager modes\", \"Always eager (dynamic)\"),\n",
        "    (\"Device Management\", \"Automatic strategies\", \"Explicit .to(device)\"),\n",
        "    (\"Parameter Access\", \"model.trainable_variables\", \"model.parameters()\")\n",
        "]\n",
        "\n",
        "for concept, tf_way, pytorch_way in comparisons:\n",
        "    print(f\"  {concept}:\")\n",
        "    print(f\"    TensorFlow: {tf_way}\")\n",
        "    print(f\"    PyTorch: {pytorch_way}\")\n",
        "\n",
        "print(\"\\nüöÄ NEXT STEPS IN YOUR PYTORCH JOURNEY:\")\n",
        "next_steps = [\n",
        "    \"üîß Advanced Architectures: ResNet, DenseNet, Vision Transformers\",\n",
        "    \"üèãÔ∏è Training Strategies: Learning rate scheduling, mixed precision\",\n",
        "    \"ü§ó Hugging Face Integration: Pre-trained transformers, fine-tuning\",\n",
        "    \"üìä Data Loading: Custom datasets, data augmentation\",\n",
        "    \"üéØ Model Optimization: Quantization, pruning, ONNX export\",\n",
        "    \"üåê Deployment: TorchServe, mobile deployment\"\n",
        "]\n",
        "\n",
        "for step in next_steps:\n",
        "    print(f\"  {step}\")\n",
        "\n",
        "print(\"\\nüí° KEY BEST PRACTICES:\")\n",
        "best_practices = [\n",
        "    \"Always call super().__init__() in nn.Module subclasses\",\n",
        "    \"Use appropriate loss functions for your task type\",\n",
        "    \"Implement proper device handling for CPU/GPU compatibility\",\n",
        "    \"Add normalization and dropout for stable training\",\n",
        "    \"Use TensorBoard for training visualization\",\n",
        "    \"Follow the train()/eval() mode switching pattern\",\n",
        "    \"Implement proper error handling and data validation\"\n",
        "]\n",
        "\n",
        "for practice in best_practices:\n",
        "    print(f\"  ‚úÖ {practice}\")\n",
        "\n",
        "print(\"\\nüéâ You're now equipped to build sophisticated PyTorch models!\")\n",
        "print(\"Ready to tackle real-world deep learning challenges with confidence.\")\n",
        "print(\"\\nü§ó Next recommended: Hugging Face transformers for state-of-the-art NLP!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}