{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Sequence-to-Sequence Translation: English ‚Üí Vietnamese\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/pytorch-mastery/blob/main/examples/language_translation/01_seq2seq_translation.ipynb)\n",
    "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-blue?logo=github)](https://github.com/vuhung16au/pytorch-mastery/blob/main/examples/language_translation/01_seq2seq_translation.ipynb)\n",
    "\n",
    "Complete implementation of sequence-to-sequence neural machine translation using PyTorch. This tutorial focuses on English-Vietnamese translation with Australian tourism examples, demonstrating core concepts of encoder-decoder architectures.\n",
    "\n",
    "## Learning Objectives\n",
    "- ‚úÖ Understand encoder-decoder architecture for sequence-to-sequence learning\n",
    "- ‚úÖ Implement LSTM-based translation model from scratch in PyTorch\n",
    "- ‚úÖ Train on English-Vietnamese pairs with Australian tourism context\n",
    "- ‚úÖ Compare with TensorFlow approaches and highlight PyTorch advantages\n",
    "- ‚úÖ Evaluate translation quality using BLEU scores\n",
    "- ‚úÖ Deploy model with device-aware training and TensorBoard logging\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "Following repository standards for environment detection and package installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules or \"kaggle\" in os.environ.get('KAGGLE_URL_BASE', '')\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    !apt update -qq\n",
    "    !apt install -y -qq software-properties-common\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nSetting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nSetting up local environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for this notebook\n",
    "required_packages = [\n",
    "    \"torch\",\n",
    "    \"transformers\", \n",
    "    \"datasets\",\n",
    "    \"tokenizers\",\n",
    "    \"pandas\",\n",
    "    \"seaborn\",\n",
    "    \"matplotlib\",\n",
    "    \"tensorboard\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        !pip install -q {package}\n",
    "    else:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                      capture_output=True)\n",
    "    print(f\"‚úì {package}\")\n",
    "\n",
    "# Verify PyTorch installation\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch {torch.__version__} ready!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup\n",
    "\n",
    "Import all necessary libraries following PyTorch best practices and repository standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Standard alias for functional operations\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seaborn style for better notebook aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"üì¶ All libraries imported successfully!\")\n",
    "print(f\"üî¢ Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Device Detection and Configuration\n",
    "\n",
    "Implement intelligent device detection following repository standards for CUDA, MPS, and CPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_device():\n",
    "    \"\"\"\n",
    "    Detect the best available PyTorch device with comprehensive hardware support.\n",
    "    \n",
    "    Priority order:\n",
    "    1. CUDA (NVIDIA GPUs) - Best performance for deep learning\n",
    "    2. MPS (Apple Silicon) - Optimized for M1/M2/M3 Macs  \n",
    "    3. CPU (Universal) - Always available fallback\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The optimal device for PyTorch operations\n",
    "        str: Human-readable device description for logging\n",
    "    \"\"\"\n",
    "    import platform\n",
    "    \n",
    "    # Check for CUDA (NVIDIA GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        device_info = f\"CUDA GPU: {gpu_name}\"\n",
    "        \n",
    "        # Additional CUDA info for optimization\n",
    "        cuda_version = torch.version.cuda\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        \n",
    "        print(f\"üöÄ Using CUDA acceleration\")\n",
    "        print(f\"   GPU: {gpu_name}\")\n",
    "        print(f\"   CUDA Version: {cuda_version}\")\n",
    "        print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        return device, device_info\n",
    "    \n",
    "    # Check for MPS (Apple Silicon)\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        device_info = \"Apple Silicon MPS\"\n",
    "        \n",
    "        # Get system info for Apple Silicon\n",
    "        system_info = platform.uname()\n",
    "        \n",
    "        print(f\"üçé Using Apple Silicon MPS acceleration\")\n",
    "        print(f\"   System: {system_info.system} {system_info.release}\")\n",
    "        print(f\"   Machine: {system_info.machine}\")\n",
    "        print(f\"   Processor: {system_info.processor}\")\n",
    "        \n",
    "        return device, device_info\n",
    "    \n",
    "    # Fallback to CPU\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_info = \"CPU (No GPU acceleration available)\"\n",
    "        \n",
    "        # Get CPU info for optimization guidance\n",
    "        cpu_count = torch.get_num_threads()\n",
    "        system_info = platform.uname()\n",
    "        \n",
    "        print(f\"üíª Using CPU (no GPU acceleration detected)\")\n",
    "        print(f\"   Processor: {system_info.processor}\")\n",
    "        print(f\"   PyTorch Threads: {cpu_count}\")\n",
    "        print(f\"   System: {system_info.system} {system_info.release}\")\n",
    "        \n",
    "        # Provide optimization suggestions for CPU-only setups\n",
    "        print(f\"\\nüí° CPU Optimization Tips:\")\n",
    "        print(f\"   ‚Ä¢ Reduce batch size to prevent memory issues\")\n",
    "        print(f\"   ‚Ä¢ Consider using smaller models for faster training\")\n",
    "        print(f\"   ‚Ä¢ Enable PyTorch optimizations: torch.set_num_threads({cpu_count})\")\n",
    "        \n",
    "        return device, device_info\n",
    "\n",
    "# Usage in notebook\n",
    "device, device_info = detect_device()\n",
    "print(f\"\\n‚úÖ PyTorch device selected: {device}\")\n",
    "print(f\"üìä Device info: {device_info}\")\n",
    "\n",
    "# Set global device for the notebook\n",
    "DEVICE = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Australian Translation Dataset\n",
    "\n",
    "Create a custom dataset with Australian tourism and culture examples for English-Vietnamese translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Australian English-Vietnamese Translation Dataset\n",
    "AUSTRALIAN_TRANSLATION_PAIRS = [\n",
    "    # Tourism and landmarks\n",
    "    (\"The Sydney Opera House attracts millions of visitors each year\", \n",
    "     \"Nh√† h√°t Opera Sydney thu h√∫t h√†ng tri·ªáu du kh√°ch m·ªói nƒÉm\"),\n",
    "    (\"Melbourne is famous for its coffee culture and street art\", \n",
    "     \"Melbourne n·ªïi ti·∫øng v·ªõi vƒÉn h√≥a c√† ph√™ v√† ngh·ªá thu·∫≠t ƒë∆∞·ªùng ph·ªë\"),\n",
    "    (\"Bondi Beach is perfect for surfing and swimming\", \n",
    "     \"B√£i bi·ªÉn Bondi ho√†n h·∫£o cho l∆∞·ªõt s√≥ng v√† b∆°i l·ªôi\"),\n",
    "    (\"The Great Barrier Reef is a UNESCO World Heritage site\", \n",
    "     \"R·∫°n san h√¥ Great Barrier Reef l√† di s·∫£n th·∫ø gi·ªõi UNESCO\"),\n",
    "    (\"Perth has beautiful beaches and a Mediterranean climate\", \n",
    "     \"Perth c√≥ nh·ªØng b√£i bi·ªÉn ƒë·∫πp v√† kh√≠ h·∫≠u ƒê·ªãa Trung H·∫£i\"),\n",
    "    (\"Uluru is sacred to the Aboriginal people of Australia\", \n",
    "     \"Uluru l√† n∆°i thi√™ng li√™ng ƒë·ªëi v·ªõi ng∆∞·ªùi th·ªï d√¢n Australia\"),\n",
    "    (\"The Sydney Harbour Bridge offers spectacular views\", \n",
    "     \"C·∫ßu C·∫£ng Sydney mang ƒë·∫øn t·∫ßm nh√¨n ngo·∫°n m·ª•c\"),\n",
    "    (\"Brisbane is the gateway to the Gold Coast\", \n",
    "     \"Brisbane l√† c·ª≠a ng√µ ƒë·∫øn Gold Coast\"),\n",
    "    (\"Adelaide is known for its wine regions and festivals\", \n",
    "     \"Adelaide n·ªïi ti·∫øng v·ªõi v√πng r∆∞·ª£u vang v√† l·ªÖ h·ªôi\"),\n",
    "    (\"Darwin is the gateway to Kakadu National Park\", \n",
    "     \"Darwin l√† c·ª≠a ng√µ ƒë·∫øn C√¥ng vi√™n Qu·ªëc gia Kakadu\"),\n",
    "    \n",
    "    # Culture and lifestyle\n",
    "    (\"Australian coffee is among the best in the world\", \n",
    "     \"C√† ph√™ √öc l√† m·ªôt trong nh·ªØng lo·∫°i t·ªët nh·∫•t th·∫ø gi·ªõi\"),\n",
    "    (\"The Aboriginal culture has a history of over 60,000 years\", \n",
    "     \"VƒÉn h√≥a th·ªï d√¢n c√≥ l·ªãch s·ª≠ h∆°n 60,000 nƒÉm\"),\n",
    "    (\"AFL is the most popular sport in Melbourne\", \n",
    "     \"AFL l√† m√¥n th·ªÉ thao ph·ªï bi·∫øn nh·∫•t ·ªü Melbourne\"),\n",
    "    (\"Cricket is Australia's national summer sport\", \n",
    "     \"Cricket l√† m√¥n th·ªÉ thao m√πa h√® qu·ªëc gia c·ªßa Australia\"),\n",
    "    (\"Fair dinkum means genuine in Australian slang\", \n",
    "     \"Fair dinkum c√≥ nghƒ©a l√† ch√≠nh hi·ªáu trong ti·∫øng l√≥ng √öc\"),\n",
    "    \n",
    "    # Food and dining\n",
    "    (\"Try the famous Australian meat pie with tomato sauce\", \n",
    "     \"H√£y th·ª≠ b√°nh th·ªãt √öc n·ªïi ti·∫øng v·ªõi t∆∞∆°ng c√†\"),\n",
    "    (\"Barramundi is a popular fish in Australian cuisine\", \n",
    "     \"C√° barramundi l√† lo·∫°i c√° ph·ªï bi·∫øn trong ·∫©m th·ª±c √öc\"),\n",
    "    (\"Lamington cake is a traditional Australian dessert\", \n",
    "     \"B√°nh Lamington l√† m√≥n tr√°ng mi·ªáng truy·ªÅn th·ªëng c·ªßa √öc\"),\n",
    "    (\"Vegemite is a dark brown Australian food paste\", \n",
    "     \"Vegemite l√† lo·∫°i t∆∞∆°ng th·ª±c ph·∫©m m√†u n√¢u ƒë·∫≠m c·ªßa √öc\"),\n",
    "    (\"Tim Tam biscuits are perfect with coffee\", \n",
    "     \"B√°nh quy Tim Tam ho√†n h·∫£o khi d√πng v·ªõi c√† ph√™\"),\n",
    "    \n",
    "    # Wildlife and nature\n",
    "    (\"Kangaroos are iconic Australian marsupials\", \n",
    "     \"Kangaroo l√† lo√†i th√∫ c√≥ t√∫i bi·ªÉu t∆∞·ª£ng c·ªßa Australia\"),\n",
    "    (\"Koalas sleep up to 20 hours per day\", \n",
    "     \"Koala ng·ªß t·ªõi 20 ti·∫øng m·ªói ng√†y\"),\n",
    "    (\"Platypus is one of the few venomous mammals\", \n",
    "     \"Platypus l√† m·ªôt trong s·ªë √≠t ƒë·ªông v·∫≠t c√≥ v√∫ c√≥ n·ªçc ƒë·ªôc\"),\n",
    "    (\"Wombats have cube-shaped droppings\", \n",
    "     \"Wombat c√≥ ph√¢n h√¨nh kh·ªëi vu√¥ng\"),\n",
    "    (\"Dingoes are Australia's largest land predator\", \n",
    "     \"Dingo l√† lo√†i ƒë·ªông v·∫≠t sƒÉn m·ªìi tr√™n c·∫°n l·ªõn nh·∫•t c·ªßa Australia\")\n",
    "]\n",
    "\n",
    "print(f\"üìä Australian Translation Dataset:\")\n",
    "print(f\"   Total translation pairs: {len(AUSTRALIAN_TRANSLATION_PAIRS)}\")\n",
    "print(f\"   Categories: Tourism, Culture, Food, Wildlife\")\n",
    "print(f\"   Language pair: English ‚Üí Vietnamese\")\n",
    "\n",
    "# Display sample translations\n",
    "print(f\"\\nüåü Sample Translations:\")\n",
    "for i in range(3):\n",
    "    en_text, vi_text = AUSTRALIAN_TRANSLATION_PAIRS[i]\n",
    "    print(f\"{i+1}. EN: {en_text}\")\n",
    "    print(f\"   VI: {vi_text}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vocabulary and Tokenization\n",
    "\n",
    "Build vocabularies for both English and Vietnamese with proper special token handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationVocabulary:\n",
    "    \"\"\"\n",
    "    Vocabulary class for translation tasks with special token handling.\n",
    "    \n",
    "    Manages word-to-index mappings for both source and target languages,\n",
    "    following PyTorch best practices for NLP datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, language: str = \"en\"):\n",
    "        self.language = language\n",
    "        \n",
    "        # Special tokens\n",
    "        self.PAD_TOKEN = '<pad>'\n",
    "        self.UNK_TOKEN = '<unk>'\n",
    "        self.SOS_TOKEN = '<sos>'  # Start of sentence\n",
    "        self.EOS_TOKEN = '<eos>'  # End of sentence\n",
    "        \n",
    "        self.PAD_IDX = 0\n",
    "        self.UNK_IDX = 1\n",
    "        self.SOS_IDX = 2\n",
    "        self.EOS_IDX = 3\n",
    "        \n",
    "        self.word2idx = {\n",
    "            self.PAD_TOKEN: self.PAD_IDX,\n",
    "            self.UNK_TOKEN: self.UNK_IDX, \n",
    "            self.SOS_TOKEN: self.SOS_IDX,\n",
    "            self.EOS_TOKEN: self.EOS_IDX\n",
    "        }\n",
    "        self.idx2word = {v: k for k, v in self.word2idx.items()}\n",
    "        self.next_idx = 4  # Start after special tokens\n",
    "        \n",
    "    def add_sentence(self, sentence: str):\n",
    "        \"\"\"Add words from sentence to vocabulary.\"\"\"\n",
    "        words = self.tokenize(sentence)\n",
    "        for word in words:\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word: str) -> int:\n",
    "        \"\"\"Add word to vocabulary and return its index.\"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.next_idx\n",
    "            self.idx2word[self.next_idx] = word\n",
    "            self.next_idx += 1\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def sentence_to_indices(self, sentence: str, add_eos: bool = False) -> List[int]:\n",
    "        \"\"\"Convert sentence to list of word indices.\"\"\"\n",
    "        words = self.tokenize(sentence)\n",
    "        indices = [self.word2idx.get(word, self.UNK_IDX) for word in words]\n",
    "        \n",
    "        if add_eos:\n",
    "            indices.append(self.EOS_IDX)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def indices_to_sentence(self, indices: List[int]) -> str:\n",
    "        \"\"\"Convert list of indices back to sentence.\"\"\"\n",
    "        words = []\n",
    "        for idx in indices:\n",
    "            if idx == self.EOS_IDX:\n",
    "                break\n",
    "            if idx not in [self.PAD_IDX, self.SOS_IDX]:\n",
    "                words.append(self.idx2word.get(idx, self.UNK_TOKEN))\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def tokenize(self, sentence: str) -> List[str]:\n",
    "        \"\"\"Tokenize sentence with language-specific handling.\"\"\"\n",
    "        # Basic preprocessing\n",
    "        sentence = sentence.lower().strip()\n",
    "        \n",
    "        # Vietnamese-specific preprocessing\n",
    "        if self.language == \"vi\":\n",
    "            # Handle Vietnamese diacritics and tone marks\n",
    "            sentence = self._normalize_vietnamese(sentence)\n",
    "        \n",
    "        # Basic tokenization (split on whitespace and punctuation)\n",
    "        tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', sentence)\n",
    "        return [token for token in tokens if token.strip()]\n",
    "    \n",
    "    def _normalize_vietnamese(self, text: str) -> str:\n",
    "        \"\"\"Basic Vietnamese text normalization.\"\"\"\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Basic punctuation normalization\n",
    "        text = text.replace('"', '\"').replace('"', '\"')\n",
    "        text = text.replace(''', \"'\").replace(''', \"'\")\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.word2idx)\n",
    "\n",
    "# Build vocabularies from Australian translation data\n",
    "print(\"üî® Building vocabularies from Australian translation data...\")\n",
    "\n",
    "src_vocab = TranslationVocabulary(\"en\")\n",
    "tgt_vocab = TranslationVocabulary(\"vi\")\n",
    "\n",
    "for en_text, vi_text in AUSTRALIAN_TRANSLATION_PAIRS:\n",
    "    src_vocab.add_sentence(en_text)\n",
    "    tgt_vocab.add_sentence(vi_text)\n",
    "\n",
    "print(f\"‚úÖ Vocabularies built successfully!\")\n",
    "print(f\"   üìä English vocabulary: {len(src_vocab)} words\")\n",
    "print(f\"   üìä Vietnamese vocabulary: {len(tgt_vocab)} words\")\n",
    "\n",
    "# Test tokenization\n",
    "print(f\"\\nüß™ Testing tokenization:\")\n",
    "test_en = \"The Sydney Opera House is beautiful\"\n",
    "test_vi = \"Nh√† h√°t Opera Sydney r·∫•t ƒë·∫πp\"\n",
    "\n",
    "en_tokens = src_vocab.tokenize(test_en)\n",
    "vi_tokens = tgt_vocab.tokenize(test_vi)\n",
    "\n",
    "print(f\"   English: {test_en} ‚Üí {en_tokens}\")\n",
    "print(f\"   Vietnamese: {test_vi} ‚Üí {vi_tokens}\")\n",
    "\n",
    "# Test conversion\n",
    "en_indices = src_vocab.sentence_to_indices(test_en, add_eos=True)\n",
    "vi_indices = tgt_vocab.sentence_to_indices(test_vi, add_eos=True)\n",
    "\n",
    "print(f\"   EN indices: {en_indices}\")\n",
    "print(f\"   VI indices: {vi_indices}\")\n",
    "\n",
    "# Test reconstruction\n",
    "reconstructed_en = src_vocab.indices_to_sentence(en_indices)\n",
    "reconstructed_vi = tgt_vocab.indices_to_sentence(vi_indices)\n",
    "\n",
    "print(f\"   Reconstructed EN: {reconstructed_en}\")\n",
    "print(f\"   Reconstructed VI: {reconstructed_vi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

